<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>ğŸ“š Embodied AI è®ºæ–‡è¿½è¸ª | é¢¨ã«å‘ã‹ã£ã¦çš„ä¸ªäººåšå®¢</title><meta name="author" content="mrguo"><meta name="copyright" content="mrguo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="ğŸ“š Embodied AI è®ºæ–‡è¿½è¸ª ğŸ¤– è‡ªåŠ¨è¿½è¸ª Embodied-AI-Daily ä»“åº“çš„æœ€æ–°è®ºæ–‡ ğŸ“… æœ€åæ›´æ–°: 2025-12-24 00:08:14 | ğŸ“Š è®ºæ–‡æ€»æ•°: 2079 | ğŸ”„ å·²åˆ†æ: 279     ğŸ”¥ æœ€è¿‘ä¸¤å‘¨è®ºæ–‡ (781 ç¯‡)  ğŸ“… 2025-12-19  ğŸ“„ Understanding and supporting how developers">
<meta property="og:type" content="website">
<meta property="og:title" content="ğŸ“š Embodied AI è®ºæ–‡è¿½è¸ª">
<meta property="og:url" content="https://ztguoresearch.github.io/papers/index.html">
<meta property="og:site_name" content="é¢¨ã«å‘ã‹ã£ã¦çš„ä¸ªäººåšå®¢">
<meta property="og:description" content="ğŸ“š Embodied AI è®ºæ–‡è¿½è¸ª ğŸ¤– è‡ªåŠ¨è¿½è¸ª Embodied-AI-Daily ä»“åº“çš„æœ€æ–°è®ºæ–‡ ğŸ“… æœ€åæ›´æ–°: 2025-12-24 00:08:14 | ğŸ“Š è®ºæ–‡æ€»æ•°: 2079 | ğŸ”„ å·²åˆ†æ: 279     ğŸ”¥ æœ€è¿‘ä¸¤å‘¨è®ºæ–‡ (781 ç¯‡)  ğŸ“… 2025-12-19  ğŸ“„ Understanding and supporting how developers">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ztguoresearch.github.io/img/touxiang.png">
<meta property="article:published_time" content="2025-12-23T16:08:14.000Z">
<meta property="article:modified_time" content="2025-12-23T16:08:14.972Z">
<meta property="article:author" content="mrguo">
<meta property="article:tag" content="åšå®¢, æŠ€æœ¯, ç”Ÿæ´»">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ztguoresearch.github.io/img/touxiang.png"><script type="application/ld+json"></script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://ztguoresearch.github.io/papers/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":false,"hitsPerPage":8},"languages":{"hits_empty":"æœªæ‰¾åˆ°ç¬¦åˆæ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}","hits_stats":"å…±æ‰¾åˆ° ${hits} ç¯‡æ–‡ç« "}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300,"highlightFullpage":true,"highlightMacStyle":true},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶å¤±è´¥',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'å¤©',
  dateSuffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: 'åŠ è½½æ›´å¤š'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ğŸ“š Embodied AI è®ºæ–‡è¿½è¸ª',
  isHighlightShrink: true,
  isToc: false,
  pageType: 'page'
}</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css"><meta name="generator" content="Hexo 8.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/touxiang.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">81</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">29</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> å½’æ¡£</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/papers/"><i class="fa-fw fas fa-file-alt"></i><span> è®ºæ–‡è¿½è¸ª</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div></div></div><div class="page type-papers" id="body-wrap"><header class="not-home-page" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">é¢¨ã«å‘ã‹ã£ã¦çš„ä¸ªäººåšå®¢</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> æœç´¢</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> å½’æ¡£</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/papers/"><i class="fa-fw fas fa-file-alt"></i><span> è®ºæ–‡è¿½è¸ª</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="page-site-info"><h1 id="site-title">ğŸ“š Embodied AI è®ºæ–‡è¿½è¸ª</h1></div></header><main class="layout" id="content-inner"><div id="page"><div class="container" id="article-container"><div class="papers-header">

<h1 id="ğŸ“š-Embodied-AI-è®ºæ–‡è¿½è¸ª"><a href="#ğŸ“š-Embodied-AI-è®ºæ–‡è¿½è¸ª" class="headerlink" title="ğŸ“š Embodied AI è®ºæ–‡è¿½è¸ª"></a>ğŸ“š Embodied AI è®ºæ–‡è¿½è¸ª</h1><blockquote>
<p>ğŸ¤– è‡ªåŠ¨è¿½è¸ª <a target="_blank" rel="noopener" href="https://github.com/luohongk/Embodied-AI-Daily">Embodied-AI-Daily</a> ä»“åº“çš„æœ€æ–°è®ºæ–‡</p>
<p>ğŸ“… æœ€åæ›´æ–°: 2025-12-24 00:08:14 | ğŸ“Š è®ºæ–‡æ€»æ•°: 2079 | ğŸ”„ å·²åˆ†æ: 279</p>
</blockquote>
<hr>
</div>

<h2 id="ğŸ”¥-æœ€è¿‘ä¸¤å‘¨è®ºæ–‡-781-ç¯‡"><a href="#ğŸ”¥-æœ€è¿‘ä¸¤å‘¨è®ºæ–‡-781-ç¯‡" class="headerlink" title="ğŸ”¥ æœ€è¿‘ä¸¤å‘¨è®ºæ–‡ (781 ç¯‡)"></a>ğŸ”¥ æœ€è¿‘ä¸¤å‘¨è®ºæ–‡ (781 ç¯‡)</h2><div class="recent-papers">

<h3 id="ğŸ“…-2025-12-19"><a href="#ğŸ“…-2025-12-19" class="headerlink" title="ğŸ“… 2025-12-19"></a>ğŸ“… 2025-12-19</h3><div class="paper-card">

<p><strong>ğŸ“„ Understanding and supporting how developers prompt for LLM-powered code editing in practice</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.20196v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.20196.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Solomonoff-Inspired Hypothesis Ranking with LLMs for Prediction Under Uncertainty</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17145v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17145.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ On the Effect of Sampling Diversity in Scaling LLM Inference</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.11027v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.11027.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic Review Synthesis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.06000v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.06000.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PILAR: Personalizing Augmented Reality Interactions with LLM-based Human-Centric and Trustworthy Explanations for Daily Use Cases</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17172v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17172.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Parallelism Meets Adaptiveness: Scalable Documents Understanding in Multi-Agent LLM Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.17061v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.17061.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.10689v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.10689.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17247v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17247.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17259v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17259.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16189v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16189.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SportsGPT: An LLM-driven Framework for Interpretable Sports Motion Assessment and Training Guidance</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14121v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14121.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.16882v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.16882.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12284v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12284.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Bridging Natural Language and Formal Specificationâ€“Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17334v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17334.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.25123v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.25123.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17375v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17375.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ RBCTest: Leveraging LLMs to Mine and Verify Oracles of API Response Bodies for RESTful API Testing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.17287v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.17287.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced Time Series Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.18686v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.18686.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17540v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17540.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17570v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17570.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17630v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17630.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Linear Personality Probing and Steering in LLMs: A Big Five Study</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17639v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17639.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Designing an LLM-Based Behavioral Activation Chatbot for Young People with Depression: Insights from an Evaluation with Artificial Users and Clinical Experts</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.21540v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.21540.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.12817v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.12817.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-as-a-qualitative-judge: automating error analysis in natural language generation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.09147v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.09147.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.20150v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.20150.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-based Behaviour Driven Development for Hardware Design</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17814v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17814.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Causal Perspective on Measuring, Explaining and Mitigating Smells in LLM-Generated Code</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.15817v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.15817.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Human-Guided, Data-Centric LLM Co-Pilots</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.10321v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.10321.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SDUM: A Scalable Deep Unrolled Model for Universal MRI Reconstruction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17137v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17137.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TCDE: Topic-Centric Dual Expansion of Queries and Documents with Large Language Models for Information Retrieval</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17164v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17164.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Electric Vehicle Charging Load Forecasting: An Experimental Comparison of Machine Learning Methods</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17257v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17257.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Diagnostic Performance of Universal-Learning Ultrasound AI Across Multiple Organs and Tasks: the UUSIC25 Challenge</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17279v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17279.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LibriVAD: A Scalable Open Dataset with Deep Learning Benchmarks for Voice Activity Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17281v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17281.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ In-Context Learning for Seismic Data Processing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11575v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11575.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Dynamic PET Image Prediction Using a Network Combining Reversible and Irreversible Modules</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.22674v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.22674.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.23117v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.23117.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PEAR: Equal Area Weather Forecasting on the Sphere</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.17720v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.17720.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Linear Attention for Joint Power Optimization and User-Centric Clustering in Cell-Free Networks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17466v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17466.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Deep Learning-Based Surrogate Creep Modelling in Inconel 625: A High-Temperature Alloy Study</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17477v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17477.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.17860v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.17860.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TwinSegNet: A Digital Twin-Enabled Federated Learning Framework for Brain Tumor Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17488v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17488.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Resource-efficient medical image classification for edge devices</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17515v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17515.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Reproducibility in Predictive Process Mining: SPICE â€“ A Deep Learning Library</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16715v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16715.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Deep Learning-based Robust Autonomous Navigation of Aerial Robots in Dense Forests</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17553v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17553.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Explainable Conversational AI for Early Diagnosis with Large Language Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17559v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17559.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Learning-Based Safety-Aware Task Scheduling for Efficient Human-Robot Collaboration</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17560v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17560.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ On Using Neural Networks to Learn Safety Speed Reduction in Human-Robot Collaboration: A Comparative Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17579v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17579.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Sharing Knowledge without Sharing Data: Stitches can improve ensembles of disjointly trained models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17592v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17592.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17594v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17594.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Edge-Native Digitization of Handwritten Marksheets: A Hybrid Heuristic-Deep Learning Framework</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.16295v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.16295.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MGRegBenchï¼šä¸€ç§å¸¦æœ‰è§£å‰–æ ‡å¿—çš„ä¹³è…ºXå…‰å›¾åƒé…å‡†æ–°å‹åŸºå‡†æ•°æ®é›†</strong></p>
<p><em>MGRegBench: A Novel Benchmark Dataset with Anatomical Landmarks for Mammography Image Registration</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>MICCAI 2024 / IEEE Transactions on Medical Imaging (TMI) / Medical Image Analysis</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†é¦–ä¸ªå…¬å¼€çš„ä¹³è…ºXå…‰å›¾åƒé…å‡†åŸºå‡†æ•°æ®é›†MGRegBenchï¼ŒåŒ…å«è¶…è¿‡5000å¯¹å›¾åƒå’Œ100å¯¹å¸¦æœ‰äººå·¥æ ‡æ³¨è§£å‰–æ ‡å¿—ç‚¹åŠåˆ†å‰²æ©ç çš„å›¾åƒå¯¹ï¼Œæ—¨åœ¨è§£å†³è¯¥é¢†åŸŸç¼ºä¹å…¬å¼€æ•°æ®å’Œæ ‡å‡†åŒ–è¯„ä¼°çš„é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è®ºæ–‡å¹¶æœªæå‡ºæ–°çš„é…å‡†æ–¹æ³•ï¼Œè€Œæ˜¯æ„å»ºäº†ä¸€ä¸ªåŸºå‡†æ•°æ®é›†ï¼Œå¹¶åˆ©ç”¨è¯¥æ•°æ®é›†ç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†åŒ…æ‹¬ç»å…¸æ–¹æ³•ï¼ˆå¦‚ANTsï¼‰ã€åŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼ˆå¦‚VoxelMorphï¼‰å’Œé¢†åŸŸç‰¹å®šæ–¹æ³•ï¼ˆå¦‚MammoRegNetï¼‰åœ¨å†…çš„å¤šç§ç°æœ‰é…å‡†ç®—æ³•ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç¨³å¥çš„ä¹³è…ºXçº¿æ‘„å½±é…å‡†å¯¹äºç–¾ç—…è¿›å±•è¿½è¸ªå’Œä¹³è…ºç»„ç»‡çºµå‘å˜åŒ–ç›‘æµ‹ç­‰ä¸´åºŠåº”ç”¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å…¬å…±æ•°æ®é›†å’Œæ ‡å‡†åŒ–åŸºå‡†ï¼Œè¯¥é¢†åŸŸè¿›å±•æœ‰é™ã€‚ç°æœ‰ç ”ç©¶é€šå¸¸ä½¿ç”¨ç§æœ‰æ•°æ®å’Œä¸ä¸€è‡´çš„è¯„ä¼°æ¡†æ¶ï¼Œå¯¼è‡´éš¾ä»¥ç›´æ¥æ¯”è¾ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºMGRegBenchâ€”â€”é¦–ä¸ªå…¬å¼€çš„ä¹³è…ºXçº¿å½±åƒé…å‡†åŸºå‡†æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«5,000ä½™å¯¹å½±åƒï¼Œå…¶ä¸­100å¯¹åŒ…å«ç”¨äºä¸¥æ ¼è¯„ä¼°çš„æ‰‹åŠ¨æ ‡æ³¨è§£å‰–æ ‡å¿—ç‚¹å’Œåˆ†å‰²æ©æ¨¡ï¼Œä½¿å…¶æˆä¸ºå½“å‰æœ€å¤§è§„æ¨¡çš„å¸¦äººå·¥æ ‡æ³¨äºŒç»´â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17605v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17605.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MolMarkï¼šé€šè¿‡å¯å­¦ä¹ åŸå­çº§æ°´å°ä¿æŠ¤åˆ†å­ç»“æ„</strong></p>
<p><em>MolMark: Safeguarding Molecular Structures through Learnable Atom-Level Watermarking</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†é¦–ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„åˆ†å­æ°´å°æ¡†æ¶MolMarkï¼Œèƒ½å¤Ÿåœ¨ä¿æŒåˆ†å­åŠŸèƒ½çš„å‰æä¸‹ï¼Œå°†é«˜ä¿çœŸæ•°å­—ç­¾ååµŒå…¥åˆ°åŸå­çº§åˆ«çš„åˆ†å­ç»“æ„ä¸­ï¼Œå¹¶ç¡®ä¿å…¶å‡ ä½•é²æ£’æ€§ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é€šè¿‡å¯å­¦ä¹ çš„åŸå­çº§è¡¨ç¤ºè°ƒåˆ¶ï¼Œåˆ©ç”¨SE(3)ä¸å˜ç‰¹å¾ä¿è¯æ°´å°åœ¨æ—‹è½¬ã€å¹³ç§»å’Œåå°„ä¸‹çš„ç¨³å®šæ€§ï¼Œå¹¶å°†æ°´å°è¿‡ç¨‹ä½œä¸ºä¸ç”Ÿæˆæ¨¡å‹æ— ç¼é›†æˆçš„å­¦ä¹ å˜æ¢ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: äººå·¥æ™ºèƒ½é©±åŠ¨çš„åˆ†å­ç”Ÿæˆæ­£åœ¨é‡å¡‘è¯ç‰©å‘ç°ä¸ææ–™è®¾è®¡é¢†åŸŸï¼Œç„¶è€Œä¿æŠ¤æœºåˆ¶çš„ç¼ºå¤±ä½¿å¾—AIç”Ÿæˆçš„åˆ†å­é¢ä¸´æœªç»æˆæƒå¤ç”¨å’Œæ¥æºæ¨¡ç³Šçš„é£é™©ã€‚è¿™ä¸€å±€é™æ—¢æŸå®³ç§‘å­¦å¯é‡å¤æ€§ï¼Œä¹Ÿå¨èƒçŸ¥è¯†äº§æƒå®‰å…¨ã€‚ä¸ºåº”å¯¹æ­¤æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†é¦–ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„åˆ†å­æ°´å°æ¡†æ¶ï¼ˆMolMarkï¼‰ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç²¾å·§è®¾è®¡å°†é«˜ä¿çœŸæ•°å­—ç­¾ååµŒå…¥åˆ†å­ï¼ŒåŒæ—¶ç¡®ä¿åˆ†å­åŠŸèƒ½ä¸å—å½±å“ã€‚MolMarké€šè¿‡å­¦ä¹ è°ƒæ§å…·æœ‰åŒ–å­¦æ„ä¹‰çš„åŸå­çº§è¡¨å¾ï¼Œå¹¶å€ŸåŠ©SE(3)ä¸å˜ç‰¹å¾å¢å¼ºå‡ ä½•â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.17702v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.17702.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ç©ºé—´æ„ŸçŸ¥å˜æ¢å™¨ï¼šå°†åœ°ç»Ÿè®¡åæ–¹å·®åç½®æ³¨å…¥è‡ªæ³¨æ„åŠ›æœºåˆ¶ä»¥æå‡æ—¶ç©ºé¢„æµ‹èƒ½åŠ›</strong></p>
<p><em>Spatially-informed transformers: Injecting geostatistical covariance biases into self-attention for spatio-temporal forecasting</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025ã€‚è¯¥è®ºæ–‡èšç„¦äºTransformeræ¶æ„çš„åŸºç¡€æ€§æ”¹è¿›ï¼Œå¹¶å°†å…¶åº”ç”¨äºæ—¶ç©ºé¢„æµ‹è¿™ä¸€æ ¸å¿ƒæœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œç†è®ºå’Œæ–¹æ³•åˆ›æ–°æ€§å¼ºï¼Œç¬¦åˆé¡¶çº§æœºå™¨å­¦ä¹ ä¼šè®®çš„å½•ç”¨æ ‡å‡†ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§ç©ºé—´æ„ŸçŸ¥çš„Transformeræ¶æ„ï¼Œé€šè¿‡å°†å¯å­¦ä¹ çš„åœ°ç»Ÿè®¡åæ–¹å·®æ ¸ç›´æ¥æ³¨å…¥è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸ºåºåˆ—å»ºæ¨¡å¼•å…¥äº†ç©ºé—´å‡ ä½•å½’çº³åç½®ï¼Œä»è€Œå¼¥åˆäº†ç»å…¸åœ°ç»Ÿè®¡å­¦ä¸æ·±åº¦å­¦ä¹ åœ¨é«˜ç»´æ—¶ç©ºè¿‡ç¨‹å»ºæ¨¡ä¸­çš„é¸¿æ²Ÿã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ ¸å¿ƒæ–¹æ³•æ˜¯å°†è‡ªæ³¨æ„åŠ›ç»“æ„å½¢å¼åŒ–åˆ†è§£ä¸ºä¸€ä¸ªå¹³ç¨³çš„ç‰©ç†å…ˆéªŒï¼ˆç”±åœ°ç»Ÿè®¡åæ–¹å·®æ ¸å®šä¹‰ï¼‰å’Œä¸€ä¸ªéå¹³ç¨³çš„æ•°æ®é©±åŠ¨æ®‹å·®é¡¹ï¼Œä»è€Œåœ¨Transformerä¸­æ–½åŠ è½¯æ‹“æ‰‘çº¦æŸï¼Œä½¿å…¶èƒ½å¤Ÿè‡ªç„¶åœ°ç†è§£ä¼ æ„Ÿå™¨ä¹‹é—´çš„è·ç¦»å…³ç³»ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: é«˜ç»´æ—¶ç©ºè¿‡ç¨‹å»ºæ¨¡é¢ä¸´ç»å…¸åœ°ç»Ÿè®¡å­¦æ¦‚ç‡ä¸¥è°¨æ€§ä¸æ·±åº¦å­¦ä¹ çµæ´»é«˜å®¹é‡è¡¨å¾ä¹‹é—´çš„æ ¹æœ¬æ€§äºŒåˆ†å›°å¢ƒã€‚é«˜æ–¯è¿‡ç¨‹è™½èƒ½æä¾›ç†è®ºä¸€è‡´æ€§åŠç²¾ç¡®çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œä½†å…¶é«˜æ˜‚çš„è®¡ç®—å¤æ‚åº¦ä½¿å…¶éš¾ä»¥é€‚ç”¨äºå¤§è§„æ¨¡ä¼ æ„Ÿå™¨ç½‘ç»œã€‚åä¹‹ï¼Œç°ä»£Transformeræ¶æ„è™½æ“…é•¿åºåˆ—å»ºæ¨¡ï¼Œå´å¤©ç„¶ç¼ºä¹å‡ ä½•å½’çº³åç½®â€”â€”å…¶å°†ç©ºé—´ä¼ æ„Ÿå™¨è§†ä¸ºæ’åˆ—ä¸å˜çš„æ ‡è®°ï¼Œæ— æ³•æœ¬è´¨ç†è§£è·ç¦»å…³ç³»ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§ç©ºé—´æ„ŸçŸ¥Transformerï¼Œè¯¥æ··åˆæ¶æ„é€šè¿‡å¯å­¦ä¹ çš„åæ–¹å·®æ ¸å°†â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17696v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17696.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MambaMIL+ï¼šé¢å‘åƒå…†åƒç´ å…¨åˆ‡ç‰‡å›¾åƒçš„é•¿ç¨‹ä¸Šä¸‹æ–‡æ¨¡å¼å»ºæ¨¡</strong></p>
<p><em>MambaMIL+: Modeling Long-Term Contextual Patterns for Gigapixel Whole Slide Image</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>MICCAI 2025 æˆ– Medical Image Analysis (MedIA) æœŸåˆŠã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºMambaMIL+æ¡†æ¶ï¼Œé€šè¿‡é‡å æ‰«æå’Œç©ºé—´ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ‰«ææœºåˆ¶ï¼Œåœ¨ä¿æŒé•¿åºåˆ—å»ºæ¨¡æ•ˆç‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆæ•´åˆäº†WSIçš„ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯å¹¶ç¼“è§£äº†è®°å¿†è¡°å‡é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ¡†æ¶åŸºäºMambaæ¶æ„ï¼Œé€šè¿‡é‡ç»„è¡¥ä¸åºåˆ—ä»¥åµŒå…¥ç©ºé—´è¿ç»­æ€§ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ‰«ææœºåˆ¶æ¥å¢å¼ºå¯¹å±€éƒ¨ç©ºé—´ç»“æ„çš„æ„ŸçŸ¥ï¼Œä»è€Œæå‡å¯¹åƒå…†åƒç´ å…¨åˆ‡ç‰‡å›¾åƒçš„åˆ†æèƒ½åŠ›ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIï¼‰æ˜¯è®¡ç®—ç—…ç†å­¦ä¸­çš„é‡è¦æ•°æ®æ¨¡æ€ï¼Œä½†å…¶åƒå…†åƒç´ çº§åˆ†è¾¨ç‡ä¸ç»†ç²’åº¦æ ‡æ³¨çš„ç¼ºå¤±å¯¹ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹æ„æˆæŒ‘æˆ˜ã€‚å¤šç¤ºä¾‹å­¦ä¹ ï¼ˆMILï¼‰é€šè¿‡å°†æ¯å¼ WSIè§†ä¸ºä¸€ç»„å›¾åƒå—çº§ç¤ºä¾‹æ¥æä¾›è§£å†³æ–¹æ¡ˆï¼Œä½†å¯¹å…·æœ‰ä¸°å¯Œç©ºé—´èƒŒæ™¯çš„è¶…é•¿åºåˆ—è¿›è¡Œæœ‰æ•ˆå»ºæ¨¡ä»å­˜åœ¨å›°éš¾ã€‚è¿‘æœŸï¼ŒMambaä½œä¸ºé•¿åºåˆ—å­¦ä¹ çš„æ–°å…´æ–¹æ³•å´­éœ²å¤´è§’ï¼Œå¯çº¿æ€§æ‰©å±•è‡³æ•°åƒä¸ªæ ‡è®°ã€‚ç„¶è€Œå°½ç®¡å…¶æ•ˆç‡çªå‡ºï¼Œè¯¥æ–¹æ³•ä»å—é™äºç©ºé—´èƒŒæ™¯å»ºæ¨¡èƒ½åŠ›ä¸è¶³ä¸è®°å¿†è¡°å‡é—®é¢˜ï¼Œåˆ¶çº¦äº†å…¶åœ¨WSâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17726v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17726.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºå¯¹é½çºµå‘MRIä¸ä¸´åºŠæ•°æ®çš„ä¹³è…ºç™Œæ–°è¾…åŠ©åŒ–ç–—ç–—æ•ˆé¢„æµ‹</strong></p>
<p><em>Breast Cancer Neoadjuvant Chemotherapy Treatment Response Prediction Using Aligned Longitudinal MRI and Clinical Data</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>MICCAI 2025 æˆ– IEEE Transactions on Medical Imagingã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ä¸ªç»“åˆçºµå‘å¯¹é½MRIå½±åƒä¸ä¸´åºŠæ•°æ®çš„æ¡†æ¶ï¼Œç”¨äºé¢„æµ‹ä¹³è…ºç™Œæ–°è¾…åŠ©åŒ–ç–—çš„æ²»ç–—ååº”ï¼Œå¹¶åˆ›æ–°æ€§åœ°æ¯”è¾ƒäº†å¤šç§æ·±åº¦å­¦ä¹ ä¸å½±åƒç»„å­¦ç‰¹å¾æå–å™¨åœ¨çºµå‘å½±åƒåˆ†æä¸­çš„æ€§èƒ½ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ¡†æ¶åŒ…å«è‚¿ç˜¤åˆ†å‰²ã€å›¾åƒé…å‡†ã€ç‰¹å¾æå–å’Œé¢„æµ‹å»ºæ¨¡å››ä¸ªæ ¸å¿ƒæ­¥éª¤ï¼Œé€šè¿‡å›¾åƒé…å‡†å®ç°ä¸åŒæ—¶é—´ç‚¹è‚¿ç˜¤åŒºåŸŸçš„çºµå‘ç‰¹å¾å¯¹é½ä¸æ¯”è¾ƒï¼Œå¹¶ç³»ç»Ÿé›†æˆäº†å¤šç§ç‰¹å¾æå–ã€é€‰æ‹©åŠæœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç›®çš„ï¼šæœ¬ç ”ç©¶æ—¨åœ¨åˆ©ç”¨çºµå‘å¯¹æ¯”å¢å¼ºç£å…±æŒ¯å›¾åƒï¼ˆCE-MRIï¼‰ä¸ä¸´åºŠæ•°æ®ï¼Œé¢„æµ‹ä¹³è…ºç™Œæ‚£è€…æ–°è¾…åŠ©åŒ–ç–—ï¼ˆNACTï¼‰çš„æ²»ç–—ååº”ã€‚ç›®æ ‡æ˜¯å¼€å‘æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ¨¡å‹ä»¥é¢„æµ‹ç—…ç†å®Œå…¨ç¼“è§£ï¼ˆPCRäºŒåˆ†ç±»ï¼‰åŠ5å¹´æ— å¤å‘ç”Ÿå­˜çŠ¶æ€ï¼ˆRFSäºŒåˆ†ç±»ï¼‰ã€‚æ–¹æ³•ï¼šæ‰€æå‡ºçš„æ¡†æ¶åŒ…æ‹¬è‚¿ç˜¤åˆ†å‰²ã€å›¾åƒé…å‡†ã€ç‰¹å¾æå–å’Œé¢„æµ‹å»ºæ¨¡ã€‚é€šè¿‡å›¾åƒé…å‡†æ–¹æ³•ï¼Œå¯åœ¨ä¸åŒæ—¶é—´ç‚¹ä»åŸå§‹è‚¿ç˜¤éƒ¨ä½æå–å¹¶æ¯”è¾ƒMRIå›¾åƒç‰¹å¾ï¼Œä»è€Œç›‘æµ‹NACTè¿‡ç¨‹ä¸­çš„ç˜¤å†…å˜åŒ–ã€‚ç ”ç©¶å®ç°å¹¶æ¯”â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17759v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17759.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ UniStateDLOï¼šé¢å‘å—é™æ“ä½œçš„é®æŒ¡ç¯å¢ƒä¸‹å¯å˜å½¢çº¿æ€§ç‰©ä½“çš„ç»Ÿä¸€ç”Ÿæˆå¼çŠ¶æ€ä¼°è®¡ä¸è·Ÿè¸ª</strong></p>
<p><em>UniStateDLO: Unified Generative State Estimation and Tracking of Deformable Linear Objects Under Occlusion for Constrained Manipulation</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– IROS 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†é¦–ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„å®Œæ•´DLOæ„ŸçŸ¥æ¡†æ¶UniStateDLOï¼Œå°†å•å¸§çŠ¶æ€ä¼°è®¡ä¸è·¨å¸§çŠ¶æ€è·Ÿè¸ªç»Ÿä¸€å»ºæ¨¡ä¸ºæ¡ä»¶ç”Ÿæˆé—®é¢˜ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹åœ¨ä¸¥é‡é®æŒ¡ä¸‹å®ç°é²æ£’æ„ŸçŸ¥ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: å°†DLOçš„å•å¸§çŠ¶æ€ä¼°è®¡å’Œè·¨å¸§çŠ¶æ€è·Ÿè¸ªå‡æ„å»ºä¸ºä»¥éƒ¨åˆ†ç‚¹äº‘ä¸ºæ¡ä»¶çš„ç”Ÿæˆä»»åŠ¡ï¼Œé€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„æ‰©æ•£æ¨¡å‹æ¡†æ¶æ¥æ¨ç†å’Œé¢„æµ‹å®Œæ•´çš„DLOçŠ¶æ€ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å¯¹å¯å˜å½¢çº¿æ€§ç‰©ä½“ï¼ˆå¦‚ç”µç¼†ã€ç»³ç´¢å’Œå¯¼çº¿ï¼‰çš„æ„ŸçŸ¥æ˜¯å®ç°ä¸‹æ¸¸æ“ä½œæˆåŠŸçš„åŸºçŸ³ã€‚å°½ç®¡åŸºäºè§†è§‰çš„æ–¹æ³•å·²è¢«å¹¿æ³›æ¢ç´¢ï¼Œä½†åœ¨å—é™æ“ä½œç¯å¢ƒä¸­ï¼Œç”±äºå‘¨å›´éšœç¢ç‰©ã€å¤§èŒƒå›´ä¸”å¤šå˜çš„å½¢å˜ä»¥åŠè§†è§’å—é™ï¼Œè¿™äº›æ–¹æ³•ä»ææ˜“å—åˆ°å¸¸è§é®æŒ¡çš„å½±å“ã€‚æ­¤å¤–ï¼ŒçŠ¶æ€ç©ºé—´çš„é«˜ç»´åº¦ã€ç¼ºä¹æ˜¾è‘—è§†è§‰ç‰¹å¾ä»¥åŠä¼ æ„Ÿå™¨å™ªå£°çš„å­˜åœ¨ï¼Œè¿›ä¸€æ­¥åŠ å‰§äº†å¯é æ„ŸçŸ¥å¯å˜å½¢çº¿æ€§ç‰©ä½“çš„æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›å¼€æ”¾æ€§é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†UniStateDLOâ€”â€”é¦–ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„å®Œæ•´å¯å˜å½¢çº¿æ€§ç‰©â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17764v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17764.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ UrbanDIFFï¼šå¯†é›†äº‘å±‚è¦†ç›–ä¸‹åŸå¸‚åœ°è¡¨æ¸©åº¦ç©ºé—´ç¼ºå¤±å¡«è¡¥çš„å»å™ªæ‰©æ•£æ¨¡å‹</strong></p>
<p><em>UrbanDIFF: A Denoising Diffusion Model for Spatial Gap Filling of Urban Land Surface Temperature Under Dense Cloud Cover</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE Transactions on Geoscience and Remote Sensing (TGRS) æˆ– Remote Sensing of Environmentã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åŸºäºå»å™ªæ‰©æ•£æ¨¡å‹çš„çº¯ç©ºé—´æ–¹æ³•UrbanDIFFï¼Œç”¨äºåœ¨å¯†é›†äº‘å±‚è¦†ç›–ä¸‹é‡å»ºåŸå¸‚åœ°è¡¨æ¸©åº¦ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤§é¢ç§¯è¿ç»­ç¼ºå¤±åŒºåŸŸæ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•å°†åœ°è¡¨æ¸©åº¦ç©ºé—´é‡å»ºä»»åŠ¡æ„å»ºä¸ºå›¾åƒä¿®å¤é—®é¢˜ï¼Œåˆ©ç”¨å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼Œåœ¨ä»…æœ‰å•æ—¶ç›¸ã€å•ä¼ æ„Ÿå™¨æ•°æ®ä¸”å­˜åœ¨å¤§é¢ç§¯äº‘é®æŒ¡çš„æƒ…å†µä¸‹ï¼Œç›´æ¥ç”Ÿæˆç¼ºå¤±åŒºåŸŸçš„åˆç†æ¸©åº¦å€¼ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å«æ˜Ÿåæ¼”çš„åœ°è¡¨æ¸©åº¦äº§å“å› å…¶åœ¨å¤§éƒ½å¸‚åŒºæä¾›è¿ç»­ç½‘æ ¼åŒ–è¦†ç›–ï¼Œæˆä¸ºåœ°è¡¨åŸå¸‚çƒ­å²›ç›‘æµ‹çš„æ ¸å¿ƒæ•°æ®æºã€‚ç„¶è€Œï¼Œäº‘æ±¡æŸ“å¸¸å¯¼è‡´åœ°è¡¨æ¸©åº¦è§‚æµ‹æ•°æ®ç¼ºå¤±ï¼Œé™åˆ¶äº†å…¶åœ¨è¿ç»­çƒ­å²›åˆ†æä¸­çš„åº”ç”¨ã€‚ç°æœ‰åœ°è¡¨æ¸©åº¦é‡å»ºæ–¹æ³•å¤šä¾èµ–å¤šæ—¶ç›¸ä¿¡æ¯æˆ–å¤šæºæ•°æ®èåˆï¼Œéœ€è¦è¾…åŠ©è§‚æµ‹æ•°æ®ï¼Œä½†åœ¨æŒç»­äº‘è¦†ç›–æ¡ä»¶ä¸‹è¿™äº›æ•°æ®å¯èƒ½æ— æ³•è·å–æˆ–ä¸å¯é ã€‚çº¯ç©ºé—´æ’å€¼æ–¹æ³•æä¾›äº†æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ä¼ ç»Ÿç»Ÿè®¡æ–¹æ³•åœ¨å¤§èŒƒå›´æˆ–ç©ºé—´è¿ç»­ç¼ºå¤±åŒºåŸŸæ•ˆæœä¸ä½³ï¼Œè€Œè®¸å¤šåŸºäºæ·±åº¦å­¦ä¹ çš„ç©ºé—´æ¨¡å‹ä¼šéšç¼ºå¤±ç‡â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17782v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17782.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ è§å…‰ä¸»å¯¼æ¡ä»¶ä¸‹æ‹‰æ›¼å…‰è°±å»å™ªçš„ä»¿çœŸé©±åŠ¨æ·±åº¦å­¦ä¹ æ¡†æ¶</strong></p>
<p><em>Simulation-Driven Deep Learning Framework for Raman Spectral Denoising Under Fluorescence-Dominant Conditions</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>å¯èƒ½å‘è¡¨äºç”Ÿç‰©åŒ»å­¦å…‰å­¦æˆ–å…‰è°±åˆ†æé¢†åŸŸçš„é¡¶çº§æœŸåˆŠï¼Œå¦‚ *Analytical Chemistry*ã€*Biomedical Optics Express* æˆ– *Nature Communications* çš„å­åˆŠã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§ç»“åˆç»Ÿè®¡å™ªå£°æ¨¡å‹ä¸æ·±åº¦å­¦ä¹ çš„ä»¿çœŸé©±åŠ¨æ¡†æ¶ï¼Œç”¨äºåœ¨è§å…‰ä¸»å¯¼æ¡ä»¶ä¸‹å¯¹æ‹‰æ›¼å…‰è°±è¿›è¡Œå»å™ªï¼Œæœ‰æ•ˆè”åˆæŠ‘åˆ¶éšæœºæ¢æµ‹å™¨å™ªå£°å’Œè§å…‰åŸºçº¿å¹²æ‰°ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é€šè¿‡å…¨é¢å»ºæ¨¡ä¸»è¦å™ªå£°æºï¼Œç”Ÿæˆå…·æœ‰ç”Ÿç‰©çœŸå®æ€§çš„ä»¿çœŸæ‹‰æ›¼å…‰è°±ï¼Œå¹¶ä»¥æ­¤è®­ç»ƒä¸€ä¸ªçº§è”æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå®ç°å¯¹å™ªå£°å’Œè§å…‰èƒŒæ™¯çš„è”åˆå»é™¤ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ‹‰æ›¼å…‰è°±ä½œä¸ºä¸€ç§éç ´åæ€§ã€å…æ ‡è®°çš„åˆ†å­åˆ†ææŠ€æœ¯ï¼Œå…·æœ‰é«˜ç‰¹å¼‚æ€§ï¼Œæ˜¯ç”Ÿç‰©åŒ»å­¦è¯Šæ–­çš„æœ‰åŠ›å·¥å…·ã€‚ç„¶è€Œï¼Œå…¶åœ¨ç”Ÿç‰©ç»„ç»‡ä¸­çš„åº”ç”¨å—åˆ°æ‹‰æ›¼æ•£å°„ä¿¡å·å›ºæœ‰å¾®å¼±æ€§å’Œå¼ºè§å…‰èƒŒæ™¯çš„æŒ‘æˆ˜ï¼Œè¿™äº›å› ç´ ä¼šæ˜¾è‘—é™ä½ä¿¡å·è´¨é‡ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§ä»¿çœŸé©±åŠ¨çš„å»å™ªæ¡†æ¶ï¼Œå°†åŸºäºç»Ÿè®¡çš„å™ªå£°æ¨¡å‹ä¸æ·±åº¦å­¦ä¹ ç›¸ç»“åˆï¼Œä»¥å¢å¼ºåœ¨è§å…‰ä¸»å¯¼æ¡ä»¶ä¸‹è·å–çš„æ‹‰æ›¼å…‰è°±ã€‚æˆ‘ä»¬å…¨é¢å»ºæ¨¡äº†ä¸»è¦å™ªå£°æºï¼Œå¹¶åŸºäºè¯¥æ¨¡å‹ç”Ÿæˆäº†ç”Ÿç‰©å­¦çœŸå®çš„æ‹‰æ›¼å…‰è°±ï¼Œç”¨äºè®­ç»ƒçº§è”æ·±åº¦ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œæ—¨åœ¨â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17852v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17852.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ä½ç§©æ»¤æ³¢ä¸å¹³æ»‘åœ¨åºåˆ—æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨</strong></p>
<p><em>Low-Rank Filtering and Smoothing for Sequential Deep Learning</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>ICLR 2025 æˆ– NeurIPS 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§è´å¶æ–¯æ¡†æ¶ï¼Œå°†ç¥ç»ç½‘ç»œå‚æ•°è§†ä¸ºéçº¿æ€§é«˜æ–¯æ¨¡å‹çš„çŠ¶æ€ç©ºé—´ï¼Œå®ç°äº†å¯¹ä»»åŠ¡é—´å…³ç³»çš„å…ˆéªŒçŸ¥è¯†ç¼–ç ï¼Œå¹¶åˆ›æ–°æ€§åœ°åº”ç”¨è´å¶æ–¯å¹³æ»‘ä½¿æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨æœªæ¥ä»»åŠ¡çš„çŸ¥è¯†ï¼Œè€Œæ— éœ€è®¿é—®å…¶åŸå§‹æ•°æ®ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é€šè¿‡å°†ç½‘ç»œå‚æ•°å»ºæ¨¡ä¸ºçŠ¶æ€ç©ºé—´ï¼Œé‡‡ç”¨å¯¹è§’åŠ ä½ç§©è¿‘ä¼¼å®ç°é«˜æ•ˆæ»¤æ³¢å’Œå¹³æ»‘ï¼Œä»è€Œåœ¨è¿ç»­å­¦ä¹ ä»»åŠ¡ä¸­å¹³è¡¡çŸ¥è¯†ä¿ç•™ä¸é€‚åº”æ€§ï¼Œå¹¶æ”¯æŒè·¨ä»»åŠ¡çš„çŸ¥è¯†åŒå‘æµåŠ¨ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: é¡ºåºå­¦ä¹ å¤šä¸ªä»»åŠ¡è¦æ±‚ç¥ç»ç½‘ç»œåœ¨ä¿æŒå·²æœ‰çŸ¥è¯†çš„åŒæ—¶ï¼Œåˆèƒ½çµæ´»é€‚åº”æ–°ä»»åŠ¡ã€‚å¯¹ç½‘ç»œå‚æ•°è¿›è¡Œæ­£åˆ™åŒ–æ˜¯å¸¸è§æ–¹æ³•ï¼Œä½†è¿™ç±»æ–¹æ³•å¾ˆå°‘èå…¥å…³äºä»»åŠ¡å…³ç³»çš„å…ˆéªŒçŸ¥è¯†ï¼Œä¸”ä»…å…è®¸ä¿¡æ¯å‘æœªæ¥ä»»åŠ¡å•å‘æµåŠ¨ã€‚æˆ‘ä»¬æå‡ºä¸€ä¸ªè´å¶æ–¯æ¡†æ¶ï¼Œå°†ç½‘ç»œå‚æ•°è§†ä¸ºéçº¿æ€§é«˜æ–¯æ¨¡å‹çš„çŠ¶æ€ç©ºé—´ï¼Œç”±æ­¤è§£é”ä¸¤é¡¹å…³é”®èƒ½åŠ›ï¼š(1) æä¾›ç¼–ç ä»»åŠ¡é—´é¢†åŸŸçŸ¥è¯†çš„ç†è®ºæ¡†æ¶ï¼Œä¾‹å¦‚å¯æ§åˆ¶å“ªäº›ç½‘ç»œå±‚åº”åœ¨ä»»åŠ¡é—´è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´ï¼›(2) è´å¶æ–¯å¹³æ»‘çš„æ–°é¢–åº”ç”¨ï¼Œä½¿ä»»åŠ¡ä¸“ç”¨æ¨¡å‹èƒ½å¤Ÿæ•´â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.06800v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.06800.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ å¼€æ”¾åŸºç¡€æ¨¡å‹ä¸­è§†è§‰çš„å¯¹æŠ—é²æ£’æ€§</strong></p>
<p><em>Adversarial Robustness of Vision in Open Foundation Models</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– CVPR/ICLR/NeurIPSç­‰é¡¶çº§ä¼šè®®çš„Workshopã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æœ¬æ–‡é¦–æ¬¡å¯¹LLaVA-1.5-13Bå’ŒMeta Llama 3.2 Vision-8B-2è¿™ä¸¤ç§å¼€æ”¾è§†è§‰åŸºç¡€æ¨¡å‹è¿›è¡Œäº†å¯¹æŠ—é²æ£’æ€§çš„å®è¯è¯„ä¼°ä¸æ¯”è¾ƒï¼Œæ­ç¤ºäº†åœ¨è§†è§‰é—®ç­”ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹åŸºçº¿å‡†ç¡®ç‡ä¸å¯¹æŠ—é²æ£’æ€§ä¹‹é—´å¯èƒ½å­˜åœ¨çš„æƒè¡¡å…³ç³»ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: ç ”ç©¶é‡‡ç”¨æ— ç›®æ ‡PGDæ”»å‡»æ–¹æ³•ï¼Œé’ˆå¯¹æ¨¡å‹çš„è§†è§‰è¾“å…¥æ¨¡æ€ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œå¹¶åœ¨VQA v2æ•°æ®é›†çš„å­é›†ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œä½¿ç”¨æ ‡å‡†VQAå‡†ç¡®ç‡æŒ‡æ ‡æ¥é‡åŒ–æ”»å‡»æ•ˆæœï¼Œå¹¶æ¯”è¾ƒäº†ä¸¤ç§æ¨¡å‹åœ¨é­å—æ”»å‡»æ—¶çš„æ€§èƒ½ä¸‹é™ç¨‹åº¦ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: éšç€æ·±åº¦å­¦ä¹ åº”ç”¨çš„æ—¥ç›Šå¢å¤šï¼Œç†è§£äººå·¥æ™ºèƒ½ç³»ç»Ÿè¯†åˆ«ç‰©ä½“çš„æ¨¡å‹å˜å¾—è¶Šæ¥è¶Šå›°éš¾ã€‚å› æ­¤ï¼Œæ”»å‡»è€…å¯èƒ½è¯•å›¾é€šè¿‡æ·»åŠ ä¸å¯è§å…ƒç´ æ¥ä¿®æ”¹å›¾åƒï¼Œä»è€Œå¹²æ‰°äººå·¥æ™ºèƒ½å¯¹å®ä½“çš„è¯†åˆ«ã€‚æœ¬æ–‡ç ”ç©¶äº†LLaVA-1.5-13Bå’ŒMetaçš„Llama 3.2 Vision-8B-2æ¨¡å‹çš„å¯¹æŠ—é²æ£’æ€§ã€‚é’ˆå¯¹è§†è§‰è¾“å…¥æ¨¡æ€ï¼Œæˆ‘ä»¬å¯¹è¿™ä¸¤ç§æ¨¡å‹è¿›è¡Œäº†æ— ç›®æ ‡æŠ•å½±æ¢¯åº¦ä¸‹é™ï¼ˆPGDï¼‰æ”»å‡»æµ‹è¯•ï¼Œå¹¶åœ¨è§†è§‰é—®ç­”ï¼ˆVQAï¼‰v2æ•°æ®é›†çš„å­é›†ä¸Šè¿›è¡Œäº†å®è¯è¯„ä¼°ã€‚éšåâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17902v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17902.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ UniGaussianï¼šåŸºäºç»Ÿä¸€é«˜æ–¯è¡¨ç¤ºçš„å¤šç›¸æœºæ¨¡å‹é©¾é©¶åœºæ™¯é‡å»º</strong></p>
<p><em>UniGaussian: Driving Scene Reconstruction from Multiple Camera Models via Unified Gaussian Representations</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ECCV 2024/2026ï¼ˆè€ƒè™‘åˆ°å…¶èšç„¦äº3Dé‡å»ºã€ç¥ç»æ¸²æŸ“ä¸è‡ªåŠ¨é©¾é©¶çš„äº¤å‰é¢†åŸŸï¼Œä¸”æ–¹æ³•å…·æœ‰æ˜¾è‘—åˆ›æ–°æ€§å’Œå®ç”¨æ€§ï¼Œé¡¶çº§è®¡ç®—æœºè§†è§‰ä¼šè®®æ˜¯å…¶ä¸»è¦ç›®æ ‡ï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åä¸ºUniGaussiançš„æ–°æ–¹æ³•ï¼Œé¦–æ¬¡å®ç°äº†ä»å¤šç›¸æœºæ¨¡å‹ï¼ˆåŒ…æ‹¬é’ˆå­”å’Œé±¼çœ¼ç›¸æœºï¼‰å­¦ä¹ ç»Ÿä¸€çš„3Dé«˜æ–¯è¡¨ç¤ºï¼Œç”¨äºè‡ªåŠ¨é©¾é©¶åŸå¸‚åœºæ™¯é‡å»ºï¼›å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§é’ˆå¯¹é±¼çœ¼ç›¸æœºæ¨¡å‹çš„å¯å¾®æ¸²æŸ“æ–¹æ³•ï¼Œé€šè¿‡ä¸€ç³»åˆ—ä»¿å°„å˜æ¢æ¥æ‰­æ›²3Dé«˜æ–¯ï¼Œè§£å†³äº†3Dé«˜æ–¯æ³¼æº…ä¸é±¼çœ¼ç›¸æœºä¸å…¼å®¹çš„éš¾é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ¡†æ¶æ˜¯æ„å»ºä¸€ä¸ªç»Ÿä¸€çš„3Dé«˜æ–¯åœºæ™¯è¡¨ç¤ºï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè®¾è®¡äº†ä¸€ä¸ªå¯å¾®çš„æ¸²æŸ“ç®¡çº¿ã€‚è¯¥ç®¡çº¿é€šè¿‡ä¸ºé±¼çœ¼ç›¸æœºæ¨¡å‹å®šåˆ¶ä»¿å°„å˜æ¢æ¥æ‰­æ›²3Dé«˜æ–¯ï¼Œä»è€Œé€‚é…å…¶å…‰çº¿ç•¸å˜ï¼Œåœ¨ä¿è¯å¯å¾®æ€§çš„åŒæ—¶ç»´æŒäº†å®æ—¶æ¸²æŸ“èƒ½åŠ›ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åŸå¸‚åœºæ™¯é‡å»ºå¯¹äºç°å®ä¸–ç•Œçš„è‡ªåŠ¨é©¾é©¶æ¨¡æ‹Ÿå™¨è‡³å…³é‡è¦ã€‚å°½ç®¡ç°æœ‰æ–¹æ³•å·²å®ç°é€¼çœŸçš„é‡å»ºæ•ˆæœï¼Œä½†å¤§å¤šèšç„¦äºé’ˆå­”ç›¸æœºæ¨¡å‹ï¼Œå¿½ç•¥äº†é±¼çœ¼ç›¸æœºçš„ç‰¹æ€§ã€‚äº‹å®ä¸Šï¼Œå¦‚ä½•åœ¨é©¾é©¶åœºæ™¯ä¸­æœ‰æ•ˆæ¨¡æ‹Ÿé±¼çœ¼ç›¸æœºä»æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„éš¾é¢˜ã€‚æœ¬ç ”ç©¶æå‡ºUniGaussianâ€”â€”ä¸€ç§ä»å¤šç›¸æœºæ¨¡å‹å­¦ä¹ ç»Ÿä¸€ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºçš„æ–°æ–¹æ³•ï¼Œç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯çš„åŸå¸‚é‡å»ºã€‚æˆ‘ä»¬çš„è´¡çŒ®ä¸»è¦ä½“ç°åœ¨ä¸¤ä¸ªæ–¹é¢ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹å¯å¾®åˆ†æ¸²æŸ“æ–¹æ³•ï¼Œé€šè¿‡é’ˆå¯¹é±¼çœ¼ç›¸æœºæ¨¡å‹è®¾è®¡â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.15355v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.15355.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PhysGMï¼šç”¨äºå‰é¦ˆå¼å››ç»´åˆæˆçš„å¤§å‹ç‰©ç†é«˜æ–¯æ¨¡å‹</strong></p>
<p><em>PhysGM: Large Physical Gaussian Model for Feed-Forward 4D Synthesis</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– arXiv preprint</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºPhysGMï¼Œä¸€ç§å‰é¦ˆå¼æ¡†æ¶ï¼Œèƒ½å¤Ÿä»å•å¼ å›¾åƒè”åˆé¢„æµ‹3Dé«˜æ–¯è¡¨ç¤ºå’Œç‰©ç†å±æ€§ï¼Œå®ç°äº†æ— éœ€é€åœºæ™¯ä¼˜åŒ–çš„å¿«é€Ÿ4Dåˆæˆä¸æ¸²æŸ“ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é¦–å…ˆé¢„è®­ç»ƒä¸€ä¸ªç‰©ç†æ„ŸçŸ¥çš„é‡å»ºæ¨¡å‹æ¥ç›´æ¥æ¨æ–­é«˜æ–¯å’Œç‰©ç†å‚æ•°ï¼Œç„¶åé€šè¿‡Dirichletè¾¹ç•Œæ¡ä»¶ç­‰æ–¹æ³•è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹ï¼Œå®ç°å¤–è§‚ä¸ç‰©ç†å±æ€§çš„è”åˆå­¦ä¹ ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å°½ç®¡åŸºäºç‰©ç†çš„ä¸‰ç»´è¿åŠ¨åˆæˆæŠ€æœ¯å·²å–å¾—è¿›å±•ï¼Œå½“å‰æ–¹æ³•ä»å­˜åœ¨å…³é”®å±€é™ï¼šä¾èµ–ä»å¯†é›†å¤šè§†è§’å›¾åƒé¢„é‡å»ºçš„ä¸‰ç»´é«˜æ–¯æº…å°„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹éœ€è€—æ—¶è¿›è¡Œé€åœºæ™¯ä¼˜åŒ–ï¼›é€šè¿‡åƒµåŒ–çš„äººå·¥æŒ‡å®šå±æ€§æˆ–ä¸ç¨³å®šçš„è§†é¢‘æ¨¡å‹è¿›è¡Œç‰©ç†é›†æˆï¼Œåè€…éœ€å€ŸåŠ©åˆ†æ•°è’¸é¦é‡‡æ ·è¿›è¡Œå¤§é‡ä¼˜åŒ–è®¡ç®—ï¼›ä»¥åŠå°†é¢„å»ºä¸‰ç»´é«˜æ–¯æ¨¡å‹ä¸ç‰©ç†æ¨¡å—ç®€å•æ‹¼æ¥ï¼Œå¿½ç•¥äº†å¤–è§‚ä¸­è•´å«çš„ç‰©ç†ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½æ¬ ä½³ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºPhysGMâ€”â€”ä¸€ç§å‰é¦ˆå¼æ¡†æ¶ï¼Œèƒ½å¤Ÿä»å•å¼ å›¾åƒè”åˆé¢„æµ‹ä¸‰ç»´â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.13911v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.13911.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºä¸‰ç»´è¾å°„åœºåŸŸé€‚åº”å­¦ä¹ çš„å•ç›®RGBæ‚ä¹±ç¯å¢ƒé£è¡Œ</strong></p>
<p><em>Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code> | ğŸ“ å‡ºå¤„: <code>ICRA 2025 æˆ– RSS 2025ï¼ˆæœºå™¨äººå­¦é¡¶çº§ä¼šè®®ï¼‰ï¼›æˆ–ä½œä¸ºäº¤å‰é¢†åŸŸå·¥ä½œå‘è¡¨äº CVPR 2025ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§ç»“åˆ3Dé«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰é«˜ä¿çœŸä»¿çœŸä¸å¯¹æŠ—æ€§åŸŸé€‚åº”çš„æ¡†æ¶ï¼Œé¦–æ¬¡å®ç°äº†ä»…ä½¿ç”¨å•ç›®RGBå›¾åƒåœ¨æ‚ä¹±ç¯å¢ƒä¸­è¿›è¡Œé›¶æ ·æœ¬çœŸå®ä¸–ç•Œé£è¡Œçš„ç­–ç•¥å­¦ä¹ ï¼Œæœ‰æ•ˆå¼¥åˆäº†ä»¿çœŸä¸ç°å®çš„æ„ŸçŸ¥å·®è·ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ–¹æ³•æ ¸å¿ƒåœ¨äºåˆ©ç”¨3DGSæ„å»ºé«˜çœŸå®æ„Ÿä»¿çœŸç¯å¢ƒè¿›è¡Œç­–ç•¥è®­ç»ƒï¼Œå¹¶å¼•å…¥å¯¹æŠ—æ€§åŸŸé€‚åº”æŠ€æœ¯ï¼Œé€šè¿‡æœ€å°åŒ–ç‰¹å¾å·®å¼‚æ¥å­¦ä¹ ä¾èµ–é¢†åŸŸä¸å˜ç‰¹å¾çš„å¯¼èˆªç­–ç•¥ï¼Œä»è€Œå®ç°ä»ä»¿çœŸåˆ°çœŸå®ä¸–ç•Œçš„é›¶æ ·æœ¬è¿ç§»ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç°ä»£è‡ªä¸»å¯¼èˆªç³»ç»Ÿä¸»è¦ä¾èµ–äºæ¿€å…‰é›·è¾¾å’Œæ·±åº¦ç›¸æœºã€‚ç„¶è€Œï¼Œä¸€ä¸ªæ ¹æœ¬æ€§é—®é¢˜ä¾ç„¶å­˜åœ¨ï¼šé£è¡Œæœºå™¨äººèƒ½å¦ä»…ä½¿ç”¨å•ç›®RGBå›¾åƒåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°å¯¼èˆªï¼Ÿé‰´äºç°å®ä¸–ç•Œæ•°æ®é‡‡é›†çš„é«˜æ˜‚æˆæœ¬ï¼Œåœ¨ä»¿çœŸç¯å¢ƒä¸­å­¦ä¹ ç­–ç•¥æä¾›äº†ä¸€æ¡å¯è¡Œçš„è·¯å¾„ã€‚ä½†ç›´æ¥å°†æ­¤ç±»ç­–ç•¥éƒ¨ç½²åˆ°ç‰©ç†ä¸–ç•Œæ—¶ï¼Œæ˜¾è‘—çš„ä»¿çœŸä¸ç°å®æ„ŸçŸ¥å·®è·æ„æˆäº†ä¸»è¦éšœç¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å°†3Dé«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰ç¯å¢ƒçš„å…‰ç…§çœŸå®æ€§ä¸å¯¹æŠ—æ€§åŸŸé€‚åº”ç›¸ç»“åˆçš„æ–°æ¡†æ¶ã€‚é€šè¿‡åœ¨é«˜ä¿çœŸä»¿çœŸç¯å¢ƒä¸­è¿›è¡Œè®­â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17349v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17349.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ VLA-ANï¼šé¢å‘å¤æ‚ç¯å¢ƒç©ºä¸­å¯¼èˆªçš„é«˜æ•ˆæœºè½½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨æ¡†æ¶</strong></p>
<p><em>VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– IROS 2025ï¼ˆå› å…¶èšç„¦è®¡ç®—æœºè§†è§‰ä¸æœºå™¨äººç³»ç»Ÿé›†æˆï¼Œä¸”è§£å†³äº†å®é™…éƒ¨ç½²çš„å…³é”®ç“¶é¢ˆï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºé¦–ä¸ªé«˜æ•ˆã€å¯æœºè½½éƒ¨ç½²çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ— äººæœºå¯¼èˆªæ¡†æ¶VLA-ANï¼Œé€šè¿‡æ„å»ºåŸºäº3Dé«˜æ–¯æ³¼æº…çš„é«˜ä¿çœŸæ•°æ®é›†ã€æ¸è¿›å¼ä¸‰é˜¶æ®µè®­ç»ƒä»¥åŠç»“åˆå‡ ä½•å®‰å…¨æ ¡æ­£çš„è½»é‡åŒ–å®æ—¶åŠ¨ä½œæ¨¡å—ï¼Œç³»ç»Ÿæ€§åœ°è§£å†³äº†ç°æœ‰å¤§å‹ç©ºä¸­å¯¼èˆªæ¨¡å‹åœ¨æ•°æ®åŸŸã€æ—¶åºæ¨ç†ã€å®‰å…¨æ€§å’Œéƒ¨ç½²æ•ˆç‡æ–¹é¢çš„å››å¤§å±€é™ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ ¸å¿ƒæ¡†æ¶åŒ…æ‹¬ï¼š1ï¼‰åˆ©ç”¨3Dé«˜æ–¯æ³¼æº…æŠ€æœ¯æ„å»ºé«˜ä¿çœŸä»¿çœŸæ•°æ®é›†ä»¥å¼¥åˆåŸŸå·®è·ï¼›2ï¼‰é‡‡ç”¨æ¸è¿›å¼ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œä¾æ¬¡å¼ºåŒ–åœºæ™¯ç†è§£ã€æ ¸å¿ƒé£è¡ŒæŠ€èƒ½å’Œå¤æ‚å¯¼èˆªèƒ½åŠ›ï¼›3ï¼‰è®¾è®¡è½»é‡çº§å®æ—¶åŠ¨ä½œæ¨¡å—ï¼Œå¹¶é›†æˆå‡ ä½•å®‰å…¨æ ¡æ­£æœºåˆ¶ï¼Œç¡®ä¿ç”Ÿæˆå®‰å…¨ã€ç¨³å®šä¸”å¯å¿«é€Ÿæ‰§è¡Œçš„é£è¡ŒæŒ‡ä»¤ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æœ¬æ–‡æå‡ºVLA-ANâ€”â€”ä¸€ç§é«˜æ•ˆæœºè½½è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¡†æ¶ï¼Œä¸“ä¸ºå¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»æ— äººæœºå¯¼èˆªè€Œè®¾è®¡ã€‚è¯¥æ¡†æ¶é’ˆå¯¹ç°æœ‰å¤§å‹ç©ºä¸­å¯¼èˆªæ¨¡å‹çš„å››å¤§å±€é™æ€§é—®é¢˜ï¼šæ•°æ®åŸŸå·®å¼‚ã€æ—¶åºå¯¼èˆªæ¨ç†èƒ½åŠ›ä¸è¶³ã€ç”Ÿæˆå¼åŠ¨ä½œç­–ç•¥çš„å®‰å…¨éšæ‚£ä»¥åŠæœºè½½éƒ¨ç½²é™åˆ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åˆ©ç”¨3Dé«˜æ–¯æº…å°„æŠ€æœ¯æ„å»ºé«˜ä¿çœŸæ•°æ®é›†ï¼Œæœ‰æ•ˆå¼¥åˆé¢†åŸŸé¸¿æ²Ÿã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºæ¸è¿›å¼ä¸‰é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œä¾æ¬¡å¼ºåŒ–åœºæ™¯ç†è§£èƒ½åŠ›ã€æ ¸å¿ƒé£è¡ŒæŠ€èƒ½ä¸å¤æ‚å¯¼èˆªèƒ½åŠ›ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬è®¾è®¡äº†æ­è½½å‡ ä½•å®‰å…¨â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15258v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15258.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ G3Splatï¼šå‡ ä½•ä¸€è‡´å¯æ³›åŒ–çš„é«˜æ–¯æº…å°„</strong></p>
<p><em>G3Splat: Geometrically Consistent Generalizable Gaussian Splatting</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ECCV 2024</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: é’ˆå¯¹ä»…ä¾èµ–è§†å›¾åˆæˆæŸå¤±å¯¼è‡´å‡ ä½•ä¿¡æ¯æ¨¡ç³Šçš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºG3Splatï¼Œé€šè¿‡å¼•å…¥å‡ ä½•å…ˆéªŒçº¦æŸï¼Œå®ç°äº†å‡ ä½•ä¸€è‡´çš„å¯æ³›åŒ–3Dé«˜æ–¯æº…å°„è¡¨ç¤ºã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•åœ¨è‡ªç›‘ç£ã€æ— å§¿æ€å…ˆéªŒçš„å¯æ³›åŒ–æº…å°„æ¡†æ¶ä¸­ï¼Œåˆ†æå¹¶è§£å†³äº†3Dé«˜æ–¯å‚æ•°å­¦ä¹ çš„æ­§ä¹‰æ€§ï¼Œé€šè¿‡å¼ºåˆ¶å‡ ä½•ä¸€è‡´æ€§å…ˆéªŒæ¥ä¼˜åŒ–é«˜æ–¯å‚æ•°é¢„æµ‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ä¸‰ç»´é«˜æ–¯æ¨¡å‹æœ€è¿‘ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„åœºæ™¯è¡¨ç¤ºæ–¹æ³•å´­éœ²å¤´è§’ï¼Œèƒ½å¤Ÿå®ç°å®æ—¶ç‚¹äº‘æ¸²æŸ“å’Œç²¾ç¡®çš„æ–°è§†è§’åˆæˆï¼Œè¿™ä¿ƒä½¿å¤šé¡¹ç ”ç©¶å°†å¤šè§†è§’ç»“æ„é¢„æµ‹ç½‘ç»œåº”ç”¨äºä»å›¾åƒå›å½’é€åƒç´ çš„ä¸‰ç»´é«˜æ–¯å‚æ•°ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶å¤§å¤šä»…æ‰©å±•è¿™äº›ç½‘ç»œä»¥é¢„æµ‹é¢å¤–çš„é«˜æ–¯å‚æ•°â€”â€”åŒ…æ‹¬æ–¹å‘ã€å°ºåº¦ã€ä¸é€æ˜åº¦å’Œå¤–è§‚â€”â€”åŒæ—¶å‡ ä¹å®Œå…¨ä¾èµ–è§†è§’åˆæˆç›‘ç£ã€‚æˆ‘ä»¬è¯æ˜ï¼Œåœ¨è¿™ç§è®¾å®šä¸‹ï¼Œä»…é è§†è§’åˆæˆæŸå¤±ä¸è¶³ä»¥æ¢å¤å…·æœ‰å‡ ä½•æ„ä¹‰çš„ç‚¹äº‘ã€‚æˆ‘ä»¬åˆ†æå¹¶è§£å†³äº†åœ¨è‡ªç›‘ç£æ¡ä»¶ä¸‹å­¦ä¹ ä¸‰ç»´é«˜æ–¯ç‚¹äº‘â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17547v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17547.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åˆå”±å›¢ï¼šé¢å‘æ•´ä½“ä¸‰ç»´é«˜æ–¯åœºæ™¯ç¼–ç çš„å¤šæ•™å¸ˆé¢„è®­ç»ƒ</strong></p>
<p><em>Chorus: Multi-Teacher Pretraining for Holistic 3D Gaussian Scene Encoding</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†Chorusï¼Œé¦–ä¸ªé€šè¿‡ä»å¤šä¸ª2DåŸºç¡€æ¨¡å‹è’¸é¦äº’è¡¥ä¿¡å·æ¥é¢„è®­ç»ƒå…¨æ ˆå¼3Dé«˜æ–¯åœºæ™¯ç¼–ç å™¨çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä¸º3DGSåŸºå…ƒå­¦ä¹ ä¸°å¯Œã€é€šç”¨çš„ç‰¹å¾è¡¨ç¤ºã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é‡‡ç”¨ä¸€ä¸ªå…±äº«çš„3Dç¼–ç å™¨å’Œå¤šä¸ªæ•™å¸ˆä¸“ç”¨æŠ•å½±å™¨ï¼Œä»è¯­è¨€å¯¹é½ã€é€šç”¨å’Œç‰©ä½“æ„ŸçŸ¥çš„2Dæ•™å¸ˆæ¨¡å‹ä¸­æå–çŸ¥è¯†ï¼Œä»è€Œåœ¨å…±äº«åµŒå…¥ç©ºé—´ä¸­èåˆä»é«˜çº§è¯­ä¹‰åˆ°ç»†ç²’åº¦ç»“æ„çš„ä¿¡å·ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å°½ç®¡3Dé«˜æ–¯æ³¼æº…ï¼ˆ3DGSï¼‰å·²æˆä¸ºä¸€ç§é«˜ä¿çœŸåœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œä½†ç›´æ¥ä»å…¶åŸºå…ƒä¸­ç¼–ç ä¸°å¯Œã€é€šç”¨çš„ç‰¹å¾ä»æœªè¢«å……åˆ†æ¢ç´¢ã€‚æˆ‘ä»¬é€šè¿‡å¼•å…¥Chorusæ¥å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ•™å¸ˆé¢„è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡ä»2DåŸºç¡€æ¨¡å‹ä¸­æå–äº’è¡¥ä¿¡å·ï¼Œå­¦ä¹ ä¸€ä¸ªæ•´ä½“çš„å‰é¦ˆå¼3Dé«˜æ–¯æ³¼æº…åœºæ™¯ç¼–ç å™¨ã€‚Chorusé‡‡ç”¨å…±äº«çš„3Dç¼–ç å™¨å’Œç‰¹å®šäºæ•™å¸ˆçš„æŠ•å½±å™¨ï¼Œä»è¯­è¨€å¯¹é½ã€é€šç”¨å’Œå¯¹è±¡æ„ŸçŸ¥çš„æ•™å¸ˆä¸­å­¦ä¹ ï¼Œé¼“åŠ±å½¢æˆä¸€ä¸ªå…±äº«çš„åµŒå…¥ç©ºé—´ï¼Œè¯¥ç©ºé—´æ•è·ä»é«˜å±‚è¯­ä¹‰åˆ°ç»†â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17817v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17817.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ä¸‰ç»´å¤æ‚ç®¡é“ä¸­è‡ªæ¨è¿›å¼ç®¡é“æœºå™¨äººèˆªä½æ¨ç®—ç®—æ³•ç ”ç©¶</strong></p>
<p><em>Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code> | ğŸ“ å‡ºå¤„: <code>IEEE/ASME Transactions on Mechatronics æˆ– IEEE International Conference on Robotics and Automation (ICRA)</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§åŸºäºæƒ¯æ€§å¯¼èˆªä¸è½®å¼é‡Œç¨‹è®¡èåˆçš„è‡ªé©±åŠ¨ç®¡é“æœºå™¨äººå®šä½æ–¹æ³•ï¼Œä»¥è§£å†³å¤æ‚ä¸‰ç»´ç®¡é“ç¯å¢ƒä¸­ä¼ ç»Ÿå®šä½æ–¹æ³•ï¼ˆå¦‚è§†è§‰&#x2F;æ¿€å…‰ï¼‰å› å…‰ç…§ä¸è¶³ã€ç‰¹å¾ç¼ºå¤±å¯¼è‡´çš„å®šä½æ¼‚ç§»é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è®¾è®¡äº†ä¸€ç§è‡ªé©±åŠ¨ç®¡é“æœºå™¨äººï¼Œé€šè¿‡èåˆæƒ¯æ€§æµ‹é‡å•å…ƒï¼ˆIMUï¼‰ä¸è½®å¼é‡Œç¨‹è®¡çš„æ•°æ®ï¼Œåœ¨æ— éœ€å¤–éƒ¨æ‹–æ‹½çš„æƒ…å†µä¸‹ï¼Œå®ç°å¤æ‚å¼¯æ›²ç®¡é“å†…çš„è‡ªä¸»å®šä½ä¸åœ°å›¾æ„å»ºã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åœ¨ç‡ƒæ°”ç®¡é“å®šä½é¢†åŸŸï¼Œç°æœ‰ç®¡é“å®šä½æ–¹æ³•å¤šä¾èµ–ç®¡é“å®šä½ä»ªï¼Œä½†é¢å¯¹å¤æ‚å¼¯æ›²ç®¡é“åœºæ™¯æ—¶ï¼Œå¸¸å› çº¿ç¼†ç¼ ç»•ã€è®¾å¤‡çµæ´»æ€§ä¸è¶³ç­‰é—®é¢˜å¯¼è‡´å®šä½å¤±è´¥ã€‚é’ˆå¯¹è¿™ä¸€ç—›ç‚¹ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€æ¬¾è‡ªèµ°å¼ç®¡é“æœºå™¨äººã€‚è¯¥æœºå™¨äººæ— éœ€å¤–éƒ¨æ‹–æ‹½ï¼Œå³å¯åœ¨å¤æ‚ç®¡ç½‘ä¸­è‡ªä¸»å®Œæˆå¤æ‚å¼¯æ›²ç®¡é“çš„å®šä½å·¥ä½œã€‚åœ¨ç®¡é“å»ºå›¾æŠ€æœ¯æ–¹é¢ï¼Œä¼ ç»Ÿè§†è§‰å»ºå›¾ä¸æ¿€å…‰å»ºå›¾æ–¹æ³•æ˜“å—ç®¡é“ç‹­å°ç©ºé—´å†…å…‰ç…§æ¡ä»¶ã€ç‰¹å¾ä¸è¶³ç­‰å› ç´ å½±å“ï¼Œå¯¼è‡´å»ºå›¾æ¼‚ç§»ä¸å‘æ•£é—®é¢˜ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œèåˆæƒ¯æ€§å¯¼èˆªä¸è½®å¼é‡Œç¨‹è®¡çš„ç®¡â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17215v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17215.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ è‡ªé€‚åº”åæ–¹å·®ä¸å››å…ƒæ•°èšç„¦æ··åˆè¯¯å·®çŠ¶æ€EKF&#x2F;UKFçš„è§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡</strong></p>
<p><em>Adaptive Covariance and Quaternion-Focused Hybrid Error-State EKF&#x2F;UKF for Visual-Inertial Odometry</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code> | ğŸ“ å‡ºå¤„: <code>IEEE Robotics and Automation Letters (RA-L) æˆ– IROS (IEEE/RSJ International Conference on Intelligent Robots and Systems)ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆè¯¯å·®çŠ¶æ€EKF&#x2F;UKFæ¶æ„ï¼Œä¸“æ³¨äºå››å…ƒæ•°ä¼˜åŒ–ï¼Œå¹¶å¼•å…¥åŠ¨æ€ä¼ æ„Ÿå™¨ç½®ä¿¡åº¦è¯„åˆ†æœºåˆ¶ï¼Œä»¥æå‡æ— äººæœºè§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: åŸºäºæ¾è€¦åˆä¼ æ„Ÿå™¨èåˆæ¡†æ¶ï¼Œå…ˆä½¿ç”¨è¯¯å·®çŠ¶æ€æ‰©å±•å¡å°”æ›¼æ»¤æ³¢å™¨ä¼ æ’­æ•´ä½“çŠ¶æ€ï¼Œå†é’ˆå¯¹æ€§åœ°ä½¿ç”¨ç¼©æ”¾æ— è¿¹å¡å°”æ›¼æ»¤æ³¢å™¨ä»…ä¼˜åŒ–å§¿æ€ï¼Œä»è€Œå…¼é¡¾ç²¾åº¦ä¸è®¡ç®—æ•ˆç‡ï¼›åŒæ—¶é€šè¿‡å›¾åƒç†µç­‰æŒ‡æ ‡åŠ¨æ€è¯„ä¼°è§†è§‰æµ‹é‡å¯é æ€§ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æœ¬ç ”ç©¶æå‡ºä¸€ç§åˆ›æ–°çš„æ··åˆè§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡æ–¹æ³•ï¼Œé€‚ç”¨äºæ— äººæœºåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»å¯¼èˆªï¼Œè¯¥æ–¹æ³•å…·å¤‡ç¯å¢ƒæŠ—å¹²æ‰°èƒ½åŠ›å¹¶èƒ½åŠ¨æ€è¯„ä¼°ä¼ æ„Ÿå™¨å¯é æ€§ã€‚åŸºäºæ¾è€¦åˆä¼ æ„Ÿå™¨èåˆæ¶æ„ï¼Œç³»ç»Ÿé‡‡ç”¨æ–°å‹æ··åˆå››å…ƒæ•°è¯¯å·®çŠ¶æ€EKF&#x2F;UKFæ¶æ„å¤„ç†æƒ¯æ€§æµ‹é‡å•å…ƒæ•°æ®ï¼šå…ˆé€šè¿‡è¯¯å·®çŠ¶æ€æ‰©å±•å¡å°”æ›¼æ»¤æ³¢å™¨è¿›è¡Œå…¨çŠ¶æ€ä¼ æ’­ï¼Œå†é‡‡ç”¨å®šå‘ç¼©æ”¾æ— è¿¹å¡å°”æ›¼æ»¤æ³¢æ­¥éª¤ä¸“é—¨ä¼˜åŒ–å§¿æ€ä¼°è®¡ã€‚è¿™ç§åºåˆ—å¤„ç†æ–¹å¼æ—¢ä¿ç•™äº†æ— è¿¹å¡å°”æ›¼æ»¤æ³¢åœ¨å››å…ƒæ•°ä¼°è®¡ä¸Šçš„ç²¾åº¦ä¼˜åŠ¿ï¼Œåˆå…¼é¡¾äº†æ‰©å±•å¡â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17505v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17505.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TakeADï¼šåŸºäºä¸“å®¶æ¥ç®¡æ•°æ®çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶åå¥½åä¼˜åŒ–</strong></p>
<p><em>TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code> | ğŸ“ å‡ºå¤„: <code>CoRL 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºTakeADæ¡†æ¶ï¼Œé¦–æ¬¡åˆ©ç”¨è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿè„±é’©åœºæ™¯ä¸­çš„ä¸“å®¶æ¥ç®¡æ•°æ®ï¼Œé€šè¿‡åå¥½ä¼˜åŒ–å¯¹é¢„è®­ç»ƒçš„æ¨¡ä»¿å­¦ä¹ ç­–ç•¥è¿›è¡Œåä¼˜åŒ–ï¼Œä»¥è§£å†³å¼€ç¯è®­ç»ƒä¸é—­ç¯éƒ¨ç½²çš„é”™ä½é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ¡†æ¶åŒ…å«é«˜æ•ˆçš„ä¸“å®¶æ¥ç®¡æ•°æ®æ”¶é›†æµç¨‹ï¼Œå¹¶è¿­ä»£ç»“åˆæ•°æ®é›†èšåˆï¼ˆDAggerï¼‰è¿›è¡Œæ¨¡ä»¿å­¦ä¹ å’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰è¿›è¡Œç­–ç•¥å¾®è°ƒï¼Œä»¥æå‡é—­ç¯é©¾é©¶æ€§èƒ½ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç°æœ‰çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ–¹æ³•é€šå¸¸ä¾èµ–äºæ¨¡ä»¿å­¦ä¹ ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼šå¼€ç¯è®­ç»ƒä¸é—­ç¯éƒ¨ç½²ä¹‹é—´çš„ä¸åŒ¹é…ã€‚è¿™ç§ä¸åŒ¹é…å¾€å¾€å¯¼è‡´åœ¨é—­ç¯æ‰§è¡Œè¿‡ç¨‹ä¸­é¢‘ç¹è§¦å‘é©¾é©¶å‘˜æ¥ç®¡å’Œç³»ç»Ÿè„±ç¦»ã€‚å¦‚ä½•åˆ©ç”¨è¿™äº›è„±ç¦»åœºæ™¯ä¸­çš„ä¸“å®¶æ¥ç®¡æ•°æ®ï¼Œæœ‰æ•ˆæ‹“å±•æ¨¡ä»¿å­¦ä¹ ç­–ç•¥çš„èƒ½åŠ›ï¼Œæˆä¸ºä¸€ä¸ªæœ‰ä»·å€¼ä½†å°šæœªå……åˆ†æ¢ç´¢çš„è¯¾é¢˜ã€‚æœ¬æ–‡æå‡ºTakeADæ¡†æ¶â€”â€”ä¸€ç§åŸºäºåå¥½çš„åä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡è„±ç¦»æ•°æ®å¯¹é¢„è®­ç»ƒçš„æ¨¡ä»¿å­¦ä¹ ç­–ç•¥è¿›è¡Œå¾®è°ƒï¼Œä»¥æå‡é—­ç¯é©¾é©¶æ€§èƒ½ã€‚é¦–å…ˆï¼Œæˆ‘â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17370v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17370.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åˆ©ç”¨é¢„æµ‹æ€§å®‰å…¨è¡¨å¾å­¦ä¹ å®‰å…¨çš„è‡ªåŠ¨é©¾é©¶ç­–ç•¥</strong></p>
<p><em>Learning Safe Autonomous Driving Policies Using Predictive Safety Representations</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code> | ğŸ“ å‡ºå¤„: <code>ICLR 2025 æˆ– NeurIPS 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: å°†ç”¨äºå®‰å…¨å¼ºåŒ–å­¦ä¹ çš„é¢„æµ‹æ€§å®‰å…¨è¡¨ç¤ºï¼ˆSRPLï¼‰æ¡†æ¶ï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§åœ°åº”ç”¨äºçœŸå®ä¸–ç•Œè‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼ˆWaymoå’ŒNuPlanæ•°æ®é›†ï¼‰ï¼ŒéªŒè¯å…¶åœ¨æå‡æˆåŠŸç‡ä¸é™ä½å®‰å…¨æˆæœ¬æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä¸ºæ™ºèƒ½ä½“è£…å¤‡ä¸€ä¸ªé¢„æµ‹æœªæ¥çº¦æŸè¿åæƒ…å†µçš„æ¨¡å‹ï¼Œä»¥æ­¤åœ¨ä¼˜åŒ–é©¾é©¶æ€§èƒ½ï¼ˆå¥–åŠ±ï¼‰ä¸æ»¡è¶³ä¸¥æ ¼å®‰å…¨è¦æ±‚ä¹‹é—´å–å¾—æ›´å¥½å¹³è¡¡ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å®‰å…¨å¼ºåŒ–å­¦ä¹ ï¼ˆSafeRLï¼‰æ˜¯è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„é‡è¦èŒƒå¼ï¼Œè¦æ±‚æ™ºèƒ½ä½“åœ¨ä¸¥æ ¼çš„å®‰å…¨çº¦æŸä¸‹ä¼˜åŒ–æ€§èƒ½ã€‚è¿™ç§åŒé‡ç›®æ ‡å½¢æˆäº†æ ¹æœ¬æ€§å¼ åŠ›ï¼šè¿‡åº¦ä¿å®ˆçš„ç­–ç•¥ä¼šé™åˆ¶é©¾é©¶æ•ˆç‡ï¼Œè€Œæ¿€è¿›çš„æ¢ç´¢åˆ™å¯èƒ½å±åŠå®‰å…¨ã€‚å®‰å…¨è¡¨å¾ç­–ç•¥å­¦ä¹ æ¡†æ¶é€šè¿‡ä¸ºæ™ºèƒ½ä½“é…å¤‡æœªæ¥çº¦æŸè¿åé¢„æµ‹æ¨¡å‹æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œå¹¶åœ¨å—æ§ç¯å¢ƒä¸­å±•ç°å‡ºæ½œåŠ›ã€‚æœ¬æ–‡æ¢ç©¶è¯¥æ¡†æ¶èƒ½å¦æ‹“å±•è‡³çœŸå®ä¸–ç•Œè‡ªåŠ¨é©¾é©¶åœºæ™¯ã€‚åŸºäºWaymoå¼€æ”¾è¿åŠ¨æ•°æ®é›†å’ŒNuPlanå¹³å°çš„ç³»ç»Ÿå®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ”¹å–„â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17586v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17586.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ StereoMV2Dï¼šä¸€ç§ç”¨äºé²æ£’å¤šè§†è§’ä¸‰ç»´ç›®æ ‡æ£€æµ‹çš„ç¨€ç–æ—¶åºç«‹ä½“å¢å¼ºæ¡†æ¶</strong></p>
<p><em>StereoMV2D: A Sparse Temporal Stereo-Enhanced Framework for Robust Multi-View 3D Object Detection</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ECCV 2024ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºStereoMV2Dæ¡†æ¶ï¼Œå°†æ—¶åºç«‹ä½“å»ºæ¨¡å¼•å…¥åŸºäº2Dæ£€æµ‹å¼•å¯¼çš„å¤šè§†è§’3Dæ£€æµ‹å™¨ï¼Œé€šè¿‡åˆ©ç”¨ç›¸é‚»å¸§é—´åŒä¸€ç›®æ ‡çš„è·¨æ—¶åºè§†å·®æ¥å¢å¼ºæ·±åº¦æ„ŸçŸ¥å¹¶ä¼˜åŒ–æŸ¥è¯¢å…ˆéªŒï¼Œä»è€Œè§£å†³å•å¸§2Dæ£€æµ‹å›ºæœ‰çš„æ·±åº¦æ¨¡ç³Šé—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ¡†æ¶åœ¨MV2DåŸºç¡€ä¸Šï¼Œåˆ©ç”¨2Dæ£€æµ‹ç»“æœä¸ºå¯å­¦ä¹ æŸ¥è¯¢åˆå§‹åŒ–æä¾›é«˜è´¨é‡ç›®æ ‡å…ˆéªŒï¼Œå¹¶é€šè¿‡é›†æˆæ—¶åºç«‹ä½“ä¿¡æ¯æ¥æå‡æ·±åº¦ä¼°è®¡ç²¾åº¦ï¼Œæœ€ç»ˆå®ç°ç«¯åˆ°ç«¯çš„3Dç›®æ ‡æ£€æµ‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å¤šè§†è§’ä¸‰ç»´ç›®æ ‡æ£€æµ‹æ˜¯è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ä¸­çš„ä¸€é¡¹åŸºç¡€ä»»åŠ¡ï¼Œåœ¨æ£€æµ‹ç²¾åº¦ä¸è®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡è‡³å…³é‡è¦ã€‚åŸºäºç¨€ç–æŸ¥è¯¢çš„ä¸‰ç»´æ£€æµ‹å™¨é€šè¿‡ä¸€ç»„å¯å­¦ä¹ çš„æŸ¥è¯¢ï¼Œé«˜æ•ˆèšåˆå¤šè§†è§’å›¾åƒä¸­ä¸ç›®æ ‡ç›¸å…³çš„ç‰¹å¾ï¼Œæä¾›äº†ä¸€ç§ç®€æ´çš„ç«¯åˆ°ç«¯æ£€æµ‹èŒƒå¼ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼ŒMV2Dåˆ©ç”¨äºŒç»´æ£€æµ‹ç»“æœä¸ºæŸ¥è¯¢åˆå§‹åŒ–æä¾›é«˜è´¨é‡çš„ç›®æ ‡å…ˆéªŒï¼Œå®ç°äº†æ›´é«˜çš„ç²¾ç¡®ç‡ä¸å¬å›ç‡ã€‚ç„¶è€Œï¼Œå•å¸§äºŒç»´æ£€æµ‹å›ºæœ‰çš„æ·±åº¦æ¨¡ç³Šæ€§ä»é™åˆ¶ç€ä¸‰ç»´æŸ¥è¯¢ç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºSteâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17620v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17620.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ OntoGSNï¼šåŸºäºæœ¬ä½“çš„ä¿éšœæ¡ˆä¾‹è¯­ä¹‰ç®¡ç†ä¸æ‰©å±•æ¡†æ¶</strong></p>
<p><em>OntoGSN: An Ontology-Based Framework for Semantic Management and Extension of Assurance Cases</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code> | ğŸ“ å‡ºå¤„: <code>å¯èƒ½å‘è¡¨äºè½¯ä»¶å·¥ç¨‹æˆ–å½¢å¼åŒ–æ–¹æ³•é¢†åŸŸçš„é¡¶çº§ä¼šè®®/æœŸåˆŠï¼Œå¦‚ICSEï¼ˆå›½é™…è½¯ä»¶å·¥ç¨‹å¤§ä¼šï¼‰ã€FSEï¼ˆè½¯ä»¶å·¥ç¨‹åŸºç¡€å¤§ä¼šï¼‰ã€IEEE Transactions on Software Engineeringæˆ–Journal of Systems and Softwareã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åŸºäºæœ¬ä½“çš„æ¡†æ¶ï¼ˆOntoGSNï¼‰ï¼Œç”¨äºå¯¹é‡‡ç”¨ç›®æ ‡ç»“æ„ç¬¦å·ï¼ˆGSNï¼‰æ ‡å‡†çš„ä¿è¯æ¡ˆä¾‹è¿›è¡Œè¯­ä¹‰åŒ–ç®¡ç†å’ŒåŠ¨æ€æ‰©å±•ï¼Œæ—¨åœ¨è§£å†³ä¿è¯æ¡ˆä¾‹åœ¨å˜æ›´ç®¡ç†ä¸­çŸ¥è¯†ç»´æŠ¤å›°éš¾çš„é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ ¸å¿ƒæ˜¯æ„å»ºäº†ä¸€ä¸ªä¸GSNç¤¾åŒºæ ‡å‡†v3ä¸¥æ ¼å¯¹åº”çš„OWLæœ¬ä½“ï¼Œå¹¶è¾…ä»¥SWRLè§„åˆ™å’Œè¾…åŠ©æœ¬ä½“ï¼Œæä¾›äº†ä¸€ä¸ªå¯è‡ªåŠ¨å¡«å……ã€è¯„ä¼°å’Œæ›´æ–°çš„çŸ¥è¯†è¡¨ç¤ºä¸å¯æŸ¥è¯¢å›¾ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ä¿è¯æ¡ˆä¾‹ï¼ˆACsï¼‰æ˜¯å»ºç«‹å’Œç»´æŠ¤å¯¹ç³»ç»Ÿå±æ€§ï¼ˆå¦‚å®‰å…¨æ€§æˆ–é²æ£’æ€§ï¼‰ä¿¡å¿ƒçš„å¸¸è§å·¥å…·ã€‚å°½ç®¡ç°æœ‰å·¥å…·åœ¨é™æ€ã€ä»¥æ–‡æ¡£ä¸ºä¸­å¿ƒçš„åº”ç”¨ä¸­æä¾›æ”¯æŒï¼Œä¸”é’ˆå¯¹åŠ¨æ€ç¯å¢ƒï¼ˆä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ï¼‰çš„æ–¹æ³•æ­£åœ¨å…´èµ·ï¼Œä½†æ„å»ºACä»å…·æŒ‘æˆ˜æ€§ã€‚é—æ†¾çš„æ˜¯ï¼Œç®¡ç†ACsä¾ç„¶å›°éš¾é‡é‡ï¼Œå› ä¸ºé¢å¯¹å˜æ›´æ—¶ç»´æŠ¤å…¶ä¸­åµŒå…¥çš„çŸ¥è¯†éœ€è¦å¤§é‡åŠªåŠ›ï¼Œè¿™ä¸€è¿‡ç¨‹é˜»ç¢äº†å¼€å‘è€…çš„ç§¯ææ€§ï¼Œç”šè‡³å¯èƒ½å¯¼è‡´ç®¡ç†ä¸å–„çš„æ¡ˆä¾‹æ»‹ç”Ÿè™šå‡ä¿¡å¿ƒã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†OntoGSNï¼šä¸€ä¸ªåŸºäºç›®æ ‡ç»“â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.11023v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.11023.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PhysFire-WMï¼šä¸€ç§ç”¨äºæ¨¡æ‹Ÿç«ç¾è”“å»¶åŠ¨æ€çš„ç‰©ç†ä¿¡æ¯ä¸–ç•Œæ¨¡å‹</strong></p>
<p><em>PhysFire-WM: A Physics-Informed World Model for Emulating Fire Spread Dynamics</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ICLR 2025ï¼ˆå› å…¶ç»“åˆäº†è®¡ç®—æœºè§†è§‰ã€ç‰©ç†å»ºæ¨¡ä¸ç”Ÿæˆæ¨¡å‹ï¼Œä¸”æ–¹æ³•å…·æœ‰åˆ›æ–°æ€§ï¼Œé€‚åˆé¡¶çº§AIä¼šè®®ï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§èåˆç‰©ç†å…ˆéªŒçš„ä¸–ç•Œæ¨¡å‹PhysFire-WMï¼Œé€šè¿‡å¼•å…¥ç‰©ç†æ¨¡æ‹Ÿå™¨çš„ç»“æ„åŒ–å…ˆéªŒæ¥çº æ­£ç‰©ç†ä¸ä¸€è‡´æ€§ï¼Œå¹¶è®¾è®¡äº†è·¨ä»»åŠ¡ååŒè®­ç»ƒç­–ç•¥ä»¥æ•´åˆçƒ­è¾å°„å’Œè¾¹ç•Œä¿¡æ¯ï¼Œæå‡äº†ç«ç¾è”“å»¶åŠ¨æ€æ¨¡æ‹Ÿçš„å‡†ç¡®æ€§ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ ¸å¿ƒæ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªç¼–ç ç‰©ç†æ¨¡æ‹Ÿå™¨å…ˆéªŒçŸ¥è¯†ä»¥ä¿®æ­£ç‰©ç†åå·®çš„æ¨¡å—ï¼Œä»¥åŠä¸€ä¸ªé€šè¿‡å‚æ•°å…±äº«å’Œæ¢¯åº¦åè°ƒæ¥ååŒè®­ç»ƒçº¢å¤–å›¾åƒä¸ç«ç¾æ©ç ä»»åŠ¡çš„ç­–ç•¥ï¼Œä»è€Œå…±åŒå­¦ä¹ ç«ç¾çš„çƒ­åŠ›å­¦å’Œç©ºé—´è¾¹ç•ŒåŠ¨æ€ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç»†ç²’åº¦ç«ç¾é¢„æµ‹åœ¨åº”æ€¥å“åº”ä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ã€‚çº¢å¤–å›¾åƒä¸ç«ç¾æ©è†œè™½èƒ½æä¾›äº’è¡¥çš„çƒ­è¾å°„ä¸è¾¹ç•Œä¿¡æ¯ï¼Œä½†ç°æœ‰æ–¹æ³•å¤šå±€é™äºäºŒå€¼æ©è†œå»ºæ¨¡ï¼Œå…¶å›ºæœ‰çš„ä¿¡å·ç¨€ç–æ€§éš¾ä»¥æ•æ‰ç«ç¾çš„å¤æ‚åŠ¨æ€ã€‚ä¸–ç•Œæ¨¡å‹åœ¨è§†é¢‘ç”Ÿæˆé¢†åŸŸå±•ç°å‡ºæ½œåŠ›ï¼Œä½†å…¶ç‰©ç†ä¸ä¸€è‡´æ€§ä¸ºç«ç¾é¢„æµ‹å¸¦æ¥æ˜¾è‘—æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºPhysFire-WMâ€”â€”ä¸€ç§èåˆç‰©ç†çŸ¥è¯†çš„ç«ç¾è”“å»¶åŠ¨æ€ä»¿çœŸä¸–ç•Œæ¨¡å‹ã€‚è¯¥æ–¹æ³•é€šè¿‡ç¼–ç ç‰©ç†æ¨¡æ‹Ÿå™¨çš„ç»“æ„åŒ–å…ˆéªŒçŸ¥è¯†æ¥ä¿®æ­£ç‰©ç†åå·®ï¼Œä»è€Œå†…åŒ–ç‡ƒçƒ§åŠ¨åŠ›å­¦æœºåˆ¶ï¼›åŒâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17152v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17152.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºä»£è¡¨æ€§æ½œåœ¨ä¸–ç•Œæ¨¡å‹çš„é«˜æ•ˆå›¾åƒç›®æ ‡å¯¼èˆª</strong></p>
<p><em>Efficient Image-Goal Navigation with Representative Latent World Model</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åœ¨é«˜çº§è¯­ä¹‰è¡¨å¾çš„éšç©ºé—´ä¸­è¿›è¡Œé¢„æµ‹å’Œè§„åˆ’çš„å¯¼èˆªä¸–ç•Œæ¨¡å‹ï¼ˆReL-NWMï¼‰ï¼Œæ‘’å¼ƒäº†ä¼ ç»Ÿæ–¹æ³•ä¸­è®¡ç®—å¯†é›†çš„åƒç´ çº§é‡å»ºï¼Œå®ç°äº†é«˜æ•ˆå¯¼èˆªã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„DINOv3ç¼–ç å™¨æ„å»ºè¡¨å¾éšç©ºé—´ï¼Œå¹¶è®¾è®¡äº†ä¸“é—¨çš„æœºåˆ¶åœ¨è¯¥ç©ºé—´ä¸­èåˆåŠ¨ä½œä¿¡å·å’Œå†å²ä¸Šä¸‹æ–‡ï¼Œä»è€Œå®Œå…¨åœ¨éšç©ºé—´å†…å®Œæˆè§„åˆ’ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ä¸–ç•Œæ¨¡å‹ä½¿æœºå™¨äººèƒ½å¤Ÿé€šè¿‡é¢„æµ‹æœªæ¥ä¸–ç•ŒçŠ¶æ€åœ¨ç‰©ç†ç¯å¢ƒä¸­è¿›è¡Œåäº‹å®æ¨ç†ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä¼˜å…ˆè€ƒè™‘æœªæ¥åœºæ™¯çš„åƒç´ çº§é‡å»ºï¼Œä½†è¿™ç§ç²¾ç»†æ¸²æŸ“è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œå¯¹äºå¯¼èˆªç­‰è§„åˆ’ä»»åŠ¡å¹¶éå¿…éœ€ã€‚å› æ­¤æˆ‘ä»¬æå‡ºï¼Œé¢„æµ‹å’Œè§„åˆ’å¯ä»¥ç›´æ¥åœ¨é«˜å±‚è¯­ä¹‰è¡¨å¾çš„æ½œåœ¨ç©ºé—´ä¸­é«˜æ•ˆæ‰§è¡Œã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºäº†è¡¨å¾æ½œåœ¨ç©ºé—´å¯¼èˆªä¸–ç•Œæ¨¡å‹ï¼ˆReL-NWMï¼‰ã€‚è¯¥æ–¹æ³•ä¸ä¾èµ–é‡å»ºå¯¼å‘çš„æ½œåœ¨åµŒå…¥ï¼Œè€Œæ˜¯åˆ©ç”¨é¢„è®­ç»ƒè¡¨å¾ç¼–ç å™¨DINOv3ï¼Œå¹¶å¼•å…¥ä¸“é—¨æœºåˆ¶åœ¨æ­¤è¡¨å¾ç©ºé—´â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.11011v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.11011.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ é€šè¿‡è¾“å…¥é¢„æµ‹ä¸å¤±è¯¯ä¿®æ­£åŠ é€Ÿå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ¸¸æˆæ€§èƒ½</strong></p>
<p><em>Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code> | ğŸ“ å‡ºå¤„: <code>ICLR 2025 æˆ– NeurIPS 2025ï¼ˆè®ºæ–‡èšç„¦å¼ºåŒ–å­¦ä¹ ä¸æ¨¡å‹é¢„æµ‹æ§åˆ¶çš„äº¤å‰é¢†åŸŸï¼Œæ–¹æ³•å…·æœ‰ç†è®ºåˆ›æ–°å’Œå®éªŒéªŒè¯ï¼Œç¬¦åˆé¡¶çº§æœºå™¨å­¦ä¹ ä¼šè®®çš„å½•ç”¨æ ‡å‡†ï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§â€œæ¨æµ‹ä¸ä¿®æ­£â€æ¡†æ¶ï¼Œå°†æ¨æµ‹æ‰§è¡Œçš„â€œé¢„æµ‹-éªŒè¯â€æ€æƒ³åº”ç”¨äºåŸºäºæ¨¡å‹çš„å®æ—¶æ§åˆ¶ï¼Œé€šè¿‡é¢„æµ‹åŠ¨ä½œé˜Ÿåˆ—å’Œè½»é‡çº§ä¿®æ­£æ¥å‡å°‘è§„åˆ’å»¶è¿Ÿï¼Œæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨æ¸¸æˆä¸­çš„å®æ—¶æ§åˆ¶æ€§èƒ½ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ ¸å¿ƒæ¡†æ¶åŒ…å«ä¸‰æ­¥ï¼š1ï¼‰åˆ©ç”¨é¢„è®­ç»ƒä¸–ç•Œæ¨¡å‹å’Œæ½œåœ¨ç©ºé—´è§„åˆ’å™¨ç”ŸæˆçŸ­è§†ç•ŒåŠ¨ä½œé˜Ÿåˆ—åŠæ½œåœ¨çŠ¶æ€é¢„æµ‹ï¼›2ï¼‰æ–°è§‚æµ‹åˆ°è¾¾æ—¶ï¼Œé€šè¿‡ç¼–ç çœŸå®æ½œåœ¨çŠ¶æ€ä¸é¢„æµ‹çŠ¶æ€çš„å·®å¼‚è§¦å‘ä¿®æ­£æœºåˆ¶ï¼›3ï¼‰å·®å¼‚è¾ƒå°æ—¶ä½¿ç”¨è½»é‡çº§å­¦ä¹ ä¿®æ­£å™¨è°ƒæ•´åŠ¨ä½œï¼Œå·®å¼‚è¿‡å¤§æ—¶å›é€€åˆ°å®Œæ•´é‡è§„åˆ’ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å®æ—¶åºåˆ—æ§åˆ¶æ™ºèƒ½ä½“å¸¸å—é™äºæ¨ç†å»¶è¿Ÿã€‚å³ä½¿æ¯æ­¥è§„åˆ’å­˜åœ¨å¾®å°å»¶è¿Ÿï¼Œä¹Ÿå¯èƒ½ç ´åæ§åˆ¶ç¨³å®šæ€§å¹¶é™ä½æ•´ä½“æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºä¸€ç§æ¨æµ‹-æ ¡æ­£æ¡†æ¶ï¼Œå°†æ¨æµ‹æ‰§è¡Œçš„â€é¢„æµ‹åéªŒè¯â€ç†å¿µé€‚é…äºåŸºäºTD-MPC2çš„æ¨¡å‹æ§åˆ¶ã€‚åœ¨æ¯ä¸ªæ—¶é—´æ­¥ï¼Œé¢„è®­ç»ƒçš„ä¸–ç•Œæ¨¡å‹ä¸æ½œåœ¨ç©ºé—´MPCè§„åˆ’å™¨ååŒç”ŸæˆçŸ­æ—¶åŸŸåŠ¨ä½œé˜Ÿåˆ—åŠå¯¹åº”çš„æ½œåœ¨çŠ¶æ€é¢„æµ‹è½¨è¿¹ï¼Œä½¿æ™ºèƒ½ä½“æ— éœ€å³æ—¶é‡è§„åˆ’å³å¯æ‰§è¡Œå¤šä¸ªè§„åˆ’åŠ¨ä½œã€‚å½“æ–°è§‚æµ‹åˆ°è¾¾æ—¶ï¼Œç³»ç»Ÿæµ‹é‡ç¼–ç åçš„çœŸå®æ½œåœ¨çŠ¶æ€ä¸é˜Ÿåˆ—ä¸­é¢„æµ‹æ½œåœ¨çŠ¶æ€â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17250v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17250.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ çµå·§ä¸–ç•Œæ¨¡å‹</strong></p>
<p><em>Dexterous World Models</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 / ICCV 2025 / arXiv preprint</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºDexterous World Model (DWM)ï¼Œä¸€ä¸ªåœºæ™¯-åŠ¨ä½œæ¡ä»¶åŒ–çš„è§†é¢‘æ‰©æ•£æ¡†æ¶ï¼Œç”¨äºå»ºæ¨¡çµå·§äººæ‰‹åŠ¨ä½œå¦‚ä½•é©±åŠ¨é™æ€3Dåœºæ™¯äº§ç”ŸåŠ¨æ€äº¤äº’å˜åŒ–ï¼Œä»è€Œä¸ºæ•°å­—å­ªç”Ÿç¯å¢ƒæ³¨å…¥å…·èº«äº¤äº’èƒ½åŠ›ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•ä»¥é™æ€3Dåœºæ™¯æ¸²æŸ“å›¾å’Œä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„æ‰‹éƒ¨è¿åŠ¨åºåˆ—ä½œä¸ºæ¡ä»¶ï¼Œé€šè¿‡è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ—¶åºè¿è´¯ã€äº¤äº’åˆç†çš„äºº-åœºæ™¯äº¤äº’è§†é¢‘ï¼Œå…¶æ ¸å¿ƒåœ¨äºåˆ©ç”¨åœºæ™¯æ¸²æŸ“ä¿è¯ç©ºé—´ä¸€è‡´æ€§ï¼Œå¹¶åˆ©ç”¨æ‰‹éƒ¨ç½‘æ ¼æ¸²æŸ“ç¼–ç å‡ ä½•ä¸è¿åŠ¨ä¿¡æ¯ä»¥ç›´æ¥å»ºæ¨¡åŠ¨ä½œé©±åŠ¨çš„åŠ¨æ€ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ä¸‰ç»´é‡å»ºé¢†åŸŸçš„æœ€æ–°è¿›å±•ä½¿å¾—ä»æ—¥å¸¸ç¯å¢ƒä¸­åˆ›å»ºé€¼çœŸçš„æ•°å­—å­ªç”Ÿä½“å˜å¾—è½»è€Œæ˜“ä¸¾ã€‚ç„¶è€Œï¼Œå½“å‰æ•°å­—å­ªç”Ÿä½“å¤§å¤šä¿æŒé™æ€ï¼Œä»…é™äºå¯¼èˆªå’Œè§†å›¾åˆæˆï¼Œç¼ºä¹å…·èº«äº¤äº’èƒ½åŠ›ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€ä¸è¶³ï¼Œæˆ‘ä»¬æå‡ºäº†çµå·§ä¸–ç•Œæ¨¡å‹â€”â€”ä¸€ç§åœºæ™¯-åŠ¨ä½œæ¡ä»¶åŒ–çš„è§†é¢‘æ‰©æ•£æ¡†æ¶ï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿçµå·§äººç±»è¡Œä¸ºå¦‚ä½•å¼•å‘é™æ€ä¸‰ç»´åœºæ™¯çš„åŠ¨æ€å˜åŒ–ã€‚ç»™å®šé™æ€ä¸‰ç»´åœºæ™¯æ¸²æŸ“ç»“æœä¸ç¬¬ä¸€äººç§°æ‰‹éƒ¨è¿åŠ¨åºåˆ—ï¼Œè¯¥æ¨¡å‹å¯ç”Ÿæˆæ—¶é—´è¿è´¯çš„è§†é¢‘ï¼Œæç»˜åˆç†çš„äºº-åœºæ™¯äº¤äº’è¿‡ç¨‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä»¥ä¸‹ä¸¤â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17907v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17907.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ éšå½¢å¨èƒï¼šæ¢ç´¢å¹¶å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹å¯¹æŠ—ç‰©ç†ä¼ æ„Ÿå™¨æ”»å‡»çš„é²æ£’æ€§</strong></p>
<p><em>Phantom Menace: Exploring and Enhancing the Robustness of VLA Models Against Physical Sensor Attacks</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: é¦–æ¬¡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†é’ˆå¯¹è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„ç‰©ç†ä¼ æ„Ÿå™¨æ”»å‡»ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªâ€œçœŸå®-æ¨¡æ‹Ÿ-çœŸå®â€æ¡†æ¶æ¥è‡ªåŠ¨ç”Ÿæˆå’ŒéªŒè¯æ”»å‡»å‘é‡ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸå®‰å…¨ç ”ç©¶çš„ç©ºç™½ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æå‡ºäº†ä¸€ä¸ªâ€œçœŸå®-æ¨¡æ‹Ÿ-çœŸå®â€æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½è‡ªåŠ¨æ¨¡æ‹Ÿé’ˆå¯¹æ‘„åƒå¤´å’Œéº¦å…‹é£çš„ç‰©ç†ä¼ æ„Ÿå™¨æ”»å‡»ï¼Œå¹¶åœ¨çœŸå®æœºå™¨äººç³»ç»Ÿä¸Šè¿›è¡ŒéªŒè¯ï¼Œä»¥é‡åŒ–æ”»å‡»å½±å“å¹¶æ¢ç´¢é˜²å¾¡æ–¹æ³•ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹é€šè¿‡æ„å»ºç«¯åˆ°ç«¯çš„æ„ŸçŸ¥-è¡ŒåŠ¨æµç¨‹ï¼Œæ•´åˆäº†å¤šç§æ„Ÿå®˜æ¨¡æ€ï¼ˆå¦‚æ‘„åƒå¤´å¤„ç†çš„è§†è§‰ä¿¡å·å’Œéº¦å…‹é£æ•è·çš„å¬è§‰ä¿¡å·ï¼‰ï¼Œä»è€Œå½»åº•é©æ–°äº†æœºå™¨äººç³»ç»Ÿã€‚è¿™ç§å¤šæ¨¡æ€èåˆä½¿VLAæ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨å¤šæ ·åŒ–çš„ä¼ æ„Ÿå™¨æ•°æ®æµæ¥è§£æå¤æ‚çš„ç°å®ç¯å¢ƒã€‚é‰´äºVLAç³»ç»Ÿé«˜åº¦ä¾èµ–æ„Ÿå®˜è¾“å…¥ï¼Œå…¶åœ¨ç‰©ç†ä¸–ç•Œä¼ æ„Ÿå™¨æ”»å‡»ä¸‹çš„å®‰å…¨æ€§ç ”ç©¶ä»å­˜åœ¨æ˜¾è‘—ç©ºç™½ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬é¦–æ¬¡ç³»ç»Ÿç ”ç©¶äº†é’ˆå¯¹VLAçš„ç‰©ç†ä¼ æ„Ÿå™¨æ”»å‡»ï¼Œé‡åŒ–äº†ä¼ æ„Ÿå™¨æ”»å‡»çš„å½±å“â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.10008v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.10008.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MiVLAï¼šè¿ˆå‘é€šç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼šåŸºäºäººæœºäº’æ¨¡ä»¿é¢„è®­ç»ƒ</strong></p>
<p><em>MiVLA: Towards Generalizable Vision-Language-Action Model with Human-Robot Mutual Imitation Pre-training</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºMiVLAæ¨¡å‹ï¼Œé€šè¿‡äººç±»ä¸æœºå™¨äººä¹‹é—´çš„â€œåŒå‘æ¨¡ä»¿â€é¢„è®­ç»ƒï¼Œåˆ©ç”¨äººæ‰‹ä¸æœºæ¢°è‡‚çš„è¡Œä¸ºç›¸ä¼¼æ€§æ¥æ„å»ºé€šç”¨çš„è¡Œä¸ºå…ˆéªŒï¼Œä»¥è§£å†³ç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨è§†è§’ã€å¤–è§‚å’Œå½¢æ€å·®å¼‚ä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•åŸºäºå·¦å³æ‰‹åæ ‡ç³»å’Œè¿åŠ¨å­¦è§„åˆ™ï¼Œåœ¨äººç±»ä¸æœºå™¨äººåŠ¨ä½œç©ºé—´ä¹‹é—´è¿›è¡ŒåŒå‘å¯¹é½ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®äººç±»æˆ–ä»¿çœŸæœºå™¨äººæ¼”ç¤ºï¼Œé¢„æµ‹ä¸€ç§å½¢æ€çš„è¡Œä¸ºè½¨è¿¹å¹¶æ¨¡ä»¿å¦ä¸€ç§æœªè§è¿‡çš„å½¢æ€çš„è¡Œä¸ºã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åœ¨åˆ©ç”¨ä¸°å¯Œçš„äººç±»è§†é¢‘å’Œæ¨¡æ‹Ÿæœºå™¨äººæ•°æ®ä»¥è§£å†³çœŸå®ä¸–ç•Œæœºå™¨äººæ•°æ®ç¨€ç¼ºé—®é¢˜çš„åŒæ—¶ï¼Œç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼ˆVLAsï¼‰çš„æ³›åŒ–èƒ½åŠ›ä»å—é™äºç›¸æœºè§†è§’ã€è§†è§‰å¤–è§‚å’Œå…·èº«å½¢æ€çš„å·®å¼‚ã€‚ä¸ºçªç ´è¿™ä¸€å±€é™ï¼Œæˆ‘ä»¬æå‡ºMiVLAâ€”â€”ä¸€ç§é€šè¿‡äººæœºäº’æ¨¡ä»¿é¢„è®­ç»ƒå¢å¼ºçš„é€šç”¨åŒ–VLAæ¨¡å‹ã€‚è¯¥æ–¹æ³•åˆ©ç”¨äººæ‰‹ä¸æœºæ¢°è‡‚ä¹‹é—´å›ºæœ‰çš„è¡Œä¸ºç›¸ä¼¼æ€§ï¼Œä¸ºäººç±»åŠ¨ä½œå’Œæœºå™¨äººæ§åˆ¶æ„å»ºäº†å¼ºå¤§çš„è¡Œä¸ºå…ˆéªŒåŸºç¡€ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é€šè¿‡å·¦å³æ‰‹åæ ‡ç³»ä¸‹çš„è¿åŠ¨å­¦è§„åˆ™ï¼Œå®ç°äººç±»ä¸â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15411v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15411.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹å‰–æï¼šä»æ¨¡å—æ„æˆåˆ°é‡Œç¨‹ç¢‘ä¸æŒ‘æˆ˜</strong></p>
<p><em>An Anatomy of Vision-Language-Action Models: From Modules to Milestones and Challenges</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprintã€‚è¿™æ˜¯ä¸€ç¯‡é¢†åŸŸç»¼è¿°è®ºæ–‡ï¼Œå†…å®¹å…¨é¢ä¸”ç»“æ„æ¸…æ™°ï¼Œæ—¨åœ¨æ¢³ç†çˆ†ç‚¸å¼å¢é•¿çš„VLAç ”ç©¶ç°çŠ¶ï¼Œå…¶å½¢å¼å’Œç›®æ ‡ä¸åœ¨arXivä¸Šå¿«é€Ÿå‘å¸ƒçš„ç»¼è¿°æ–‡ç« é«˜åº¦å»åˆã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æœ¬æ–‡çš„ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºä¸ºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹é¢†åŸŸæä¾›äº†ä¸€ä¸ªæ¸…æ™°ã€ç»“æ„åŒ–çš„ç»¼è¿°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒè´¡çŒ®æ˜¯å°†è¯¥é¢†åŸŸçš„å‘å±•è·¯å¾„ç³»ç»Ÿæ€§åœ°åˆ†è§£ä¸ºâ€œæ¨¡å—-é‡Œç¨‹ç¢‘-æŒ‘æˆ˜â€ä¸‰ä¸ªå±‚æ¬¡ï¼Œå¹¶é‡ç‚¹å‰–æäº†è¡¨å¾ã€æ‰§è¡Œã€æ³›åŒ–ã€å®‰å…¨ã€æ•°æ®é›†ä¸è¯„ä¼°è¿™äº”å¤§æ ¸å¿ƒæŒ‘æˆ˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è®ºæ–‡æå‡ºäº†ä¸€ä¸ªä»¥ç ”ç©¶è€…å­¦ä¹ è·¯å¾„ä¸ºå¯¼å‘çš„åˆ†ææ¡†æ¶ï¼šé¦–å…ˆè§£æVLAæ¨¡å‹çš„åŸºç¡€æ„æˆæ¨¡å—ï¼Œå…¶æ¬¡æ¢³ç†å…¶å‘å±•å†ç¨‹ä¸­çš„å…³é”®é‡Œç¨‹ç¢‘ï¼Œæœ€åæ·±å…¥æ¢è®¨å®šä¹‰å½“å‰ç ”ç©¶å‰æ²¿çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹æ­£åœ¨æ¨åŠ¨æœºå™¨äººæŠ€æœ¯çš„é©å‘½ï¼Œä½¿æœºå™¨èƒ½å¤Ÿç†è§£æŒ‡ä»¤å¹¶ä¸ç‰©ç†ä¸–ç•Œäº’åŠ¨ã€‚è¯¥é¢†åŸŸæ­£æ¶Œç°å¤§é‡æ–°æ¨¡å‹ä¸æ•°æ®é›†ï¼Œæ—¢ä»¤äººæŒ¯å¥‹åˆä½¿è·Ÿè¿›ç ”ç©¶å……æ»¡æŒ‘æˆ˜ã€‚æœ¬ç»¼è¿°ä¸ºVLAé¢†åŸŸæä¾›äº†æ¸…æ™°çš„ç»“æ„åŒ–æŒ‡å—ã€‚æˆ‘ä»¬æŒ‰ç…§ç ”ç©¶è€…çš„è‡ªç„¶å­¦ä¹ è·¯å¾„è®¾è®¡æ¡†æ¶ï¼šä»VLAæ¨¡å‹çš„åŸºç¡€æ¨¡å—å‡ºå‘ï¼Œè¿½æº¯å…³é”®é‡Œç¨‹ç¢‘å‘å±•å†ç¨‹ï¼Œç»§è€Œæ·±å…¥å‰–æç•Œå®šå‰æ²¿ç ”ç©¶çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®åœ¨äºå¯¹äº”å¤§æŒ‘æˆ˜çš„ç»†è‡´è§£æ„ï¼šï¼ˆ1ï¼‰è¡¨å¾å­¦ä¹ ï¼Œï¼ˆ2ï¼‰åŠ¨ä½œæ‰§è¡Œï¼Œï¼ˆ3â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11362v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11362.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ æ¨¡ä»¿è§†é¢‘ï¼šè¶…è¶Šè§†è§‰è¯­è¨€æ¨¡å‹çš„é€šç”¨æœºå™¨äººæ§åˆ¶è§†é¢‘åŠ¨ä½œæ¨¡å‹</strong></p>
<p><em>mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ICLR 2025ï¼ˆè‹¥æœªæ­£å¼å‘è¡¨ï¼Œå¯èƒ½å…ˆä»¥ arXiv preprint å½¢å¼å‘å¸ƒï¼‰</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§åä¸º mimic-video çš„æ–°å‹è§†é¢‘-åŠ¨ä½œæ¨¡å‹ï¼Œé€šè¿‡åˆ©ç”¨äº’è”ç½‘è§„æ¨¡çš„è§†é¢‘æ¨¡å‹æ¥è”åˆå­¦ä¹ è¯­ä¹‰å’Œè§†è§‰åŠ¨æ€å…ˆéªŒï¼Œä»è€Œå°†ä½çº§æ§åˆ¶ä»»åŠ¡ä¸ç‰©ç†åŠ¨æ€ç†è§£åˆ†ç¦»ï¼Œæ—¨åœ¨å‡å°‘æœºå™¨äººç­–ç•¥å­¦ä¹ å¯¹å¤§è§„æ¨¡ä¸“å®¶æ¼”ç¤ºæ•°æ®çš„ä¾èµ–ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ç»“åˆä¸€ä¸ªé¢„è®­ç»ƒçš„äº’è”ç½‘è§„æ¨¡è§†é¢‘æ¨¡å‹ä¸ä¸€ä¸ªåŸºäºæµåŒ¹é…çš„åŠ¨ä½œè§£ç å™¨ï¼Œæ„å»ºäº†ä¸€ä¸ªè§†é¢‘-åŠ¨ä½œæ¨¡å‹ï¼Œæ—¨åœ¨ä»è§†é¢‘æ•°æ®ä¸­ç›´æ¥æ•è·ç‰©ç†å› æœå…³ç³»å’Œæ—¶åºä¾èµ–ï¼Œä»¥å¢å¼ºæœºå™¨äººæ§åˆ¶çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å½“å‰ç”¨äºæœºå™¨äººæ“ä½œçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼ˆVLAsï¼‰å¤§å¤šåŸºäºå¤§è§„æ¨¡ä½†ç¦»æ•£çš„é™æ€ç½‘ç»œæ•°æ®è¿›è¡Œé¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€ä¸»å¹²ç½‘ç»œæ„å»ºã€‚å°½ç®¡è¿™ç§æ¶æ„æå‡äº†è¯­ä¹‰æ³›åŒ–èƒ½åŠ›ï¼Œä½†ç­–ç•¥æ¨¡å‹ä»éœ€ä»…ä»æœºå™¨äººè½¨è¿¹æ•°æ®ä¸­éšå¼æ¨æ–­å¤æ‚çš„ç‰©ç†åŠ¨æ€ä¸æ—¶é—´ä¾èµ–å…³ç³»ã€‚è¿™ç§ä¾èµ–å¯¼è‡´ä¸å¯æŒç»­çš„æ•°æ®è´Ÿæ‹…â€”â€”ä¸ºå¼¥è¡¥æ¨¡å‹å†…åœ¨ç‰©ç†ç†è§£çš„ç¼ºå¤±ï¼Œå¿…é¡»æŒç»­æ”¶é›†å¤§è§„æ¨¡ä¸“å®¶æ¼”ç¤ºæ•°æ®ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè§†è§‰-è¯­è¨€é¢„è®­ç»ƒè™½èƒ½æœ‰æ•ˆæ•è·è¯­ä¹‰å…ˆéªŒï¼Œå´æ— æ³•æ„ŸçŸ¥ç‰©ç†å› æœå…³ç³»ã€‚æ›´æœ‰æ•ˆâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15692v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15692.pdf">PDF</a></p>
</div>

<hr>
<h3 id="ğŸ“…-2025-12-18"><a href="#ğŸ“…-2025-12-18" class="headerlink" title="ğŸ“… 2025-12-18"></a>ğŸ“… 2025-12-18</h3><div class="paper-card">

<p><strong>ğŸ“„ MultiPath Transfer Engine: Breaking GPU and Host-Memory Bandwidth Bottlenecks in LLM Services</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16056v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16056.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Scaling Text2SQL via LLM-efficient Schema Filtering with Functional Dependency Graph Rerankers</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16083v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16083.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Input Reduction Enhanced LLM-based Program Repair</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.15251v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.15251.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.06489v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.06489.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The Illusion of Rationality: Tacit Bias and Strategic Dominance in Frontier LLM Negotiation Games</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09254v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09254.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Multi-Language Perspective on the Robustness of LLM Code Generation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.19108v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.19108.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16134v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16134.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Generation-Time vs. Post-hoc Citation: A Holistic Evaluation of LLM Attribution</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.21557v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.21557.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Ev-Trust: A Strategy Equilibrium Trust Mechanism for Evolutionary Games in LLM-Based Multi-Agent Services</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16167v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16167.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Knowledge Hierarchy Guided Biological-Medical Dataset Distillation for Domain LLM Training</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.15108v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.15108.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Beyond Blind Spots: Analytic Hints for Mitigating LLM-Based Evaluation Pitfalls</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16272v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16272.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.04070v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.04070.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16962v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16962.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Design and Evaluation of Cost-Aware PoQ for Decentralized LLM Inference</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16317v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16317.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Easy Come, Easy Go? Examining the Perceptions and Learning Effects of LLM-based Chatbot in the Context of Search-as-Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.01396v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.01396.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Beyond â€œNot Novel Enoughâ€: Enriching Scholarly Critique with LLM-Assisted Feedback</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.10795v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.10795.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Hearing to Translate: The Effectiveness of Speech Modality Integration into LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16378v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16378.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Kascade: A Practical Sparse Attention Method for Long-Context LLM Inference</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16391v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16391.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Beyond Over-Refusal: Scenario-Based Diagnostics and Post-Hoc Mitigation for Exaggerated Refusals in LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.08158v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.08158.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM one-shot style transfer for Authorship Attribution and Verification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.13302v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.13302.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Synthelite: Chemist-aligned and feasibility-aware synthesis planning with LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16424v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16424.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Agent-OM: Leveraging LLM Agents for Ontology Matching</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.00326v24">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.00326.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.17361v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.17361.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16969v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16969.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Efficient CPU-GPU Collaborative Inference for MoE-based LLMs on Memory-Limited Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16473v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16473.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Plain language adaptations of biomedical text using LLMs: Comparision of evaluation metrics</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16530v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16530.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Systematic Study of Code Obfuscation Against LLM-based Vulnerability Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16538v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16538.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.16145v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.16145.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Refusal Steering: Fine-grained Control over LLM Refusal Behaviour for Sensitive Topics</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16602v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16602.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.04133v5">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.04133.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Evaluating and Mitigating Errors in LLM-Generated Web API Integrations</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.20172v6">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.20172.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16676v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16676.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16750v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16750.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Inside Out: Uncovering How Comment Internalization Steers LLMs for Better or Worse</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16790v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16790.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16795v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16795.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MEPIC: Memory Efficient Position Independent Caching for LLM Serving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16822v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16822.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Constructive Circuit Amplification: Improving Math Reasoning in LLMs via Targeted Sub-Network Updates</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16914v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16914.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16917v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16917.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17008v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17008.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17023v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17023.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17043v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17043.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ On the Role of Contextual Information and Ego States in LLM Agent Behavior for Transactional Analysis Dialogues</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17060v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17060.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Lang2Manip: A Tool for LLM-Based Symbolic-to-Geometric Planning for Manipulation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17062v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17062.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17093v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17093.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ResDynUNet++: A nested U-Net with residual dynamic convolution blocks for dual-spectral CT</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16140v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16140.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AI-Powered Dermatological Diagnosis: From Interpretable Models to Clinical Implementation A Comprehensive Framework for Accessible and Trustworthy Skin Disease Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16235v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16235.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16251v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16251.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Scene-aware SAR ship detection guided by unsupervised sea-land segmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.12775v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.12775.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Pixel Super-Resolved Fluorescence Lifetime Imaging Using Deep Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16266v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16266.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DKDS: A Benchmark Dataset of Degraded Kuzushiji Documents with Seals for Detection and Binarization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.09117v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.09117.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ An Efficient Deep Learning Framework for Brain Stroke Diagnosis Using Computed Tomography Images</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.03558v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.03558.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Domain-Agnostic Causal-Aware Audio Transformer for Infant Cry Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16271v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16271.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GFLAN: Generative Functional Layouts</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16275v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16275.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WildFit: Autonomous In-situ Model Adaptation for Resource-Constrained IoT Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.07796v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.07796.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SemanticBridge - A Dataset for 3D Semantic Segmentation of Bridges and Domain Gap Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15369v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15369.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Colormap-Enhanced Vision Transformers for MRI-Based Multiclass (4-Class) Alzheimerâ€™s Disease Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16964v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16964.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GeoGraph: Geometric and Graph-based Ensemble Descriptors for Intrinsically Disordered Proteins</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.00774v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.00774.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Iterative Feature Exclusion Ranking for Deep Tabular Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.16442v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.16442.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ UAMDP: Uncertainty-Aware Markov Decision Process for Risk-Constrained Reinforcement Learning from Probabilistic Forecasts</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.08226v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.08226.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Practical Alzheimerâ€™s Disease Diagnosis: A Lightweight and Interpretable Spiking Neural Model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.09695v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.09695.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Artificial Intelligence for Microbiology and Microbiome Research</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.01098v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.01098.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Muon is Provably Faster with Momentum Variance Reduction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16598v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16598.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Plug to Place: Indoor Multimedia Geolocation from Electrical Sockets for Digital Investigation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16620v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16620.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SARMAE: Masked Autoencoder for SAR Representation Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16635v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16635.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16648v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16648.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Synthetic Electrogram Generation with Variational Autoencoders for ECGI</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14537v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14537.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Blog Data Showdown: Machine Learning vs Neuro-Symbolic Models for Gender Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16687v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16687.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Phishing Detection System: An Ensemble Approach Using Character-Level CNN and Feature Engineering</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16717v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16717.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ An Empirical Study of the Realism of Mutants in Deep Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16741v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16741.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Few-Shot Specific Emitter Identification via Integrated Complex Variational Mode Decomposition and Spatial Attention Transfer</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16786v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16786.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Radiology Report Generation with Layer-Wise Anatomical Attention</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16841v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16841.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Core-Set Selection for Data-efficient Land Cover Segmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.01225v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.01225.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Multimodal Representation Learning and Fusion</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.20494v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.20494.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Adversarial VR: An Open-Source Testbed for Evaluating Adversarial Robustness of VR Cybersickness Detection and Mitigation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17029v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17029.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Interpretable Similarity of Synthetic Image Utility</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17080v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17080.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Classical Machine Learning to Emerging Foundation Models: Review on Multimodal Data Integration for Cancer Research</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.09028v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.09028.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17100v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17100.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ D-FCGS: Feedforward Compression of Dynamic Gaussian Splatting for Free-Viewpoint Videos</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.05859v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.05859.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SDFoam: Signed-Distance Foam for explicit surface reconstruction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16706v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16706.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ NeAR: Coupled Neural Asset-Renderer Stack</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18600v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18600.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Iterative Joint Detection of Kalman Filter and Channel Decoder for Sensor-to-Controller Link in Wireless Networked Control Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.18022v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.18022.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Gated KalmaNet: A Fading Memory Layer Through Test-Time Ridge Regression</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.21016v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.21016.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Driving in Corner Case: A Real-World Adversarial Closed-Loop Evaluation Platform for End-to-End Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16055v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16055.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Autoencoder-based Denoising Defense against Adversarial Attacks on Object Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16123v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16123.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LADY: Linear Attention for Autonomous Driving Efficiency without Transformers</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15038v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15038.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CompEvent: Complex-valued Event-RGB Fusion for Low-light Video Enhancement and Deblurring</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14469v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.14469.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.12796v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.12796.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Self-localization on a 3D map by fusing global and local features from a monocular camera</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.26170v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.26170.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13107v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13107.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16760v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16760.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DVGT: Driving Visual Geometry Transformer</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16919v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16919.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Enter the Void - Planning to Seek Entropy When Reward is Scarce</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.16787v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.16787.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SNOW: Spatio-Temporal Scene Understanding with World Knowledge for Open-World Embodied Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16461v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16461.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Animate Any Character in Any World</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17796v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17796.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The World is Your Canvas: Painting Promptable Events with Reference Images, Trajectories, and Text</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16924v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16924.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08333v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08333.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GeoPredict: Leveraging Predictive Kinematics and 3D Gaussian Geometry for Precise VLA Manipulation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16811v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16811.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CauSTreamï¼šé¢å‘å¾„æµé¢„æµ‹çš„å› æœæ—¶ç©ºè¡¨å¾å­¦ä¹ </strong></p>
<p><em>CauSTream: Causal Spatio-Temporal Representation Learning for Streamflow Forecasting</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 / ICLR 2025 / æ°´æ–‡å­¦æˆ–ç¯å¢ƒä¿¡æ¯å­¦é¢†åŸŸçš„é¡¶çº§æœŸåˆŠï¼ˆå¦‚ Water Resources Researchï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºCauSTreamæ¡†æ¶ï¼Œé€šè¿‡è”åˆå­¦ä¹ å¾„æµå› æœå›¾å’ŒåŠ¨æ€è·¯ç”±å›¾ï¼Œå°†å¯é€‚åº”çš„å› æœç»“æ„å¼•å…¥å¾„æµé¢„æµ‹ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•ä¾èµ–å›ºå®šå› æœå›¾ã€éš¾ä»¥é€‚åº”æ•°æ®çš„é—®é¢˜ï¼Œå¹¶å»ºç«‹äº†éå‚æ•°è®¾ç½®ä¸‹çš„å› æœç»“æ„å¯è¯†åˆ«æ€§æ¡ä»¶ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ¡†æ¶æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å› æœæ—¶ç©ºå¾„æµé¢„æµ‹æ¨¡å‹ï¼Œæ ¸å¿ƒæ˜¯åŒæ—¶å­¦ä¹ æ°”è±¡å¼ºè¿«ä¸å¾„æµä¹‹é—´çš„å› æœå›¾ï¼Œä»¥åŠæ•æ‰æ°´æ–‡ç«™ä¹‹é—´åŠ¨æ€ä¾èµ–å…³ç³»çš„è·¯ç”±å›¾ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å¾„æµé¢„æµ‹å¯¹äºæ°´èµ„æºç®¡ç†ä¸é£é™©ç¼“è§£è‡³å…³é‡è¦ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹è™½å·²å–å¾—å“è¶Šçš„é¢„æµ‹æ€§èƒ½ï¼Œå´å¸¸å¿½ç•¥åº•å±‚ç‰©ç†è¿‡ç¨‹ï¼Œé™åˆ¶äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚è¿‘æœŸå› æœå­¦ä¹ æ–¹æ³•é€šè¿‡èåˆé¢†åŸŸçŸ¥è¯†åº”å¯¹è¿™äº›é—®é¢˜ï¼Œä½†é€šå¸¸ä¾èµ–å›ºå®šå› æœå›¾è€Œéš¾ä»¥é€‚åº”æ•°æ®ç‰¹æ€§ã€‚æœ¬æ–‡æå‡ºCauStreamâ€”â€”ä¸€ä¸ªé¢å‘å› æœæ—¶ç©ºå¾„æµé¢„æµ‹çš„ç»Ÿä¸€æ¡†æ¶ã€‚è¯¥æ¡†æ¶è”åˆå­¦ä¹ ï¼ˆiï¼‰æ°”è±¡é©±åŠ¨å› ç´ é—´çš„å¾„æµå› æœå›¾ï¼Œä»¥åŠï¼ˆiiï¼‰æ•æ‰æ°´æ–‡ç«™ç‚¹é—´åŠ¨æ€ä¾èµ–å…³ç³»çš„æ±‡æµå›¾ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å»ºç«‹äº†éå‚â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16046v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16046.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ æµ·æ´‹é¢„æµ‹åŸºå‡†ï¼šé¢å‘æ•°æ®é©±åŠ¨å…¨çƒæµ·æ´‹é¢„æµ‹çš„åŸºå‡†æ•°æ®é›†</strong></p>
<p><em>OceanForecastBench: A Benchmark Dataset for Data-Driven Global Ocean Forecasting</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 / ICLR 2025 æˆ– arXiv preprint</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†é¦–ä¸ªå¼€æºã€æ ‡å‡†åŒ–çš„å…¨çƒæµ·æ´‹é¢„æŠ¥åŸºå‡†æ•°æ®é›†OceanForecastBenchï¼Œæ—¨åœ¨è§£å†³æ•°æ®é©±åŠ¨æµ·æ´‹é¢„æŠ¥æ¨¡å‹å› ç¼ºä¹ç»Ÿä¸€åŸºå‡†è€Œå¯¼è‡´çš„æ•°æ®ä½¿ç”¨å’Œè¯„ä¼°æ–¹æ³•ä¸ä¸€è‡´é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥åŸºå‡†æä¾›ä¸‰é¡¹æ ¸å¿ƒå†…å®¹ï¼š28å¹´é«˜è´¨é‡å…¨çƒæµ·æ´‹å†åˆ†ææ•°æ®ç”¨äºæ¨¡å‹è®­ç»ƒï¼ŒåŒ…å«å¤šå˜é‡ã€å¤šæ·±åº¦åŠæµ·è¡¨å˜é‡ï¼›é«˜å¯é æ€§å«æ˜Ÿå’Œç°åœºè§‚æµ‹æ•°æ®ç”¨äºéªŒè¯ï¼›ä»¥åŠæ ‡å‡†åŒ–çš„è¯„ä¼°åè®®å’ŒæŒ‡æ ‡ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å…¨çƒæµ·æ´‹é¢„æŠ¥æ—¨åœ¨é¢„æµ‹æ¸©åº¦ã€ç›åº¦å’Œæµ·æµç­‰å…³é”®æµ·æ´‹å˜é‡ï¼Œè¿™å¯¹ç†è§£å’Œæè¿°æµ·æ´‹ç°è±¡è‡³å…³é‡è¦ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºæ•°æ®é©±åŠ¨çš„æ·±åº¦å­¦ä¹ æµ·æ´‹é¢„æŠ¥æ¨¡å‹ï¼Œå¦‚â€ç¾²å’Œâ€ã€â€æ–‡æµ·â€ã€â€æµªæ¶¯â€å’ŒAI-GOMSç­‰ï¼Œåœ¨æ•æ‰å¤æ‚æµ·æ´‹åŠ¨åŠ›è¿‡ç¨‹ä¸æå‡é¢„æŠ¥æ•ˆç‡æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå°½ç®¡å–å¾—è¿™äº›è¿›å±•ï¼Œå¼€æºæ ‡å‡†åŒ–åŸºå‡†çš„ç¼ºå¤±å¯¼è‡´æ•°æ®ä½¿ç”¨å’Œè¯„ä¼°æ–¹æ³•ç¼ºä¹ç»Ÿä¸€æ€§ã€‚è¿™ä¸€ç©ºç™½é˜»ç¢äº†æ¨¡å‹çš„é«˜æ•ˆå¼€å‘ï¼Œå½±å“äº†æ€§èƒ½çš„å…¬å¹³æ¯”è¾ƒï¼Œå¹¶åˆ¶çº¦äº†è·¨å­¦ç§‘åˆä½œã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18732v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18732.pdf">PDF</a></p>
</div>

<hr>
<h3 id="ğŸ“…-2025-12-17"><a href="#ğŸ“…-2025-12-17" class="headerlink" title="ğŸ“… 2025-12-17"></a>ğŸ“… 2025-12-17</h3><div class="paper-card">

<p><strong>ğŸ“„ The Trojan Knowledge: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.01353v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.01353.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.02389v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.02389.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15662v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15662.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15674v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15674.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ OLAF: Towards Robust LLM-Based Annotation Framework in Empirical Software Engineering</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15979v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15979.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HPU: High-Bandwidth Processing Unit for Scalable, Cost-effective LLM Inference via GPU Co-processing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.16112v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.16112.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Are We on the Right Way to Assessing LLM-as-a-Judge?</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16041v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16041.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MVGSR: Multi-View Consistent 3D Gaussian Super-Resolution via Epipolar Guidance</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15048v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15048.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Off The Grid: Detection of Primitives for Feed-Forward 3D Gaussian Splatting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15508v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15508.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Gaussian Pixel Codec Avatars: A Hybrid Representation for Efficient Rendering</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15711v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15711.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Supervisory Measurement-Guided Noise Covariance Estimation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.24508v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.24508.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Variational Robust Kalman Filters: A Unified Framework</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15419v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15419.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Large Model Enabled Embodied Intelligence for 6G Integrated Perception, Communication, and Computation Network</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15109v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15109.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ EPSM: A Novel Metric to Evaluate the Safety of Environmental Perception in Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15195v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15195.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ KD360-VoxelBEV: LiDAR and 360-degree Camera Cross Modality Knowledge Distillation for Birdâ€™s-Eye-View Segmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15311v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15311.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.09245v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.09245.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Human-like Working Memory from Artificial Intrinsic Plasticity Neurons</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15829v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15829.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ OccSTeP: Benchmarking 4D Occupancy Spatio-Temporal Persistence</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15621v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15621.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Words to Wavelengths: VLMs for Few-Shot Multispectral Object Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15971v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15971.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ QuantGraph: A Receding-Horizon Quantum Graph Solver</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Graph Optimization</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15476v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15476.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Spatia: Video Generation with Updatable Spatial Memory</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Visual SLAM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15716v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15716.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SparseWorld-TC: Trajectory-Conditioned Sparse Occupancy World Model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.22039v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.22039.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Soft Geometric Inductive Bias for Object Centric Dynamics</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15493v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15493.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MMGR: Multi-Modal Generative Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14691v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14691.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ R4: Retrieval-Augmented Reasoning for Vision-Language Models in 4D Spatio-Temporal Space</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15940v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15940.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AIE4ML: An End-to-End Framework for Compiling Neural Networks for the Next Generation of AMD AI Engines</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15946v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15946.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Large Video Planner Enables Generalizable Robot Control</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15840v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15840.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision and Language Navigation</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14222v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14222.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Stronger-MAS: Multi-Agent Reinforcement Learning for Collaborative LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.11062v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.11062.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15000v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15000.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15053v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15053.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Quantifying Return on Security Controls in LLM Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15081v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15081.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15082v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15082.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ChemDFM-R: A Chemical Reasoning LLM Enhanced with Atomized Chemical Knowledge</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.21990v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.21990.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ No More Hidden Pitfalls? Exposing Smart Contract Bad Practices with LLM-Powered Hybrid Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15179v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15179.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Designing LLMs for cultural sensitivity: Evidence from English-Japanese translation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.11921v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.11921.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.23049v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.23049.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15274v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15274.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15312v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15312.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Exploring User Acceptance and Concerns toward LLM-powered Conversational Agents in Immersive Extended Reality</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15343v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15343.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Adversarial versification in portuguese as a jailbreak operator in LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15353v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15353.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ArcBERT: An LLM-based Search Engine for Exploring Integrated Multi-Omics Metadata</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15365v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15365.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13857v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13857.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ORACLE: Time-Dependent Recursive Summary Graphs for Foresight on News Data Using LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15397v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15397.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.20764v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.20764.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLMs and Fuzzing in Tandem: A New Approach to Automatically Generating Weakest Preconditions</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.05272v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.05272.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Toward expert-level motivational interviewing for health behavior improvement with LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15446v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15446.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Scaling Behaviors of LLM Reinforcement Learning Post-Training: An Empirical Study in Mathematical Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.25300v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.25300.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15550v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15550.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.14285v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.14285.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Evaluating Metrics for Safety with LLM-as-Judges</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15617v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15617.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14990v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14990.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Near-Zero-Overhead Freshness for Recommendation Systems via Inference-Side Model Updates</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12295v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12295.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15088v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15088.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TrajSyn: Privacy-Preserving Dataset Distillation from Federated Model Trajectories for Server-Side Adversarial Training</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15123v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15123.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Generalization and Feature Attribution in Machine Learning Models for Crop Yield and Anomaly Prediction in Germany</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15140v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15140.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Feature Importance-Aware Deep Joint Source-Channel Coding for Computationally Efficient and Adjustable Image Transmission</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.04758v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.04758.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Time-Varying Audio Effect Modeling by End-to-End Adversarial Training</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15313v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15313.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep Neural Network and Grad-CAM Explanations</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.00456v5">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.00456.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15344v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15344.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ See It Before You Grab It: Deep Learning-based Action Anticipation in Basketball</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15386v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15386.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Mapis: A Knowledge-Graph Grounded Multi-Agent Framework for Evidence-Based PCOS Diagnosis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15398v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15398.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Preserving Marker Specificity with Lightweight Channel-Independent Representation Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15410v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15410.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Packed Malware Detection Using Grayscale Binary-to-Image Representations</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15414v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15414.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Spectral Masking and Interpolation Attack (SMIA): A Black-box Adversarial Attack against Voice Authentication and Anti-Spoofing Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.07677v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.07677.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Deep Learning for Retinal Degeneration Assessment: A Comprehensive Analysis of the MARIO Challenge</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.02976v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.02976.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Evaluation of deep learning architectures for wildlife object detection: A comparative study of ResNet and Inception</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15480v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15480.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ BubbleOKAN: A Physics-Informed Interpretable Neural Operator for High-Frequency Bubble Dynamics</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.03965v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.03965.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The LUMirage: An independent evaluation of zero-shot performance in the LUMIR challenge</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15505v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15505.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Autonomous Pressure Control in MuVacAS via Deep Reinforcement Learning and Deep Learning Surrogate Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15521v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15521.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MedicoSAM: Robust Improvement of SAM for Medical Imaging</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.11734v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.11734.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SoFlow: Solution Flow Models for One-Step Generative Modeling</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15657v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15657.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Artism: AI-Driven Dual-Engine System for Art Generation and Critique</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15710v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15710.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FARM: Fine-Tuning Geospatial Foundation Models for Intra-Field Crop Yield Regression</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.26609v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.26609.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Improved Segmentation of Polyps and Visual Explainability Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.18159v5">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.18159.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Deep generative priors for 3D brain analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.15119v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.15119.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Dynamic Rank Reinforcement Learning for Adaptive Low-Rank Multi-Head Self Attention in Large Language Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15973v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15973.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Forgetting is Everywhere</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.04666v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.04666.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Bayesian Deep Learning for Discrete Choice</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.18077v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.18077.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Uncovering Alzheimerâ€™s Disease Progression via SDE-based Spatio-Temporal Graph Deep Learning on Longitudinal Brain Networks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.21735v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.21735.pdf">PDF</a></p>
</div>

<hr>
<h3 id="ğŸ“…-2025-12-16"><a href="#ğŸ“…-2025-12-16" class="headerlink" title="ğŸ“… 2025-12-16"></a>ğŸ“… 2025-12-16</h3><div class="paper-card">

<p><strong>ğŸ“„ ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14039v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14039.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14087v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14087.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14180v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14180.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14200v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14200.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ RTR-GS: 3D Gaussian Splatting for Inverse Rendering with Radiance Transfer and Reflection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.07733v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.07733.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14352v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14352.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Enhancing Geo-localization for Crowdsourced Flood Imagery via LLM-Guided Attention</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Visual Place Recognition</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11811v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11811.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Quadratic Kalman Filter for Elliptical Extended Object Tracking based on Decoupling State Components</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14426v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14426.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Chirp Delay-Doppler Domain Modulation Based Joint Communication and Radar for Autonomous Vehicles</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14432v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14432.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TransientTrack: Advanced Multi-Object Tracking and Classification of Cancer Cells with Transient Fluorescent Signals</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.01885v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.01885.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Nowcasting using regression on signatures</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.10256v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.10256.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FocalComm: Hard Instance-Aware Multi-Agent Perception</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13982v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13982.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14044v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14044.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13177v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13177.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CIS-BA: Continuous Interaction Space Based Backdoor Attack for Object Detection in the Real-World</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14158v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14158.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14225v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14225.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LSM: A Comprehensive Metric for Assessing the Safety of Lane Detection Systems in Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.07740v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.07740.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13636v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13636.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DriverGaze360: OmniDirectional Driver Attention with Object-Level Guidance</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14266v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14266.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Closing the Loop: Motion Prediction Models beyond Open-Loop Benchmarks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.05638v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.05638.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Segments to Scenes: Temporal Understanding in Autonomous Driving via Vision-Language Model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.05277v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.05277.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>GNSS</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14428v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14428.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SUPER â€“ A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Visual Inertial Odometry</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14189v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14189.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Deep Learning Perspective of Scene Understanding in Autonomous Robots</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Visual SLAM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14020v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14020.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.10400v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.10400.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MobileWorldBench: Towards Semantic World Modeling For Mobile Agents</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14014v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14014.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14614v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14614.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14031v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14031.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14666v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14666.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14474v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14474.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PushGen: Push Notifications Generation with LLM</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14490v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14490.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14531v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14531.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14594v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14594.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLmFPCA-detect: LLM-powered Multivariate Functional PCA for Anomaly Detection in Sparse Longitudinal Texts</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14604v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14604.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Reconsidering Conversational Norms in LLM Chatbots for Sustainable AI</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14673v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14673.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Love First, Know Later: Persona-Based Romantic Compatibility Through LLM Text World Engines</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11844v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11844.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14846v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14846.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Hidden in the Haystack: Smaller Needles are More Difficult for LLMs to Find</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.18148v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.18148.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14896v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14896.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ EVICPRESS: Joint KV-Cache Compression and Eviction for Efficient LLM Serving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14946v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14946.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The 4&#x2F;$Î´$ Bound: Designing Predictable LLM-Verifier Systems for Formal Method Guarantee</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.02080v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.02080.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Improving Pre-trained Segmentation Models using Post-Processing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14937v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14937.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Low-Rank Tensor Decompositions for the Theory of Neural Networks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.18408v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.18408.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.07400v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.07400.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ An empirical analysis of zero-day vulnerabilities disclosed by the zero day initiative</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15803v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15803.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Deep Learning and Elicitability for McKean-Vlasov FBSDEs With Common Noise</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14967v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14967.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer VLM-LLM Pipeline</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13974v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13974.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13978v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13978.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ReflCtrl: Controlling LLM Reflection via Representation Engineering</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13979v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13979.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Can Finetuing LLMs on Small Human Samples Increase Heterogeneity, Alignment, and Belief-Action Coherence?</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.21218v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.21218.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Beyond Jailbreak: Unveiling Risks in LLM Applications Arising from Blurred Capability Boundaries</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.17874v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.17874.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.14522v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.14522.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.13109v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.13109.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PAT: Accelerating LLM Decoding via Prefix-Aware Attention with Resource Efficient Multi-Tile Kernel</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.22333v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.22333.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LAPPI: Interactive Optimization with LLM-Assisted Preference-Based Problem Instantiation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14138v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14138.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14142v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14142.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DIWALI: Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.17399v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.17399.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Comparative Analysis of Retrieval-Augmented Generation Techniques for Bengali Standard-to-Dialect Machine Translation Using LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14179v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14179.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.04359v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.04359.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A LoRA-Based Approach to Fine-Tuning LLMs for Educational Guidance in Resource-Constrained Settings</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.15610v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.15610.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14233v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14233.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14277v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14277.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14288v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14288.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ One Battle After Another: Probing LLMsâ€™ Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.03508v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.03508.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ EcoScapes: LLM-Powered Advice for Crafting Sustainable Cities</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14373v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14373.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14417v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14417.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14448v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14448.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14792v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14792.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.11064v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.11064.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14058v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14058.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FusAD: Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14078v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14078.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Quality-Aware Framework for Video-Derived Respiratory Signals</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14093v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14093.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ComMark: Covert and Robust Black-Box Model Watermarking with Compressed Samples</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15641v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15641.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PathFinder: Advancing Path Loss Prediction for Single-to-Multi-Transmitter Scenario</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14150v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14150.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Translating Electrocardiograms to Cardiac Magnetic Resonance Imaging Useful for Cardiac Assessment and Disease Screening: A Multi-Center Study</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.13602v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.13602.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Robust Beamforming for Multiuser MIMO Systems with Unknown Channel Statistics: A Hybrid Offline-Online Framework</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14165v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14165.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.11252v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.11252.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Evaluating Adversarial Attacks on Federated Learning for Temperature Forecasting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13207v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13207.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Error Bound Analysis of Physics-Informed Neural Networks-Driven T2 Quantification in Cardiac Magnetic Resonance Imaging</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14211v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14211.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ IdealTSF: Can Non-Ideal Data Contribute to Enhancing the Performance of Time Series Forecasting Models?</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.05442v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.05442.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Multi-View MRI Approach for Classification of MGMT Methylation in Glioblastoma Patients</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14232v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14232.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Beyond MMD: Evaluating Graph Generative Models with Geometric Deep Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14241v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14241.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.14831v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.14831.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14274v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14274.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Multimodal Deep Learning for Stroke Prediction and Detection using Retinal Imaging and Clinical Data</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.02677v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.02677.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Multimodal classification of forest biodiversity potential from 2D orthophotos and 3D airborne laser scanning point clouds</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.01728v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.01728.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ High Volume Rate 3D Ultrasound Reconstruction with Diffusion Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.22090v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.22090.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Hybrid Ensemble Method for Detecting Cyber-Attacks in Water Distribution Systems Using the BATADAL Dataset</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14422v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14422.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AnySleep: a channel-agnostic deep learning system for high-resolution sleep staging in multi-center cohorts</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14461v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14461.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TACK Tunnel Data (TTD): A Benchmark Dataset for Deep Learning-Based Defect Detection in Tunnels</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14477v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14477.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Linguists should learn to love speech-based deep learning models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14506v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14506.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Artificial Intelligence for the Assessment of Peritoneal Carcinosis during Diagnostic Laparoscopy for Advanced Ovarian Cancer</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14797v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14797.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CAPRMIL: Context-Aware Patch Representations for Multiple Instance Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14540v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14540.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Test Time Optimized Generalized AI-based Medical Image Registration Method</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14556v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14556.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14563v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14563.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Sound and Music Biases in Deep Music Transcription Models: A Systematic Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14602v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14602.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14640v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14640.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Unreliable Uncertainty Estimates with Monte Carlo Dropout</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14851v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14851.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Primer C-VAE: An interpretable deep learning primer design method to detect emerging virus variants</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.01459v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.01459.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Deep learning water-unsuppressed MRSI at ultra-high field for simultaneous quantitative metabolic, susceptibility and myelin water imaging</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14929v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14929.pdf">PDF</a></p>
</div>

<hr>
<h3 id="ğŸ“…-2025-12-15"><a href="#ğŸ“…-2025-12-15" class="headerlink" title="ğŸ“… 2025-12-15"></a>ğŸ“… 2025-12-15</h3><div class="paper-card">

<p><strong>ğŸ“„ Towards Physically Executable 3D Gaussian for Embodied Navigation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.21307v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.21307.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HybridSplat: Fast Reflection-baked Gaussian Tracing using Hybrid Splatting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08334v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08334.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Computer vision training dataset generation for robotic environments using Gaussian splatting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13411v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13411.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.09397v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.09397.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13796v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13796.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Test-time Efficient Visual Place Recognition via Asymmetric Query Processing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Visual Place Recognition</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13055v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13055.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ K-VARK: Kernelized Variance-Aware Residual Kalman Filter for Sensorless Force Estimation in Collaborative Robots</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13009v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13009.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CT-UIO: Continuous-Time UWB-Inertial-Odometer Localization Using Non-Uniform B-spline with Fewer Anchors</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.06287v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.06287.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Safe Online Control-Informed Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13868v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13868.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Machine Learning Architectures for the Estimation of Predicted Occupancy Grids in Road Traffic</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12907v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12907.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Astra: General Interactive World Model with Autoregressive Denoising</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08931v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08931.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WCCNet: Wavelet-context Cooperative Network for Efficient Multispectral Pedestrian Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.01042v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2308.01042.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DRO-EDL-MPC: Evidential Deep Learning-Based Distributionally Robust Model Predictive Control for Safe Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.05710v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.05710.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Sequence of Expert: Boosting Imitation Planners for Autonomous Driving through Temporal Alternation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13094v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13094.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Post-Training and Test-Time Scaling of Generative Agent Behavior Models for Interactive Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13262v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13262.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FractalCloud: A Fractal-Inspired Architecture for Efficient Large-Scale Point Cloud Processing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.07665v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.07665.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Convex Obstacle Avoidance Formulation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13836v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13836.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ 3D Scene Prompting for Scene-Consistent Camera-Controllable Video Generation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Dynamic SLAM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.14945v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.14945.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Motus: A Unified Latent Action World Model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13030v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13030.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ IPR-1: Interactive Physical Reasoner</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.15407v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.15407.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Deep Learning Model of Mental Rotation Informed by Interactive VR Experiments</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13517v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13517.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LongVie 2: Multimodal Controllable Ultra-Long Video World Model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13604v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13604.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ World Models Can Leverage Human Videos for Dexterous Manipulation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13644v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13644.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13821v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13821.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11047v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11047.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13080v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13080.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision and Language Navigation</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.03958v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.03958.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13481v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13481.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DFALLM: Achieving Generalizable Multitask Deepfake Detection by Optimizing Audio LLM Components</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08403v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08403.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Async Control: Stress-testing Asynchronous Control Measures for LLM Agents</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13526v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13526.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.03005v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.03005.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Bilevel ZOFO: Efficient LLM Fine-Tuning and Meta-Training</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.03604v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.03604.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Effective Model Editing for LLM Personalization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13676v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13676.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08786v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08786.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Verification-Guided Context Optimization for Tool Calling via Hierarchical LLMs-as-Editors</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13860v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13860.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM Inference Beyond a Single Node: From Bottlenecks to Mitigations with Fast All-Reduce Communication</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.09557v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.09557.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ OPTIMA: Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13886v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13886.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.20768v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.20768.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Letâ€™s (not) just put things in Context: Test-Time Training for Long-Context LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13898v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13898.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ How K-12 Educators Use AI: LLM-Assisted Qualitative Analysis at Scale</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.17985v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.17985.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Context Branching for LLM Conversations: A Version Control Approach to Exploratory Programming</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13914v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13914.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Conveying Imagistic Thinking in Traditional Chinese Medicine Translation: A Prompt Engineering and LLM-Based Evaluation Framework</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.01198v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.01198.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CTIGuardian: A Few-Shot Framework for Mitigating Privacy Leakage in Fine-Tuned LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12914v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12914.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12922v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12922.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PROSERVE: Unified Multi-Priority Request Scheduling for LLM Serving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12928v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12928.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Diagnose, Localize, Align: A Full-Stack Framework for Reliable LLM Multi-Agent Systems under Instruction Conflicts</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.23188v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.23188.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09321v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09321.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10449v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10449.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Understanding Structured Financial Data with LLMs: A Case Study on Fraud Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13040v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13040.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM Rationalis? Measuring Bargaining Capabilities of AI Negotiators</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13063v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13063.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Resource-Efficient Serverless LLM Inference with SLINFER</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.00507v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.00507.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LikeBench: Evaluating Subjective Likability in LLMs for Personalization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13077v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13077.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Cost-aware LLM-based Online Dataset Annotation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.15101v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.15101.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Chasing Shadows: Pitfalls in LLM Security Research</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09549v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09549.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åæœŸä¿®æ­£ï¼šLLMåè®­ç»ƒæ•°æ®è´¨é‡ä¸æ¨¡å‹æ€§èƒ½æ¯”è¾ƒç ”ç©¶</strong></p>
<p><em>Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025ï¼ˆé‰´äºå…¶ç³»ç»Ÿæ€§å®éªŒã€å¯¹å½“å‰LLMç ”ç©¶æ ¸å¿ƒé—®é¢˜çš„æ·±å…¥æ¢è®¨ï¼Œä»¥åŠå¡«è¡¥é¢†åŸŸç©ºç™½çš„ä»·å€¼ï¼Œå¾ˆå¯èƒ½å‘è¡¨äºé¡¶çº§æœºå™¨å­¦ä¹ ä¼šè®®ï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æœ¬æ–‡é¦–æ¬¡å¯¹ä¸¤ä¸ªä¸»æµçš„å¼€æºåè®­ç»ƒæ•°æ®é›†ï¼ˆOpenHermeså’ŒUltraChatï¼‰è¿›è¡Œäº†å…¨é¢çš„å¹¶è¡Œå¯¹æ¯”åˆ†æï¼Œç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†æ•°æ®è´¨é‡ï¼ˆå¦‚æ ·æœ¬ã€ä»»åŠ¡ç±»å‹ã€ç­›é€‰ç­–ç•¥ï¼‰å¯¹ä¸‹æ¸¸æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸç³»ç»Ÿæ€§æ¯”è¾ƒç ”ç©¶çš„ç©ºç™½ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: ç ”ç©¶é€šè¿‡æ§åˆ¶å˜é‡å®éªŒï¼Œåœ¨ç›¸åŒæ¨¡å‹æ¶æ„å’Œè®¡ç®—é¢„ç®—ä¸‹ï¼Œåˆ†åˆ«ä½¿ç”¨ä¸¤ä¸ªæ•°æ®é›†è¿›è¡Œåè®­ç»ƒï¼Œå¹¶åœ¨å¹¿æ³›çš„åŸºå‡†æµ‹è¯•ï¼ˆå¦‚æŒ‡ä»¤éµå¾ªã€ä¸–ç•ŒçŸ¥è¯†ã€æ¨ç†èƒ½åŠ›ï¼‰ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œä»è€Œç›´æ¥æ¯”è¾ƒä¸åŒæ•°æ®é›†çš„æ•ˆç”¨ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: è¿‘æœŸå…³äºå¤§è¯­è¨€æ¨¡å‹çš„ç ”ç©¶æ—¥ç›Šèšç„¦äºåè®­ç»ƒé˜¶æ®µï¼Œä»¥åŠé€šè¿‡ç²¾é€‰æ•°æ®é›†è¿›è¡Œå¯¹é½ä»¥æå‡æŒ‡ä»¤éµå¾ªã€ä¸–ç•ŒçŸ¥è¯†å’Œä¸“ä¸šæŠ€èƒ½ã€‚ç„¶è€Œï¼Œä¸»æµå¼€æºä¸é—­æºå¤§è¯­è¨€æ¨¡å‹æ‰€ä½¿ç”¨çš„åè®­ç»ƒæ•°æ®é›†å¤§å¤šæœªå‘å…¬ä¼—å¼€æ”¾ï¼Œå…¶æ„å»ºè¿‡ç¨‹ä¹Ÿé²œæœ‰æŠ«éœ²ã€‚è¿™ç§é€æ˜åº¦çš„ç¼ºå¤±æ¨åŠ¨äº†å¼€æºåè®­ç»ƒè¯­æ–™åº“çš„è¿‘æœŸå‘å±•ã€‚è™½ç„¶åŸºäºè¿™äº›å¼€æºæ›¿ä»£æ–¹æ¡ˆè¿›è¡Œè®­ç»ƒèƒ½è¾¾åˆ°ä¸ä¸»æµæ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼Œä½†ç”±äºå¤§è§„æ¨¡ä¸¥è°¨æ¯”è¾ƒæ‰€éœ€è®¡ç®—æˆæœ¬è¿‡é«˜ï¼Œç³»ç»Ÿæ€§å¯¹æ¯”ç ”ç©¶ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå› æ­¤ç›¸å…³åˆ†æåŸºæœ¬å¤„äºç©ºç™½çŠ¶æ€â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.06522v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.06522.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ å±€éƒ¨ä¸»ä¹‰å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ¸è¿›å¼å®šä½</strong></p>
<p><em>Progressive Localisation in Localist LLMs</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>ICLR 2025 æˆ– NeurIPS 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºâ€œæ¸è¿›å±€éƒ¨åŒ–â€ä½œä¸ºæ„å»ºå¯è§£é‡Šå¤§è¯­è¨€æ¨¡å‹çš„æœ€ä¼˜æ¶æ„ï¼Œå³åœ¨ç½‘ç»œæ·±åº¦ä¸Šé€æ­¥å¢åŠ æ³¨æ„åŠ›å±€éƒ¨æ€§ï¼Œä»è€Œåœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶è·å¾—å¯è§£é‡Šçš„æ³¨æ„åŠ›æ¨¡å¼ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é€šè¿‡ç³»ç»Ÿå®éªŒï¼Œåœ¨GPT-2æ¨¡å‹ä¸Šè¯„ä¼°äº†äº”ç§æ³¨æ„åŠ›å±€éƒ¨æ€§é…ç½®ï¼ˆåŒ…æ‹¬ä¸¤ç§å‡åŒ€åŸºçº¿åŠä¸‰ç§æ¸è¿›å¤šé¡¹å¼è°ƒåº¦ï¼‰ï¼Œå¹¶è¯æ˜ç»“åˆè‡ªé€‚åº”è¯­ä¹‰å—åˆ’åˆ†ä¸é™¡å³­å¤šé¡¹å¼å±€éƒ¨åŒ–è°ƒåº¦çš„æ¸è¿›è¯­ä¹‰å±€éƒ¨åŒ–æ–¹æ³•æ•ˆæœæœ€ä½³ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æœ¬æ–‡è¯æ˜ï¼Œæ¸è¿›å¼å®šä½â€”â€”å³æ³¨æ„åŠ›æœºåˆ¶ä»æ—©æœŸåˆ†å¸ƒå¼å±‚åˆ°åæœŸå±€éƒ¨åŒ–å±‚çš„é€æ­¥èšç„¦â€”â€”ä»£è¡¨äº†åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶æ„å»ºå¯è§£é‡Šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€ä¼˜æ¶æ„ã€‚é€šè¿‡å¯¹ã€Šäººå·¥è¶…çº§æ™ºèƒ½å¿ƒç†å­¦ã€‹è¿›è¡Œå¾®è°ƒçš„GPT-2æ¨¡å‹è¿›è¡Œç³»ç»Ÿæ€§å®éªŒï¼Œæˆ‘ä»¬è¯„ä¼°äº†äº”ç§å®šä½é…ç½®ï¼šä¸¤ç§å‡åŒ€åŸºçº¿ï¼ˆå®Œå…¨åˆ†å¸ƒå¼ä¸å®Œå…¨å±€éƒ¨åŒ–ï¼‰åŠä¸‰ç§æ¸è¿›å¤šé¡¹å¼è°ƒåº¦æ–¹æ¡ˆã€‚æˆ‘ä»¬æ¢ç©¶äº†å¯è§£é‡Šæ€§çº¦æŸèƒ½å¦åœ¨è·¨ç½‘ç»œæ·±åº¦ç­–ç•¥æ€§åº”ç”¨çš„åŒæ—¶ï¼Œä¸è‡ªç„¶è¯­ä¹‰ç»“æ„ä¿æŒå¯¹é½ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç»“åˆè‡ªé€‚åº”â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18375v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18375.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MiniLinguaï¼šé¢å‘æ¬§æ´²è¯­è¨€çš„å°å‹å¼€æºå¤§è¯­è¨€æ¨¡å‹</strong></p>
<p><em>MiniLingua: A Small Open-Source LLM for European Languages</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– EMNLP 2025ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºMiniLinguaï¼Œä¸€ä¸ªä¸“ä¸º13ç§æ¬§æ´²è¯­è¨€ä»å¤´è®­ç»ƒã€å‚æ•°çº¦10äº¿çš„å¼€æºå¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹ï¼Œåœ¨æŒ‡ä»¤å¾®è°ƒåï¼Œå…¶æ€§èƒ½è¶…è¶Šäº†è®­ç»ƒé¢„ç®—æ›´é«˜çš„åŒç±»æ¨¡å‹EuroLLMã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é€šè¿‡ä»å¤´è®­ç»ƒä¸€ä¸ªçº¦10äº¿å‚æ•°çš„å°å‹é«˜æ•ˆæ¨¡å‹ï¼Œå¹¶é’ˆå¯¹å¤šè¯­è¨€æŒ‡ä»¤è·Ÿéšèƒ½åŠ›è¿›è¡Œä¼˜åŒ–ï¼Œæ—¨åœ¨å¹³è¡¡è¯­è¨€è¦†ç›–èŒƒå›´ä¸ä»»åŠ¡æ€§èƒ½ï¼ŒåŒæ—¶å®ç°è®¾å¤‡ç«¯éƒ¨ç½²çš„æ½œåŠ›ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å¤§å‹è¯­è¨€æ¨¡å‹è™½åŠŸèƒ½å¼ºå¤§ï¼Œä½†å¸¸å—é™äºé«˜æ˜‚çš„è®¡ç®—æˆæœ¬ã€éšç§é—®é¢˜ä»¥åŠä»¥è‹±è¯­ä¸ºä¸­å¿ƒçš„è®­ç»ƒæ¨¡å¼ã€‚è¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œå‚æ•°é‡çº¦åäº¿çš„å°å‹é«˜æ•ˆæ¨¡å‹åŒæ ·èƒ½å–å¾—ä¼˜å¼‚æ€§èƒ½ï¼Œå¹¶æ”¯æŒç«¯ä¾§éƒ¨ç½²ã€‚æœ¬æ–‡æå‡ºçš„MiniLinguaæ˜¯ä¸€ä¸ªæ‹¥æœ‰åäº¿å‚æ•°çš„å¤šè¯­è¨€å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼Œä¸“ä¸º13ç§æ¬§æ´²è¯­è¨€ä»å¤´è®­ç»ƒè€Œæˆï¼Œæ—¨åœ¨å¹³è¡¡è¯­è¨€è¦†ç›–èŒƒå›´ä¸æŒ‡ä»¤è·Ÿéšèƒ½åŠ›ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„MiniLinguaåœ¨æ–‡æœ¬æ‘˜è¦ã€åˆ†ç±»ã€å¼€å·ä¸é—­å·é—®ç­”ä»»åŠ¡ä¸Šå‡ä¼˜äºEurâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13298v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13298.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Phythesisï¼šåŸºäºç‰©ç†å¼•å¯¼çš„è¿›åŒ–åœºæ™¯åˆæˆï¼Œé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹å®ç°èŠ‚èƒ½æ•°æ®ä¸­å¿ƒè®¾è®¡</strong></p>
<p><em>Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>å¯èƒ½å‘è¡¨äºäººå·¥æ™ºèƒ½ä¸ç³»ç»Ÿäº¤å‰é¢†åŸŸçš„é¡¶çº§ä¼šè®®ï¼Œå¦‚ **NeurIPS 2025** æˆ– **ICLR 2025**ï¼Œæˆ–ä½œä¸ºé¢„å°æœ¬å‘å¸ƒäº **arXiv**ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åä¸ºPhythesisçš„æ–°æ¡†æ¶ï¼Œé¦–æ¬¡å°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸åŸºäºç‰©ç†è§„åˆ™çš„è¿›åŒ–ä¼˜åŒ–ç›¸ç»“åˆï¼Œç”¨äºè‡ªåŠ¨åŒ–ç”Ÿæˆå¯ç›´æ¥ç”¨äºä»¿çœŸçš„æ•°æ®ä¸­å¿ƒä¸‰ç»´å¸ƒå±€ï¼Œä»¥è§£å†³ä¼ ç»Ÿç”Ÿæˆæ–¹æ³•å¿½ç•¥ç‰©ç†çº¦æŸå’Œé‡åŒ–è¿è¥ç›®æ ‡çš„é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é‡‡ç”¨åŒå±‚è¿­ä»£ä¼˜åŒ–æ¶æ„ï¼šä¸Šå±‚ç”±LLMé©±åŠ¨ï¼Œç”Ÿæˆç‰©ç†ä¸Šåˆç†çš„ä¸‰ç»´å¸ƒå±€å¹¶è¿›è¡Œè‡ªæˆ‘æ‰¹åˆ¤ä¸ä¿®æ­£ï¼›ä¸‹å±‚è¿›è¡ŒåŸºäºç‰©ç†è§„åˆ™çš„è¿›åŒ–ä¼˜åŒ–ï¼Œç¡®ä¿è®¾è®¡æ»¡è¶³ä¸¥æ ¼çš„èƒ½è€—ç­‰ç‰©ç†çº¦æŸä¸è¿è¥ç›®æ ‡ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ•°æ®ä¸­å¿ƒåŸºç¡€è®¾æ–½æ˜¯æ”¯æ’‘æ—¥ç›Šå¢é•¿è®¡ç®—èƒ½åŠ›éœ€æ±‚çš„å…³é”®æ”¯æŸ±ã€‚ä¼ ç»Ÿè®¾è®¡æ–¹æ³•å°†äººç±»ä¸“ä¸šçŸ¥è¯†ä¸ä¸“ä¸šä»¿çœŸå·¥å…·ç›¸ç»“åˆï¼Œä½†éšç€ç³»ç»Ÿå¤æ‚æ€§çš„å¢åŠ ï¼Œå…¶æ‰©å±•æ€§æ˜æ˜¾ä¸è¶³ã€‚è¿‘æœŸç ”ç©¶é‡‡ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¥è®¾è®¡åˆç†çš„äººæœ¬åŒ–å®¤å†…å¸ƒå±€ï¼Œç„¶è€Œè¿™äº›æ–¹æ³•æœªè€ƒè™‘åº•å±‚ç‰©ç†åŸç†ï¼Œä½¿å…¶éš¾ä»¥é€‚ç”¨äºè®¾å®šå¯é‡åŒ–è¿è¡Œç›®æ ‡å’Œä¸¥æ ¼ç‰©ç†çº¦æŸçš„æ•°æ®ä¸­å¿ƒè®¾è®¡ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºPhythesisæ¡†æ¶â€”â€”ä¸€ç§èåˆå¤§å‹è¯­è¨€æ¨¡å‹ä¸ç‰©ç†å¼•å¯¼è¿›åŒ–ä¼˜åŒ–çš„åˆ›æ–°æ–¹æ³•ï¼Œæ—¨åœ¨å®ç°â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10611v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10611.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FROCï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹æœºå™¨é—å¿˜çš„ç»Ÿä¸€æ¡†æ¶ä¸é£é™©ä¼˜åŒ–æ§åˆ¶</strong></p>
<p><em>FROC: A Unified Framework with Risk-Optimized Control for Machine Unlearning in LLMs</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºFROCæ¡†æ¶ï¼Œé¦–æ¬¡å°†é£é™©æ§åˆ¶ç†è®ºå¼•å…¥å¤§è¯­è¨€æ¨¡å‹æœºå™¨é—å¿˜é¢†åŸŸï¼Œé€šè¿‡æ¦‚ç‡çº¦æŸé‡åŒ–é—å¿˜é£é™©é¢„ç®—ï¼Œä¸ºå¹³è¡¡é—å¿˜å……åˆ†æ€§ä¸æ¨¡å‹æ•ˆç”¨æä¾›äº†å¯éªŒè¯çš„ä¼˜åŒ–æ–¹æ³•ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ„å»ºäº†ä¸€ä¸ªåŸºäºé£é™©æ§åˆ¶ç†è®ºçš„ç»Ÿä¸€æ¡†æ¶ï¼Œå…è®¸ç”¨æˆ·è®¾å®šé£é™©é¢„ç®—ï¼Œå¹¶ä»¥æ­¤çº¦æŸæŒ‡å¯¼é—å¿˜ç­–ç•¥çš„æ¯”è¾ƒã€å¯è¡Œæ“ä½œåŒºåŸŸçš„è¯†åˆ«ä»¥åŠè¶…å‚æ•°çš„é€‰æ‹©ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æœºå™¨é—å¿˜ï¼ˆMUï¼‰æ—¨åœ¨æ¶ˆé™¤å·²éƒ¨ç½²æ¨¡å‹ä¸­ç‰¹å®šè®­ç»ƒæ ·æœ¬çš„å½±å“ã€‚éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œç®¡ç†å› é—å¿˜ä¸è¶³æˆ–æ•ˆç”¨æŸå¤±è€Œäº§ç”Ÿçš„é£é™©å˜å¾—æ—¥ç›Šå…³é”®ã€‚å½“å‰MUæŠ€æœ¯ç¼ºä¹è¯„ä¼°å’Œæ§åˆ¶è¿™äº›é£é™©çš„æœ‰æ•ˆæœºåˆ¶ï¼Œé˜»ç¢äº†åœ¨å®‰å…¨æ€§ä¸æ•ˆç”¨é—´å–å¾—é€‚å½“å¹³è¡¡çš„ç­–ç•¥é€‰æ‹©ï¼Œå¹¶å¼•å‘å›´ç»•â€è¢«é—å¿˜æƒâ€çš„ä¿¡ä»»æ‹…å¿§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºFROCâ€”â€”ä¸€ä¸ªä¸ºLLMæœºå™¨é—å¿˜è®¾è®¡çš„ã€å…·å¤‡é£é™©ä¼˜åŒ–æ§åˆ¶çš„ç»Ÿä¸€æ¡†æ¶ã€‚FROCå›´ç»•ä¿å½¢é£æ ¼çš„é£é™©æ§åˆ¶å…¬å¼æ„å»ºï¼Œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13337v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13337.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºæ®‹å·®æ ¡æ­£æ‰©æ•£æ¨¡å‹çš„ä¸­å›½åŒºåŸŸ3å…¬é‡Œé™å°ºåº¦ç ”ç©¶</strong></p>
<p><em>China Regional 3km Downscaling Based on Residual Corrective Diffusion Model</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– æ°”è±¡/åœ°çƒç§‘å­¦ç±»æœŸåˆŠï¼ˆå¦‚ Journal of Advances in Modeling Earth Systems, Geophysical Research Lettersï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: å°†åŸºäºæ®‹å·®æ ¡æ­£çš„æ‰©æ•£æ¨¡å‹ï¼ˆCorrDiffï¼‰åº”ç”¨äºä¸­å›½åŒºåŸŸï¼Œå®ç°äº†æ¯”åŸå·¥ä½œåŒºåŸŸæ‰©å¤§è¿‘40å€ã€ä¸”åŒ…å«é«˜ç©ºå˜é‡ï¼ˆ6ä¸ªæ°”å‹å±‚ï¼‰çš„å¤§èŒƒå›´æ°”è±¡é™å°ºåº¦ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é‡‡ç”¨åŸºäºæ‰©æ•£æ¨¡å‹çš„ç»Ÿè®¡é™å°ºåº¦æ¡†æ¶CorrDiffï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ å»ºç«‹ä½åˆ†è¾¨ç‡ä¸é«˜åˆ†è¾¨ç‡å†å²æ•°æ®é—´çš„ç»Ÿè®¡å…³ç³»ï¼Œä»¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡æ°”è±¡é¢„æŠ¥ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ•°å€¼å¤©æ°”é¢„æŠ¥ä¸­çš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜æ˜¯å¦‚ä½•é«˜æ•ˆç”Ÿæˆé«˜åˆ†è¾¨ç‡é¢„æŠ¥ã€‚å¸¸è§çš„è§£å†³æ–¹æ¡ˆæ˜¯å¯¹å…¨çƒæ¨¡å¼è¾“å‡ºé‡‡ç”¨é™å°ºåº¦æ–¹æ³•ï¼Œä¸»è¦åŒ…æ‹¬åŠ¨åŠ›é™å°ºåº¦å’Œç»Ÿè®¡é™å°ºåº¦ã€‚æœ¬ç ”ç©¶èšç„¦äºç»Ÿè®¡é™å°ºåº¦æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç»Ÿè®¡æ¨¡å‹å»ºç«‹ä½åˆ†è¾¨ç‡ä¸é«˜åˆ†è¾¨ç‡å†å²æ•°æ®ä¹‹é—´çš„ç»Ÿè®¡å…³ç³»ã€‚æ·±åº¦å­¦ä¹ å·²æˆä¸ºè¯¥ä»»åŠ¡çš„æœ‰åŠ›å·¥å…·ï¼Œå‚¬ç”Ÿäº†å¤šç§å¯ç›´æ¥åº”ç”¨äºé™å°ºåº¦çš„é«˜æ€§èƒ½è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼Œä¾‹å¦‚æ‰©æ•£æ¨¡å‹å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€‚æœ¬ç ”ç©¶åŸºäºåä¸ºCorrDiffçš„æ‰©æ•£å¼é™å°ºåº¦æ¡†æ¶ã€‚ä¸CorrDiâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.05377v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.05377.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FlashFuserï¼šé€šè¿‡å†…æ ¸é—´è¿æ¥æ‰©å±•è®¡ç®—å¯†é›†å‹ç®—å­èåˆè§„æ¨¡</strong></p>
<p><em>FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>ASPLOS 2025 æˆ– OSDI 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: é¦–æ¬¡æå‡ºåˆ©ç”¨ç°ä»£GPUçš„æ ¸é—´è¿æ¥æœºåˆ¶ï¼ˆåˆ†å¸ƒå¼å…±äº«å†…å­˜ï¼ŒDSMï¼‰è¿›è¡Œå†…æ ¸èåˆçš„ç¼–è¯‘å™¨æ¡†æ¶ï¼Œçªç ´äº†ä¼ ç»Ÿèåˆç­–ç•¥å—é™äºæœ¬åœ°æš‚å­˜å™¨å®¹é‡çš„ç“¶é¢ˆã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æå‡ºä¸€ä¸ªåŸºäºDSMçš„é€šä¿¡æŠ½è±¡ï¼Œå°†æˆç†Ÿçš„èåˆæŠ€æœ¯æ‰©å±•è‡³DSMé¢†åŸŸï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªç¼–è¯‘å™¨æ¡†æ¶æ¥åˆ©ç”¨è¿™ä¸€æ›´å¤§ã€é«˜å¸¦å®½çš„ç‰‡ä¸Šå†…å­˜æ± ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: è®¡ç®—ååé‡çš„æ‰©å±•æŒç»­è¶…è¶Šå†…å­˜å¸¦å®½çš„æå‡ï¼Œä½¿å¾—è®¸å¤šæ·±åº¦å­¦ä¹ å·¥ä½œè´Ÿè½½å—é™äºå†…å­˜ã€‚å†…æ ¸èåˆæ˜¯ç¼“è§£è¿™ä¸€é—®é¢˜çš„å…³é”®æŠ€æœ¯ï¼Œä½†ç°æœ‰ç¼–è¯‘å™¨å’Œæ¡†æ¶çš„èåˆç­–ç•¥ä»…é™äºä½¿ç”¨æœ¬åœ°æš‚å­˜å†…å­˜ã€‚å½“ä¸­é—´ç»“æœè¶…å‡ºæœ‰é™å®¹é‡ï¼ˆå¦‚FFNï¼‰æ—¶ï¼Œèåˆä¾¿ä¼šå¤±è´¥ã€‚å°½ç®¡ç°ä»£GPUï¼ˆå¦‚è‹±ä¼Ÿè¾¾H100ï¼‰ç°å·²å¼•å…¥ç§°ä¸ºåˆ†å¸ƒå¼å…±äº«å†…å­˜ï¼ˆDSMï¼‰çš„æ ¸å¿ƒé—´è¿æ¥æœºåˆ¶â€”â€”æä¾›äº†ä¸€ä¸ªæ›´å¤§ã€é«˜å¸¦å®½ã€ä½å»¶è¿Ÿçš„ç‰‡ä¸Šå†…å­˜æ± â€”â€”ä½†è¿™ä¸€ç¡¬ä»¶æ½œåŠ›å°šæœªè¢«è½¯ä»¶æ¡†æ¶æ‰€åˆ©ç”¨ã€‚ä¸ºå¼¥åˆè¿™ä¸€å·®è·â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12949v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12949.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ æ·±åº¦å­¦ä¹ åœ¨ç”Ÿç‰©æ•°æ®å‹ç¼©ä¸­çš„åº”ç”¨</strong></p>
<p><em>Application of Deep Learning in Biological Data Compression</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– ç”Ÿç‰©ä¿¡æ¯å­¦/è®¡ç®—ç”Ÿç‰©å­¦é¢†åŸŸçš„ä¼šè®®ï¼ˆå¦‚ ISMB æˆ– RECOMBï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åŸºäºéšå¼ç¥ç»è¡¨ç¤ºï¼ˆINRï¼‰çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå‹ç¼©å†·å†»ç”µé•œï¼ˆCryo-EMï¼‰ç”Ÿç‰©æ•°æ®ï¼Œå¹¶é€šè¿‡å¼•å…¥ä½ç½®ç¼–ç å’ŒåŠ æƒå‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°æ¥æå‡é‡å»ºç²¾åº¦ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•é¦–å…ˆæ ¹æ®å¯†åº¦é˜ˆå€¼æå–æ–‡ä»¶çš„äºŒå€¼åŒ–å›¾è°±ï¼Œåˆ©ç”¨GZIPå‹ç¼©å…¶é‡å¤ç»“æ„ï¼›éšåè®­ç»ƒç¥ç»ç½‘ç»œç¼–ç ç©ºé—´å¯†åº¦ä¿¡æ¯ï¼Œæœ€ç»ˆå­˜å‚¨ç½‘ç»œå‚æ•°å’Œå¯å­¦ä¹ çš„æ½œåœ¨å‘é‡ä»¥å®ç°å‹ç¼©ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ä½æ¸©ç”µå­æ˜¾å¾®é•œï¼ˆCryo-EMï¼‰å·²æˆä¸ºè·å–é«˜åˆ†è¾¨ç‡ç”Ÿç‰©ç»“æ„çš„é‡è¦å·¥å…·ã€‚å°½ç®¡å…¶åœ¨å¯è§†åŒ–æ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œä½†Cryo-EMæ•°æ®æ–‡ä»¶åºå¤§çš„å­˜å‚¨è§„æ¨¡ç»™ç ”ç©¶äººå‘˜å’Œæ•™è‚²å·¥ä½œè€…å¸¦æ¥äº†æ˜¾è‘—æŒ‘æˆ˜ã€‚æœ¬æ–‡ç ”ç©¶äº†æ·±åº¦å­¦ä¹ æŠ€æœ¯â€”â€”ç‰¹åˆ«æ˜¯éšå¼ç¥ç»è¡¨ç¤ºï¼ˆINRï¼‰â€”â€”åœ¨Cryo-EMç”Ÿç‰©æ•°æ®å‹ç¼©ä¸­çš„åº”ç”¨ã€‚æ‰€æå‡ºçš„æ–¹æ³•é¦–å…ˆæ ¹æ®å¯†åº¦é˜ˆå€¼æå–æ¯ä¸ªæ–‡ä»¶çš„äºŒå€¼åŒ–å›¾è°±ã€‚å¯†åº¦å›¾è°±å…·æœ‰é«˜åº¦é‡å¤æ€§ï¼Œå¯é€šè¿‡GZIPç®—æ³•å®ç°é«˜æ•ˆå‹ç¼©ã€‚éšåç¥ç»ç½‘ç»œé€šè¿‡è®­ç»ƒâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12975v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12975.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åœ¨å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£ï¼Œè¯„è®ºå¯¹æ¨èè¿˜é‡è¦å—ï¼Ÿ</strong></p>
<p><em>Do Reviews Matter for Recommendations in the Era of Large Language Models?</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>SIGIR 2025 æˆ– TheWebConf (WWW) 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£ï¼Œç”¨æˆ·è¯„è®ºæ˜¯å¦ä»æ˜¯æ¨èç³»ç»Ÿçš„å…³é”®ä¿¡æ¯æ¥æºï¼Œå¹¶é€šè¿‡å¼•å…¥ä¸€ä¸ªåä¸ºRAREvalçš„åŸºå‡†è¯„ä¼°æ¡†æ¶ï¼Œå…¨é¢è¯„ä¼°äº†æ–‡æœ¬è¯„è®ºå¯¹æ¨èæ€§èƒ½çš„è´¡çŒ®ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è®ºæ–‡é€šè¿‡åœ¨å¤§è¯­è¨€æ¨¡å‹ä¸Šè¿›è¡Œé›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒåœºæ™¯ä¸‹çš„å¹¿æ³›å®éªŒï¼Œå¯¹æ¯”äº†æ·±åº¦å­¦ä¹ æ–¹æ³•ä¸LLMæ–¹æ³•ï¼Œä»¥åˆ†æè¯„è®ºåœ¨æ¨èä¸­ä½œç”¨çš„æ¼”å˜ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œæ¨èç³»ç»Ÿé¢†åŸŸæ­£åœ¨ç»å†é‡å¤§å˜é©ã€‚ä¼ ç»Ÿä¸Šï¼Œç”¨æˆ·è¯„è®ºä½œä¸ºä¸°å¯Œä¸Šä¸‹æ–‡ä¿¡æ¯çš„å…³é”®æ¥æºï¼Œå¯¹æå‡æ¨èè´¨é‡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œéšç€LLMå±•ç°å‡ºå‰æ‰€æœªæœ‰çš„ç†è§£å’Œç”Ÿæˆç±»äººæ–‡æœ¬çš„èƒ½åŠ›ï¼Œè¿™å¼•å‘äº†ä¸€ä¸ªé—®é¢˜ï¼šåœ¨LLMæ—¶ä»£ï¼Œæ˜¾å¼çš„ç”¨æˆ·è¯„è®ºæ˜¯å¦ä»ç„¶ä¸å¯æˆ–ç¼ºï¼Ÿæœ¬æ–‡é€šè¿‡æ¯”è¾ƒæ·±åº¦å­¦ä¹ æ–¹æ³•å’ŒLLMæ–¹æ³•ï¼Œå¯¹æ–‡æœ¬è¯„è®ºåœ¨æ¨èç³»ç»Ÿä¸­ä¸æ–­æ¼”å˜çš„è§’è‰²è¿›è¡Œäº†ç³»ç»Ÿæ€§ç ”ç©¶ã€‚ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬åœ¨å…«ä¸ªå…¬å…±æ•°æ®é›†ä¸Šå¯¹LLMè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12978v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12978.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TWLRï¼šåŸºäºæ–‡æœ¬å¼•å¯¼çš„å¼±ç›‘ç£ç—…ç¶å®šä½ä¸ä¸¥é‡åº¦å›å½’ç”¨äºå¯è§£é‡Šæ€§ç³–å°¿ç—…è§†ç½‘è†œç—…å˜åˆ†çº§</strong></p>
<p><em>TWLR: Text-Guided Weakly-Supervised Lesion Localization and Severity Regression for Explainable Diabetic Retinopathy Grading</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>MICCAI 2024 æˆ– IEEE Transactions on Medical Imaging</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ä¸ªä¸¤é˜¶æ®µå¯è§£é‡Šæ€§ç³–å°¿ç—…è§†ç½‘è†œç—…å˜è¯„ä¼°æ¡†æ¶TWLRï¼Œåˆ›æ–°æ€§åœ°å°†é¢†åŸŸçœ¼ç§‘çŸ¥è¯†é€šè¿‡æ–‡æœ¬åµŒå…¥æ•´åˆåˆ°è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­ï¼Œå¹¶åˆ©ç”¨å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²å®ç°ç—…ç¶å®šä½ä¸ä¸¥é‡æ€§å›å½’ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: ç¬¬ä¸€é˜¶æ®µä½¿ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è”åˆè¿›è¡ŒDRåˆ†çº§å’Œç—…ç¶åˆ†ç±»ï¼Œå°†åŒ»å­¦è¯­ä¹‰æ¦‚å¿µä¸è§†è§‰ç‰¹å¾å…³è”ï¼›ç¬¬äºŒé˜¶æ®µåŸºäºå¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„è¿­ä»£ä¸¥é‡æ€§å›å½’æ¡†æ¶ï¼Œé€šè¿‡æ¸è¿›ä¿®å¤æœºåˆ¶ç”Ÿæˆç—…ç¶æ˜¾è‘—å›¾ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å‡†ç¡®çš„åŒ»å­¦å›¾åƒåˆ†æèƒ½æå¤§è¾…åŠ©ä¸´åºŠè¯Šæ–­ï¼Œä½†å…¶æ•ˆæœä¾èµ–äºé«˜è´¨é‡çš„ä¸“å®¶æ ‡æ³¨ã€‚è·å–åŒ»å­¦å›¾åƒï¼ˆå°¤å…¶æ˜¯çœ¼åº•å›¾åƒï¼‰çš„åƒç´ çº§æ ‡æ³¨ä»ç„¶æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶ã€‚ä¸æ­¤åŒæ—¶ï¼Œå°½ç®¡æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å½±åƒé¢†åŸŸå–å¾—æˆåŠŸï¼Œå…¶å¯è§£é‡Šæ€§çš„ç¼ºä¹é™åˆ¶äº†ä¸´åºŠåº”ç”¨çš„æ¨å¹¿ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºTWLRâ€”â€”ä¸€ä¸ªç”¨äºå¯è§£é‡Šæ€§ç³–å°¿ç—…è§†ç½‘è†œç—…å˜ï¼ˆDRï¼‰è¯„ä¼°çš„ä¸¤é˜¶æ®µæ¡†æ¶ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œè§†è§‰è¯­è¨€æ¨¡å‹å°†ç‰¹å®šé¢†åŸŸçš„çœ¼ç§‘çŸ¥è¯†æ•´åˆåˆ°æ–‡æœ¬åµŒå…¥ä¸­ï¼Œè”åˆæ‰§è¡ŒDRåˆ†çº§å’Œç—…ç¶åˆ†ç±»ï¼Œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13008v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13008.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ç£å…±æŒ¯å¼¹æ€§æˆåƒä¸­åŸºäºæ·±åº¦å­¦ä¹ çš„å‰ªåˆ‡æ¨¡é‡åæ¼”æ¡†æ¶ï¼ˆDIMEï¼‰</strong></p>
<p><em>Deep Learning-Driven Inversion Framework for Shear Modulus Estimation in Magnetic Resonance Elastography (DIME)</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>Medical Image Analysis æˆ– IEEE Transactions on Medical Imagingã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„ç£å…±æŒ¯å¼¹æ€§æˆåƒå‰ªåˆ‡æ¨¡é‡åæ¼”æ¡†æ¶ï¼ˆDIMEï¼‰ï¼Œæ—¨åœ¨å…‹æœä¼ ç»Ÿå¤šæ¨¡æ€ç›´æ¥åæ¼”ç®—æ³•å¯¹å™ªå£°æ•æ„Ÿã€ä¾èµ–å‡åŒ€ä»‹è´¨å‡è®¾çš„å±€é™æ€§ï¼Œæå‡åæ¼”çš„é²æ£’æ€§ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•åˆ©ç”¨æœ‰é™å…ƒæ¨¡æ‹Ÿç”Ÿæˆçš„ä½ç§»åœº-åˆšåº¦å›¾å¯¹è¿›è¡Œè®­ç»ƒï¼Œå¹¶é€šè¿‡åœ¨å°å›¾åƒå—ä¸Šè¿›è¡Œè®­ç»ƒæ¥æ•æ‰å±€éƒ¨æ³¢åŠ¨è¡Œä¸ºï¼Œä»¥å¢å¼ºå¯¹å…¨å±€å›¾åƒå˜åŒ–çš„é²æ£’æ€§ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å¤šæ¨¡æ€ç›´æ¥åæ¼”ï¼ˆMMDIï¼‰ç®—æ³•åœ¨ç£å…±æŒ¯å¼¹æ€§æˆåƒï¼ˆMREï¼‰ä¸­è¢«å¹¿æ³›ç”¨äºä¼°è®¡ç»„ç»‡å‰ªåˆ‡åˆšåº¦ã€‚ç„¶è€Œï¼ŒMMDIä¾èµ–äºäº¥å§†éœå…¹æ–¹ç¨‹ï¼Œè¯¥æ–¹ç¨‹å‡è®¾æ³¢åœ¨å‡åŒ€ã€åŒè´¨ä¸”æ— é™çš„ä»‹è´¨ä¸­ä¼ æ’­ã€‚æ­¤å¤–ï¼Œæ‹‰æ™®æ‹‰æ–¯ç®—å­çš„ä½¿ç”¨ä½¿MMDIå¯¹å™ªå£°é«˜åº¦æ•æ„Ÿï¼Œä»è€Œå½±å“äº†åˆšåº¦ä¼°è®¡çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºMREå‰ªåˆ‡æ¨¡é‡ä¼°è®¡çš„æ·±åº¦å­¦ä¹ é©±åŠ¨åæ¼”æ¡†æ¶ï¼ˆDIMEï¼‰ï¼Œæ—¨åœ¨å¢å¼ºåæ¼”çš„é²æ£’æ€§ã€‚DIMEé€šè¿‡æœ‰é™å…ƒå»ºæ¨¡ï¼ˆFEMï¼‰æ¨¡æ‹Ÿç”Ÿæˆçš„ä½ç§»åœºâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13010v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13010.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ é€šè¿‡ç‰¹å¾å·¥ç¨‹å¢å¼ºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ</strong></p>
<p><em>Enhancing Physics-Informed Neural Networks Through Feature Engineering</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>ICLR 2025 æˆ– NeurIPS 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åä¸ºSAFE-NETçš„å•å±‚è‡ªé€‚åº”ç‰¹å¾å·¥ç¨‹ç½‘ç»œï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•ï¼Œèƒ½ä»¥æ›´å°‘çš„å‚æ•°å®ç°è¯¯å·®æ•°é‡çº§çš„é™ä½å’Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•åŸºäºç®€åŒ–çš„å•éšè—å±‚ç½‘ç»œæ¶æ„ï¼Œç»“åˆå‚…é‡Œå¶ç‰¹å¾å’Œä¸€ç§æ”¹è¿›PINNä¼˜åŒ–é—®é¢˜æ¡ä»¶æ•°çš„æœ‰æ•ˆä¼˜åŒ–å™¨ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNsï¼‰æ—¨åœ¨é€šè¿‡æ·±åº¦å­¦ä¹ æ±‚è§£åå¾®åˆ†æ–¹ç¨‹ã€‚å½“å‰ä¸»æµæ–¹æ³•é‡‡ç”¨å…¨è¿æ¥å¤šå±‚æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œéœ€è¦é•¿æ—¶é—´è®­ç»ƒæ‰èƒ½è¾¾åˆ°ä¸­ç­‰ç²¾åº¦ï¼Œè€Œè¿‘æœŸç‰¹å¾å·¥ç¨‹ç ”ç©¶å®ç°äº†æ›´é«˜ç²¾åº¦ä¸æ›´å¿«æ”¶æ•›ã€‚æœ¬æ–‡æå‡ºSAFE-NETâ€”â€”ä¸€ç§å•å±‚è‡ªé€‚åº”ç‰¹å¾å·¥ç¨‹ç½‘ç»œï¼Œç›¸æ¯”åŸºçº¿ç‰¹å¾å·¥ç¨‹æ–¹æ³•ï¼Œè¯¥ç½‘ç»œä»¥æ›´å°‘å‚æ•°å®ç°è¯¯å·®æ•°é‡çº§é™ä½ã€‚SAFE-NETå›å½’æœºå™¨å­¦ä¹ åŸºæœ¬æ€æƒ³ï¼Œé‡‡ç”¨å‚…é‡Œå¶ç‰¹å¾ã€ç®€åŒ–çš„å•éšè—å±‚ç½‘ç»œæ¶æ„ï¼Œä»¥åŠèƒ½æ”¹å–„PINNä¼˜åŒ–é—®é¢˜æ¡ä»¶â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.07209v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.07209.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ é¢å‘æ·±åº¦å­¦ä¹ æ¯«ç±³æ³¢é›·è¾¾æ„ŸçŸ¥çš„è·¨ç¯å¢ƒæ³›åŒ–èƒ½åŠ›ç»¼åˆéƒ¨ç½²è¯„ä¼°</strong></p>
<p><em>Comprehensive Deployment-Oriented Assessment for Cross-Environment Generalization in Deep Learning-Based mmWave Radar Sensing</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE Internet of Things Journal æˆ– IEEE Sensors Journalã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: é¦–æ¬¡å¯¹æ·±åº¦å­¦ä¹ å°„é¢‘æ„ŸçŸ¥ä¸­çš„ç©ºé—´æ³›åŒ–æŠ€æœ¯è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶å‘ç°åŸºäºSigmoidçš„å¹…åº¦åŠ æƒæ–¹æ³•åœ¨è·¨ç¯å¢ƒäººå‘˜è®¡æ•°ä»»åŠ¡ä¸­è¡¨ç°æœ€ä¼˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: ç³»ç»Ÿç ”ç©¶äº†å¹…åº¦ç»Ÿè®¡é¢„å¤„ç†ã€é¢‘åŸŸæ»¤æ³¢ã€è‡ªç¼–ç å™¨èƒŒæ™¯æŠ‘åˆ¶ã€æ•°æ®å¢å¼ºå’Œè¿ç§»å­¦ä¹ ç­‰å¤šç§æ–¹æ³•ï¼Œä»¥æå‡FMCW MIMOé›·è¾¾åœ¨å®¤å†…äººå‘˜è®¡æ•°ä¸­çš„è·¨ç¯å¢ƒæ³›åŒ–èƒ½åŠ›ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æœ¬ç ”ç©¶é¦–æ¬¡å¯¹ç©ºé—´æ³›åŒ–æŠ€æœ¯è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œè¿™äº›æŠ€æœ¯å¯¹äºåŸºäºæ·±åº¦å­¦ä¹ çš„å°„é¢‘ä¼ æ„Ÿå®é™…éƒ¨ç½²è‡³å…³é‡è¦ã€‚èšç„¦äºä½¿ç”¨è°ƒé¢‘è¿ç»­æ³¢å¤šè¾“å…¥å¤šè¾“å‡ºé›·è¾¾è¿›è¡Œå®¤å†…äººæ•°ç»Ÿè®¡çš„åœºæ™¯ï¼Œæˆ‘ä»¬ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†å¤šç§æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºå¹…åº¦çš„ç»Ÿè®¡é¢„å¤„ç†ï¼ˆSå‹å‡½æ•°åŠ æƒä¸é˜ˆå€¼å½’é›¶ï¼‰ã€é¢‘åŸŸæ»¤æ³¢ã€åŸºäºè‡ªç¼–ç å™¨çš„èƒŒæ™¯æŠ‘åˆ¶ã€æ•°æ®å¢å¼ºç­–ç•¥ä»¥åŠè¿ç§»å­¦ä¹ ã€‚é€šè¿‡åœ¨ä¸¤ç§ä¸åŒå¸ƒå±€ç¯å¢ƒä¸­é‡‡é›†çš„å®éªŒæ•°æ®è¡¨æ˜ï¼ŒåŸºäºSå‹å‡½æ•°çš„å¹…åº¦åŠ æƒæ–¹æ³•åœ¨è·¨ç¯å¢ƒæ€§èƒ½ä¸ŠæŒç»­è¡¨ç°ä¼˜å¼‚ï¼Œä¸åŸºçº¿æ–¹æ³•â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13018v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13018.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºæ— çº¿ç”µæ³¢æ„ŸçŸ¥çš„äººç±»ä¼°è®¡ä¸­è§„åˆ™æ–¹æ³•ã€æœºå™¨å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ çš„ç»¼åˆè¯„ä¼°ï¼šå‡†ç¡®æ€§ã€ç©ºé—´æ³›åŒ–æ€§ä¸è¾“å‡ºç²’åº¦æƒè¡¡</strong></p>
<p><em>Comprehensive Evaluation of Rule-Based, Machine Learning, and Deep Learning in Human Estimation Using Radio Wave Sensing: Accuracy, Spatial Generalization, and Output Granularity Trade-offs</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE Internet of Things Journal æˆ– IEEE Sensors Journal</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: é¦–æ¬¡åœ¨è°ƒé¢‘è¿ç»­æ³¢MIMOé›·è¾¾äººä½“æ„ŸçŸ¥ä»»åŠ¡ä¸­ï¼Œç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†åŸºäºè§„åˆ™çš„æ–¹æ³•ã€ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶é‡ç‚¹åˆ†æäº†å®ƒä»¬åœ¨ç²¾åº¦ã€ç©ºé—´æ³›åŒ–èƒ½åŠ›å’Œè¾“å‡ºç²’åº¦ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: åœ¨ä¸¤ç§ä¸åŒå¸ƒå±€çš„å®¤å†…ç¯å¢ƒä¸­ï¼Œè¯„ä¼°äº†äº”ç§æ–¹æ³•ï¼šä¸€ç§åŸºäºè§„åˆ™çš„è¿é€šåˆ†é‡æ–¹æ³•ï¼›ä¸‰ç§ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆKè¿‘é‚»ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºï¼‰ï¼›ä»¥åŠä¸€ç§ç»“åˆå·ç§¯ç¥ç»ç½‘ç»œå’Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æœ¬ç ”ç©¶é¦–æ¬¡ç³»ç»Ÿæ¯”è¾ƒäº†è°ƒé¢‘è¿ç»­æ³¢å¤šè¾“å…¥å¤šè¾“å‡ºé›·è¾¾åœ¨æ— çº¿ç”µæ³¢æ„ŸçŸ¥ä¸­åŸºäºè§„åˆ™çš„æ–¹æ³•ã€ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ä¸æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨ä¸¤ç§ä¸åŒå¸ƒå±€çš„å®¤å†…ç¯å¢ƒä¸­ï¼Œå¯¹äº”ç§æ–¹æ³•è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼šåŸºäºè§„åˆ™çš„è¿é€šåˆ†é‡æ³•ï¼›ä¸‰ç§ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆkè¿‘é‚»ç®—æ³•ã€éšæœºæ£®æ—å’Œæ”¯æŒå‘é‡æœºï¼‰ï¼›ä»¥åŠç»“åˆå·ç§¯ç¥ç»ç½‘ç»œä¸é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚åœ¨è®­ç»ƒç¯å¢ƒä¸­ï¼Œå·ç§¯ç¥ç»ç½‘ç»œ-é•¿çŸ­æ—¶è®°å¿†æ¨¡å‹å–å¾—äº†æœ€é«˜å‡†ç¡®ç‡ï¼Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è¡¨ç°ä¸­ç­‰ã€‚ç„¶è€Œåœ¨æ–°â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13031v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13031.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºè‡ªç¼–ç å™¨è¿ç§»å­¦ä¹ çš„å¤šä¿çœŸåº¦æ°”åŠ¨æ•°æ®èåˆ</strong></p>
<p><em>Multi-fidelity aerodynamic data fusion by autoencoder transfer learning</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>AIAA Journal æˆ– Journal of Computational Physics</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§ç»“åˆè‡ªç¼–ç å™¨è¿ç§»å­¦ä¹ å’Œæ–°å‹å¤šåˆ†å½¢ä¿å½¢é¢„æµ‹ç­–ç•¥çš„å¤šä¿çœŸåº¦æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ•°æ®æåº¦ç¨€ç¼ºçš„æƒ…å†µä¸‹å®ç°ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ç©ºæ°”åŠ¨åŠ›å­¦æ•°æ®èåˆã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: åˆ©ç”¨ä¸°å¯Œçš„ä½ä¿çœŸåº¦æ•°æ®å­¦ä¹ ç´§å‡‘çš„æ½œåœ¨ç‰©ç†è¡¨ç¤ºä½œä¸ºå†»ç»“çŸ¥è¯†åº“ï¼Œéšåä½¿ç”¨ç¨€ç¼ºçš„é«˜ä¿çœŸåº¦æ ·æœ¬å¯¹è§£ç å™¨è¿›è¡Œå¾®è°ƒï¼Œå¹¶å¼•å…¥å¤šåˆ†å½¢ä¿å½¢é¢„æµ‹ç­–ç•¥é‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç²¾ç¡®çš„ç©ºæ°”åŠ¨åŠ›å­¦é¢„æµ‹é€šå¸¸ä¾èµ–äºé«˜ä¿çœŸåº¦ä»¿çœŸï¼Œä½†å…¶é«˜æ˜‚çš„è®¡ç®—æˆæœ¬ä¸¥é‡åˆ¶çº¦äº†å…¶åœ¨æ•°æ®é©±åŠ¨å»ºæ¨¡ä¸­çš„åº”ç”¨ã€‚è¿™ä¸€å±€é™æ€§æ¨åŠ¨äº†å¤šä¿çœŸåº¦ç­–ç•¥çš„å‘å±•ï¼Œè¯¥ç­–ç•¥èƒ½åœ¨ä¸ç‰ºç‰²ç²¾åº¦çš„æƒ…å†µä¸‹åˆ©ç”¨ä½æˆæœ¬çš„ä½ä¿çœŸåº¦ä¿¡æ¯ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šä¿çœŸåº¦æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå°†åŸºäºè‡ªåŠ¨ç¼–ç å™¨çš„è¿ç§»å­¦ä¹ ä¸æ–°å¼€å‘çš„å¤šåˆ†é›†ä¿å½¢é¢„æµ‹ç­–ç•¥ç›¸ç»“åˆï¼Œåœ¨æç«¯æ•°æ®ç¨€ç¼ºæ¡ä»¶ä¸‹å®ç°ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ç©ºæ°”åŠ¨åŠ›å­¦æ•°æ®èåˆã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä¸°å¯Œçš„ä½ä¿çœŸåº¦æ•°æ®å­¦ä¹ ç´§å‡‘çš„æ½œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13069v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13069.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FID-Netï¼šä¸€ç§ç”¨äºæ£®æ—è™«å®³æ£€æµ‹çš„ç‰¹å¾å¢å¼ºæ·±åº¦å­¦ä¹ ç½‘ç»œ</strong></p>
<p><em>FID-Net: A Feature-Enhanced Deep Learning Network for Forest Infestation Detection</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE Transactions on Geoscience and Remote Sensing æˆ– Remote Sensing</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºFID-Netæ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥è½»é‡çº§ç‰¹å¾å¢å¼ºæ¨¡å—ã€è‡ªé€‚åº”å¤šå°ºåº¦ç‰¹å¾èåˆæ¨¡å—å’Œé«˜æ•ˆé€šé“æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»æ— äººæœºå¯è§å…‰å›¾åƒä¸­æ£€æµ‹å—è™«å®³æ ‘æœ¨ï¼Œå¹¶æ„å»ºäº†åŸºäºä¸‰ä¸ªç©ºé—´åº¦é‡çš„è™«å®³æƒ…å†µåˆ†ææ¡†æ¶ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: åŸºäºYOLOv8næ”¹è¿›ï¼Œé€šè¿‡ç‰¹å¾å¢å¼ºæ¨¡å—æå–ç—…å®³æ•æ„Ÿç‰¹å¾ï¼ŒèåˆRGBå’Œå¢å¼ºç‰¹å¾çš„åŒåˆ†æ”¯ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨é«˜æ•ˆé€šé“æ³¨æ„åŠ›ä¼˜åŒ–åˆ¤åˆ«ä¿¡æ¯ï¼Œæœ€ç»ˆç»“åˆæ ¸å¯†åº¦ä¼°è®¡ã€é‚»åŸŸè¯„ä¼°å’ŒDBSCANèšç±»è¿›è¡Œè™«å®³ç©ºé—´æ¨¡å¼åˆ†æã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ£®æ—ç—…è™«å®³å¨èƒç”Ÿæ€ç³»ç»Ÿç¨³å®šï¼ŒäºŸéœ€é«˜æ•ˆç›‘æµ‹æ‰‹æ®µã€‚ä¸ºå…‹æœä¼ ç»Ÿæ–¹æ³•åœ¨å¤§èŒƒå›´ã€ç»†ç²’åº¦æ£€æµ‹ä¸­çš„å±€é™ï¼Œæœ¬ç ”ç©¶èšç„¦äºç²¾å‡†è¯†åˆ«æŸ“ç—…æ ‘æœ¨å¹¶è§£æè™«å®³åˆ†å¸ƒæ¨¡å¼ã€‚æˆ‘ä»¬æå‡ºFID-Netæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡æ— äººæœºå¯è§å…‰å½±åƒæ£€æµ‹ç—…è™«å®³æ ‘æœ¨ï¼Œå¹¶å€ŸåŠ©ä¸‰é¡¹ç©ºé—´åº¦é‡å®ç°è™«æƒ…åˆ†æã€‚åŸºäºYOLOv8næ¶æ„ï¼ŒFID-Netå¼•å…¥è½»é‡åŒ–ç‰¹å¾å¢å¼ºæ¨¡å—æå–ç—…å®³æ•æ„Ÿç‰¹å¾ï¼Œé‡‡ç”¨è‡ªé€‚åº”å¤šå°ºåº¦ç‰¹å¾èåˆæ¨¡å—å¯¹é½å¹¶èåˆåŒåˆ†æ”¯ç‰¹å¾ï¼ˆåŸå§‹RGBä¸å¢å¼ºç‰¹å¾ï¼‰ï¼Œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13104v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13104.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LeafTrackNetï¼šä¸€ç§ç”¨äºä¿¯è§†æ¤ç‰©è¡¨å‹åˆ†æä¸­ç¨³å¥å¶ç‰‡è¿½è¸ªçš„æ·±åº¦å­¦ä¹ æ¡†æ¶</strong></p>
<p><em>LeafTrackNet: A Deep Learning Framework for Robust Leaf Tracking in Top-Down Plant Phenotyping</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ECCV 2024ï¼ˆè®¡ç®—æœºè§†è§‰é¡¶ä¼šï¼‰ï¼Œæˆ– Plant Phenomicsï¼ˆæ¤ç‰©è¡¨å‹å­¦é¢†åŸŸæœŸåˆŠï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†é¦–ä¸ªé’ˆå¯¹å¤æ‚ä½œç‰©ï¼ˆæ²¹èœï¼‰çš„å¤§è§„æ¨¡å¶ç‰‡è¿½è¸ªæ•°æ®é›†CanolaTrackï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªä¸“ç”¨äºæ¤ç‰©è¡¨å‹åˆ†æçš„é²æ£’å¶ç‰‡è¿½è¸ªæ·±åº¦å­¦ä¹ æ¡†æ¶LeafTrackNetã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: LeafTrackNetæ˜¯ä¸€ä¸ªé«˜æ•ˆçš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆç›®æ ‡æ£€æµ‹ä¸æ•°æ®å…³è”ï¼Œä¸“é—¨å¤„ç†åŠ¨æ€æ¤ç‰©ç”Ÿé•¿åœºæ™¯ä¸­çš„å¶ç‰‡è¿½è¸ªé—®é¢˜ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åœ¨å•å¶å±‚é¢è¿›è¡Œé«˜åˆ†è¾¨ç‡è¡¨å‹åˆ†æï¼Œèƒ½å¤Ÿä¸ºæ¤ç‰©å‘è‚²å’Œèƒè¿«å“åº”æä¾›ç²¾ç»†åŒ–çš„æ´å¯Ÿã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹ç¨³å¥çš„è¿½è¸ªæ–¹æ³•â€”â€”ç‰¹åˆ«æ˜¯é’ˆå¯¹æ²¹èœç­‰ç»“æ„å¤æ‚çš„ä½œç‰©ï¼Œç²¾å‡†å¶ç‰‡æ—¶åºè¿½è¸ªçš„å®Œæ•´æ½œåŠ›åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ç°æœ‰çš„æ¤ç‰©ä¸“ç”¨è¿½è¸ªæ–¹æ³•é€šå¸¸å±€é™äºå°è§„æ¨¡ç‰©ç§æˆ–ä¾èµ–å—é™çš„æˆåƒæ¡ä»¶ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œé€šç”¨çš„å¤šç›®æ ‡è¿½è¸ªæ–¹æ³•å¹¶éä¸ºåŠ¨æ€ç”Ÿç‰©åœºæ™¯è®¾è®¡ã€‚åœ¨çœŸå®æ¡ä»¶ä¸‹é‡‡é›†çš„å¤§è§„æ¨¡æ•°æ®é›†çš„ç¼ºä¹ï¼Œä¹Ÿé˜»ç¢äº†ç²¾å‡†å¶ç‰‡è¿½è¸ªæ¨¡å‹çš„å¼€å‘è¿›å±•ã€‚æœ¬ç ”ç©¶æ¨å‡ºäº†Câ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13130v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13130.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ æƒé‡ç©ºé—´ç›¸å…³æ€§åˆ†æï¼šé‡åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„ç‰¹å¾åˆ©ç”¨</strong></p>
<p><em>Weight Space Correlation Analysis: Quantifying Feature Utilization in Deep Learning Models</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>MICCAI 2025 æˆ– Medical Image Analysis (æœŸåˆŠ)</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åä¸ºâ€œæƒé‡ç©ºé—´ç›¸å…³æ€§åˆ†æâ€çš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œç”¨äºé‡åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹ç‰¹å¾ï¼ˆç‰¹åˆ«æ˜¯åµŒå…¥ä¸­å¯èƒ½å­˜åœ¨çš„æ··æ‚å…ƒæ•°æ®ï¼‰çš„å®é™…åˆ©ç”¨ç¨‹åº¦ï¼Œä»è€Œæ£€æµ‹â€œæ·å¾„å­¦ä¹ â€ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•é€šè¿‡æµ‹é‡ä¸»ä¸´åºŠä»»åŠ¡åˆ†ç±»å¤´ä¸è¾…åŠ©å…ƒæ•°æ®ä»»åŠ¡åˆ†ç±»å¤´çš„æƒé‡å‘é‡ä¹‹é—´çš„å¯¹é½ç¨‹åº¦ï¼Œæ¥é‡åŒ–ç‰¹å¾åˆ©ç”¨æƒ…å†µï¼Œå¹¶éªŒè¯äº†å…¶åœ¨æ£€æµ‹äººä¸ºè¯±å¯¼å’ŒçœŸå®åœºæ™¯ï¼ˆå¦‚æ—©äº§é¢„æµ‹æ¨¡å‹ï¼‰ä¸­æ·å¾„å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åŒ»å­¦å½±åƒä¸­çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å®¹æ˜“é™·å…¥æ·å¾„å­¦ä¹ ï¼Œä¾èµ–æ··æ‚å…ƒæ•°æ®ï¼ˆå¦‚æ‰«æä»ªå‹å·ï¼‰ï¼Œè¿™äº›ä¿¡æ¯å¸¸è¢«ç¼–ç äºå›¾åƒåµŒå…¥ä¸­ã€‚å…³é”®é—®é¢˜åœ¨äºæ¨¡å‹æ˜¯å¦ä¸»åŠ¨åˆ©ç”¨è¿™äº›ç¼–ç ä¿¡æ¯è¿›è¡Œæœ€ç»ˆé¢„æµ‹ã€‚æˆ‘ä»¬æå‡ºæƒé‡ç©ºé—´ç›¸å…³æ€§åˆ†æâ€”â€”ä¸€ç§å¯è§£é‡Šçš„æ–¹æ³•è®ºï¼Œé€šè¿‡æµ‹é‡ä¸»è¦ä¸´åºŠä»»åŠ¡åˆ†ç±»å¤´ä¸è¾…åŠ©å…ƒæ•°æ®ä»»åŠ¡åˆ†ç±»å¤´ä¹‹é—´çš„å¯¹é½ç¨‹åº¦ï¼Œé‡åŒ–ç‰¹å¾åˆ©ç”¨æƒ…å†µã€‚é¦–å…ˆé€šè¿‡æˆåŠŸæ£€æµ‹äººå·¥è¯±å¯¼çš„æ·å¾„å­¦ä¹ éªŒè¯äº†è¯¥æ–¹æ³•ã€‚éšåå°†å…¶åº”ç”¨äºåˆ†æä¸ºé¢„æµ‹è‡ªå‘æ€§æ—©äº§è®­ç»ƒçš„SA-SonoNetæ¨¡â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13144v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13144.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ å…¨çƒèˆ¹èˆ¶è‡ªåŠ¨è¯†åˆ«ç³»ç»Ÿè½¨è¿¹ä¸­çš„ç›®çš„åœ°ä¼°è®¡</strong></p>
<p><em>WAY: Estimation of Vessel Destination in Worldwide AIS Trajectory</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE Transactions on Intelligent Transportation Systems æˆ– KDDã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§å°†é•¿è·ç¦»æ¸¯å£é—´è½¨è¿¹é‡æ„ä¸ºåµŒå¥—åºåˆ—ç»“æ„çš„æ–¹æ³•ï¼Œå¹¶è®¾è®¡äº†åä¸ºWAYçš„æ–°å‹æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œç”¨äºæå‰æ•°å¤©è‡³æ•°å‘¨é¢„æµ‹èˆ¹èˆ¶ç›®çš„åœ°ï¼Œä»¥è§£å†³å…¨çƒAISæ•°æ®å¯é æ€§å·®ã€é—´éš”ä¸è§„åˆ™çš„é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ–¹æ³•æ ¸å¿ƒåŒ…æ‹¬ï¼š1ï¼‰åˆ©ç”¨ç©ºé—´ç½‘æ ¼å¯¹è½¨è¿¹è¿›è¡Œé‡æ„ä»¥å‡è½»æ—¶ç©ºåå·®ï¼›2ï¼‰WAYæ¶æ„åŒ…å«è½¨è¿¹è¡¨ç¤ºå±‚ï¼ˆå°†è¿åŠ¨ä¸éè¿åŠ¨ç‰¹å¾è½¬ä¸ºå¤šé€šé“å‘é‡åºåˆ—ï¼‰å’Œé€šé“èšåˆåºåˆ—å¤„ç†æ¨¡å—ï¼ˆä½¿ç”¨å¤šå¤´é€šé“ä¸è‡ªæ³¨æ„åŠ›è¿›è¡Œä¿¡æ¯èšåˆä¸ä¼ é€’ï¼‰ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: èˆ¹èˆ¶è‡ªåŠ¨è¯†åˆ«ç³»ç»Ÿï¼ˆAISï¼‰ä¸ºæ•°æ®é©±åŠ¨çš„æµ·äº‹ç›‘æ§æä¾›äº†å¯èƒ½ï¼Œä½†å…¶å­˜åœ¨å¯é æ€§é—®é¢˜ä¸”æ•°æ®é—´éš”ä¸è§„åˆ™ã€‚é’ˆå¯¹å…¨çƒèŒƒå›´AISæ•°æ®çš„èˆ¹èˆ¶ç›®çš„åœ°é¢„æµ‹é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§å·®å¼‚åŒ–æ–¹æ³•ï¼Œå°†é•¿è·ç¦»æ¸¯åˆ°æ¸¯è½¨è¿¹é‡æ„ä¸ºåµŒå¥—åºåˆ—ç»“æ„ã€‚è¯¥æ–¹æ³•é€šè¿‡ç©ºé—´ç½‘æ ¼åŒ–å¤„ç†ï¼Œåœ¨ä¿æŒç²¾ç»†åˆ†è¾¨ç‡çš„åŒæ—¶ç¼“è§£æ—¶ç©ºåå·®ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°å‹æ·±åº¦å­¦ä¹ æ¶æ„WAYï¼Œä¸“é—¨å¤„ç†é‡æ„åçš„è½¨è¿¹ä»¥å®ç°æå‰æ•°å¤©è‡³æ•°å‘¨çš„é•¿æ—¶ç›®çš„åœ°é¢„æµ‹ã€‚WAYç”±è½¨è¿¹è¡¨å¾å±‚å’Œé€šé“èšåˆåºåˆ—å¤„ç†æ¨¡å—æ„â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13190v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13190.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ å¾®éœ‡ç›¸ä½ç¥ç»ç®—å­ï¼šå°†åœ°éœ‡è®­ç»ƒç›¸ä½ç¥ç»ç®—å­åº”ç”¨äºå¾®éœ‡ç›¸ä½æ‹¾å–</strong></p>
<p><em>MicroPhaseNO: Adapting an Earthquake-Trained Phase Neural Operator for Microseismic Phase Picking</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>Geophysical Research Letters æˆ– Journal of Geophysical Research: Solid Earth</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åŸºäºè¿ç§»å­¦ä¹ çš„å¾®åœ°éœ‡éœ‡ç›¸æ‹¾å–æ–¹æ³•ï¼Œé€šè¿‡å°†åœ¨å¤§è§„æ¨¡åœ°éœ‡æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„PhaseNOæ¨¡å‹ï¼Œä»…ç”¨å°‘é‡å¾®åœ°éœ‡æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ‹¾å–å™¨åœ¨å¾®åœ°éœ‡æ•°æ®ä¸Šæ€§èƒ½ä¸ä½³çš„é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é‡‡ç”¨é¢„è®­ç»ƒ-å¾®è°ƒæ¡†æ¶ï¼šé¦–å…ˆåœ¨å¤§è§„æ¨¡åœ°éœ‡å’Œå™ªå£°æ•°æ®é›†ä¸Šé¢„è®­ç»ƒPhaseNOæ¨¡å‹ï¼Œç„¶åä»…ä½¿ç”¨200æ¡æ°´åŠ›å‹è£‚è¯±å‘å¾®åœ°éœ‡çš„æ ‡è®°æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶é€‚åº”å¾®åœ°éœ‡æ•°æ®çš„ä½ä¿¡å™ªæ¯”å’ŒçŸ­æ—¶ç¨‹ç‰¹ç‚¹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åœ°éœ‡éœ‡ç›¸æ‹¾å–å¸¸ç”¨äºå¾®éœ‡ç›‘æµ‹å’Œåœ°ä¸‹æˆåƒã€‚ä¼ ç»Ÿäººå·¥å¤„ç†æ–¹æ³•æ—¢æ— æ³•æ»¡è¶³å®æ—¶åº”ç”¨éœ€æ±‚ï¼Œä¹Ÿéš¾ä»¥åº”å¯¹å¤§è§„æ¨¡å°é˜µæ•°æ®ã€‚åŸºäºæ·±åº¦å­¦ä¹ ã€é€šè¿‡å¤§é‡åœ°éœ‡ç›®å½•è®­ç»ƒçš„è‡ªåŠ¨æ‹¾å–å™¨ä¸ºæ­¤æä¾›äº†è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œè¿™ç±»æ–¹æ³•é€šå¸¸é’ˆå¯¹é«˜ä¿¡å™ªæ¯”ã€é•¿æ—¶ç¨‹å°ç½‘è¿›è¡Œä¼˜åŒ–ï¼Œéš¾ä»¥åº”å¯¹å¾®éœ‡æ•°æ®é›†çš„ç‰¹æœ‰æŒ‘æˆ˜â€”â€”è¿™ç±»æ•°æ®é›†ä¸“ä¸ºæœ‰é™æ—¶æ®µè®¾è®¡ï¼Œä¸”ç¼ºä¹é¢„å…ˆæ£€æµ‹åˆ°çš„åœ°éœ‡æ´»åŠ¨è®°å½•ã€‚æœ¬ç ”ç©¶é€šè¿‡è¿ç§»å­¦ä¹ ï¼Œå±•ç¤ºäº†å¦‚ä½•å°†é€‚ç”¨äºå°ç½‘å°ºåº¦çš„åœ°éœ‡éœ‡ç›¸æ‹¾å–å™¨â€”â€”ç›¸ä½ç¥ç»ç®—å­ï¼ˆPhaâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13197v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13197.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ å¯»æ±‚å¹³è¡¡ï¼šè·¨ä»£Ryzen AI NPUçš„GEMMæ€§èƒ½ä¼˜åŒ–</strong></p>
<p><em>Striking the Balance: GEMM Performance Optimization Across Generations of Ryzen AI NPUs</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– ç¡¬ä»¶/ä½“ç³»ç»“æ„é¡¶ä¼šï¼ˆå¦‚ MICRO, HPCA, ISCAï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§é€šç”¨çš„ç³»ç»ŸåŒ–æ–¹æ³•ï¼Œç”¨äºä¼˜åŒ–è·¨AMDä¸¤ä»£NPUï¼ˆXDNAå’ŒXDNA2ï¼‰çš„é€šç”¨çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰æ€§èƒ½ï¼Œå¹¶é’ˆå¯¹å…¶ç‹¬ç‰¹æ¶æ„ç‰¹å¾å’Œç³»ç»Ÿçº§ç“¶é¢ˆè¿›è¡Œäº†å®ç°ï¼Œåœ¨int8å’Œbf16ç²¾åº¦ä¸Šå‡å–å¾—äº†å½“å‰æœ€ä¼˜çš„ååé‡ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é€šè¿‡ä¸€ç§ç³»ç»Ÿçº§æ–¹æ³•è®ºï¼Œå……åˆ†åˆ©ç”¨AMD NPUçš„æ¶æ„ç‰¹æ€§ï¼Œå¹¶è§£å†³å…³é”®æ€§èƒ½ç“¶é¢ˆï¼Œä»è€Œå®ç°å¯¹ä¸åŒè§„æ¨¡GEMMè®¡ç®—çš„é«˜æ•ˆä¼˜åŒ–ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç°ä»£æ·±åº¦å­¦ä¹ å·¥ä½œè´Ÿè½½çš„é«˜è®¡ç®—ä¸å†…å­˜éœ€æ±‚ï¼Œæ¨åŠ¨äº†ä»äº‘ç«¯åˆ°è¾¹ç¼˜çš„ä¸“ç”¨ç¡¬ä»¶è®¾å¤‡å‘å±•ï¼Œä¾‹å¦‚AMDçš„Ryzen AI XDNA NPUã€‚é’ˆå¯¹è¿™äº›æ¶æ„ä¼˜åŒ–é€šç”¨çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰ç®—æ³•å¯¹äºæå‡æ·±åº¦å­¦ä¹ å·¥ä½œè´Ÿè½½æ€§èƒ½è‡³å…³é‡è¦ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºä¸€ç§é€šç”¨çš„ç³»ç»ŸåŒ–æ–¹æ³•ï¼Œç”¨äºä¼˜åŒ–å½“å‰ä¸¤ä»£NPUï¼ˆå³XDNAä¸XDNA2ï¼‰ä¸Šçš„GEMMå·¥ä½œè´Ÿè½½ã€‚æˆ‘ä»¬çš„å®ç°æ–¹æ¡ˆå……åˆ†åˆ©ç”¨äº†AMD NPUçš„ç‹¬ç‰¹æ¶æ„ç‰¹æ€§ï¼Œå¹¶åœ¨ç³»ç»Ÿå±‚é¢è§£å†³äº†å…³é”®æ€§èƒ½ç“¶é¢ˆã€‚â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13282v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13282.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ é‡åŒ–ç¨³å¥æ€§ï¼šç½‘ç»œç‰©ç†ç³»ç»Ÿä¸­æ·±åº¦å­¦ä¹ é¢„æµ‹çš„åŸºå‡†æµ‹è¯•æ¡†æ¶</strong></p>
<p><em>Quantifying Robustness: A Benchmarking Framework for Deep Learning Forecasting in Cyber-Physical Systems</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– ICLR 2025ï¼ˆé‰´äºå…¶èšç„¦äºæ·±åº¦å­¦ä¹ è¯„ä¼°åŸºå‡†ä¸é²æ£’æ€§ï¼Œå±äºæœºå™¨å­¦ä¹ é¢†åŸŸçš„é‡è¦è®®é¢˜ï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§é’ˆå¯¹å·¥ä¸šä¿¡æ¯ç‰©ç†ç³»ç»Ÿï¼ˆCPSï¼‰çš„ã€åŸºäºåˆ†å¸ƒé²æ£’æ€§çš„å®ç”¨æ€§é²æ£’æ€§å®šä¹‰ï¼Œå¹¶å»ºç«‹äº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„åŸºå‡†æµ‹è¯•æ¡†æ¶ï¼Œä»¥é‡åŒ–è¯„ä¼°æ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹åœ¨çœŸå®æ‰°åŠ¨ä¸‹çš„é²æ£’æ€§ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ¼‚ç§»ã€å™ªå£°å’Œä¸è§„åˆ™é‡‡æ ·ç­‰çœŸå®ä¸–ç•Œæ‰°åŠ¨ï¼Œåœ¨çœŸå®CPSæ•°æ®é›†ä¸Šå¯¹é¢„æµ‹æ¨¡å‹è¿›è¡Œå…¨é¢çš„é²æ£’æ€§åˆ†æï¼Œå¹¶æä¾›ä¸€ä¸ªæ ‡å‡†åŒ–çš„é²æ£’æ€§è¯„åˆ†ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åœ¨åˆ¶é€ ã€èƒ½æºåˆ†é…ç­‰é¢†åŸŸï¼Œç½‘ç»œç‰©ç†ç³»ç»Ÿä¼šäº§ç”Ÿå¯¹é¢„æµ‹ä¸å¥åº·ç®¡ç†è‡³å…³é‡è¦çš„å¤æ‚æ—¶é—´åºåˆ—æ•°æ®ã€‚å°½ç®¡æ·±åº¦å­¦ä¹ æ–¹æ³•å·²å±•ç°å‡ºå¼ºå¤§çš„é¢„æµ‹èƒ½åŠ›ï¼Œä½†ç”±äºé²æ£’æ€§ä¸è¶³ï¼Œå…¶åœ¨å·¥ä¸šç½‘ç»œç‰©ç†ç³»ç»Ÿä¸­çš„å®é™…åº”ç”¨ä»å—é™ã€‚ç°æœ‰é²æ£’æ€§è¯„ä¼°ä¸»è¦é›†ä¸­äºå½¢å¼åŒ–éªŒè¯æˆ–å¯¹æŠ—æ‰°åŠ¨ï¼Œæœªèƒ½å……åˆ†åæ˜ çœŸå®ç½‘ç»œç‰©ç†ç³»ç»Ÿåœºæ™¯ä¸­çš„å¤æ‚æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§åŸºäºåˆ†å¸ƒé²æ£’æ€§çš„å®ç”¨æ€§å®šä¹‰ï¼Œä¸“é—¨é’ˆå¯¹å·¥ä¸šç½‘ç»œç‰©ç†ç³»ç»Ÿå®šåˆ¶ï¼Œå¹¶æ„å»ºäº†ç³»ç»ŸåŒ–çš„é²æ£’æ€§è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿä¼ æ„Ÿâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.03494v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.03494.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åˆ©ç”¨DINOè‡ªæ³¨æ„åŠ›â€œé”®â€è§£é”æ¯è‚‰åˆ†å‰²çš„æ³›åŒ–èƒ½åŠ›</strong></p>
<p><em>Unlocking Generalization in Polyp Segmentation with DINO Self-Attention â€œkeysâ€</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>MICCAI 2025 æˆ– Medical Image Analysisã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§åˆ©ç”¨DINOè‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„â€œé”®â€ï¼ˆkeyï¼‰ç‰¹å¾è¿›è¡Œæ¯è‚‰åˆ†å‰²çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡ä½¿ç”¨æµ…å±‚ã€æ›´å…·æ³›åŒ–æ€§çš„ç‰¹å¾ï¼Œæ›¿ä»£ä¼ ç»Ÿæ–¹æ³•ä¸­ä¾èµ–æ·±å±‚ç‰¹å¾çš„åšæ³•ï¼Œä»è€Œæå‡æ¨¡å‹åœ¨æ•°æ®å—é™æˆ–å¤æ‚åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯æå–DINO Vision Transformerè‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­çš„â€œé”®â€ç‰¹å¾ï¼Œå¹¶ç»“åˆä¸€ä¸ªç®€å•çš„å·ç§¯è§£ç å™¨æ¥é¢„æµ‹æ¯è‚‰åˆ†å‰²æ©ç ï¼Œæ„å»ºäº†ä¸€ä¸ªè½»é‡ä¸”æ³›åŒ–æ€§å¼ºçš„åˆ†å‰²æ¡†æ¶ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: è‡ªåŠ¨æ¯è‚‰åˆ†å‰²å¯¹äºæå‡ç»“ç›´è‚ ç™Œï¼ˆCRCï¼‰çš„ä¸´åºŠè¯†åˆ«è‡³å…³é‡è¦ã€‚å°½ç®¡æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨æ­¤é¢†åŸŸå·²å¾—åˆ°å¹¿æ³›ç ”ç©¶ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨æ³›åŒ–èƒ½åŠ›æ–¹é¢ä»å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶åœ¨æ•°æ®å—é™æˆ–å¤æ‚åœºæ™¯ä¸‹è¡¨ç°å°¤ä¸ºæ˜æ˜¾ã€‚æ­¤å¤–ï¼Œè®¸å¤šç°æœ‰æ¯è‚‰åˆ†å‰²æ–¹æ³•ä¾èµ–äºå¤æ‚ä¸”ä»»åŠ¡ç‰¹å®šçš„æ¶æ„ã€‚ä¸ºåº”å¯¹è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨DINOè‡ªæ³¨æ„åŠ›â€å…³é”®â€ç‰¹å¾å†…åœ¨é²æ£’æ€§çš„åˆ†å‰²æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä»è§†è§‰Transformeræœ€æ·±å±‚æ¬¡æå–ç‰¹å¾ä¸åŒï¼Œæœ¬æ–¹æ³•é€šè¿‡è‡ªæ³¨æ„åŠ›æ¨¡å—çš„å…³â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13376v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13376.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºTransformerä¸å›¾ç¥ç»ç½‘ç»œçš„é€»è¾‘ç»¼åˆç»“æœè´¨é‡é¢„æµ‹</strong></p>
<p><em>The prediction of the quality of results in Logic Synthesis using Transformer and Graph Neural Networks</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>DACï¼ˆDesign Automation Conferenceï¼‰æˆ– ICCADï¼ˆInternational Conference on Computer-Aided Designï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§ç»“åˆTransformerä¸å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹é€»è¾‘ç»¼åˆä¸­æœªè§è¿‡çš„ç”µè·¯-ä¼˜åŒ–åºåˆ—å¯¹çš„ç»“æœè´¨é‡ï¼ˆQoRï¼‰ï¼Œä»¥åŠ é€Ÿä¼˜åŒ–åºåˆ—çš„æœç´¢ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: ä½¿ç”¨åµŒå…¥æ–¹æ³•å’ŒTransformeræå–ä¼˜åŒ–åºåˆ—çš„å‘é‡ç‰¹å¾ï¼ŒåŒæ—¶å°†ç”µè·¯è¡¨ç¤ºä¸ºé‚»æ¥çŸ©é˜µå’Œç‰¹å¾çŸ©é˜µè¾“å…¥å›¾ç¥ç»ç½‘ç»œï¼Œå®ç°è·¨ç”µè·¯çš„æ³›åŒ–é¢„æµ‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åœ¨é€»è¾‘ç»¼åˆé˜¶æ®µï¼Œç»¼åˆå·¥å…·ä¸­çš„ç»“æ„å˜æ¢éœ€è¦ç»„åˆæˆä¼˜åŒ–åºåˆ—å¹¶ä½œç”¨äºç”µè·¯ï¼Œä»¥æ»¡è¶³æŒ‡å®šçš„ç”µè·¯é¢ç§¯å’Œå»¶è¿Ÿè¦æ±‚ã€‚ç„¶è€Œï¼Œé€»è¾‘ç»¼åˆä¼˜åŒ–åºåˆ—çš„è¿è¡Œè€—æ—¶è¾ƒé•¿ï¼Œé¢„æµ‹ç”µè·¯åœ¨ç»¼åˆä¼˜åŒ–åºåˆ—ä¸‹çš„ç»“æœè´¨é‡ï¼ˆQoRï¼‰æœ‰åŠ©äºå·¥ç¨‹å¸ˆæ›´å¿«åœ°æ‰¾åˆ°æ›´ä¼˜çš„ä¼˜åŒ–åºåˆ—ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºé¢„æµ‹æœªè§è¿‡çš„ç”µè·¯-ä¼˜åŒ–åºåˆ—å¯¹çš„QoRã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡åµŒå…¥æ–¹æ³•å°†ç»“æ„å˜æ¢è½¬åŒ–ä¸ºå‘é‡ï¼Œå¹¶åˆ©ç”¨å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æŠ€æœ¯ï¼ˆTransformerï¼‰æå–â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2207.11437v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2207.11437.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ End2Regï¼šè„ŠæŸ±æ‰‹æœ¯ä¸­æ— æ ‡è®°é…å‡†çš„ä»»åŠ¡ç‰¹å®šåˆ†å‰²å­¦ä¹ </strong></p>
<p><em>End2Reg: Learning Task-Specific Segmentation for Markerless Registration in Spine Surgery</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>MICCAI (åŒ»å­¦å›¾åƒè®¡ç®—ä¸è®¡ç®—æœºè¾…åŠ©å¹²é¢„ä¼šè®®) æˆ– IEEE Transactions on Medical Imaging (TMI)ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆEnd2Regï¼‰ï¼Œå°†åˆ†å‰²ä¸é…å‡†ä»»åŠ¡è”åˆä¼˜åŒ–ï¼Œæ— éœ€ä¾èµ–å¼±åˆ†å‰²æ ‡ç­¾æˆ–æ‰‹åŠ¨æ­¥éª¤ï¼Œé€šè¿‡é…å‡†ç›®æ ‡ç›´æ¥é©±åŠ¨å­¦ä¹ å¯¹é…å‡†ä»»åŠ¡æœ€ä¼˜çš„åˆ†å‰²æ©ç ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ¡†æ¶æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯ç½‘ç»œï¼Œå…¶æ ¸å¿ƒæ˜¯ä»…ä»¥é…å‡†ç›®æ ‡ä¸ºç›‘ç£ä¿¡å·ï¼Œè”åˆå­¦ä¹ åˆ†å‰²å’Œé…å‡†ï¼Œä½¿ç½‘ç»œè‡ªåŠ¨å­¦ä¹ å‡ºä¸“ä¸ºé…å‡†ä¼˜åŒ–çš„è§£å‰–ç»“æ„åˆ†å‰²ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç›®çš„ï¼šè„ŠæŸ±æ‰‹æœ¯ä¸­çš„æœ¯ä¸­å¯¼èˆªéœ€è¦æ¯«ç±³çº§ç²¾åº¦ã€‚å½“å‰åŸºäºæœ¯ä¸­æ”¾å°„æˆåƒå’Œéª¨é”šå®šæ ‡è®°çš„ç³»ç»Ÿå…·æœ‰ä¾µå…¥æ€§ã€è¾å°„å¼ºåº¦é«˜ä¸”ä¼šå¹²æ‰°å·¥ä½œæµç¨‹ã€‚æœ€è¿‘çš„æ— æ ‡è®°RGB-Dé…å‡†æ–¹æ³•æä¾›äº†æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ç°æœ‰æ–¹æ³•ä¾èµ–å¼±åˆ†å‰²æ ‡ç­¾æ¥åˆ†ç¦»ç›¸å…³è§£å‰–ç»“æ„ï¼Œè¿™å¯èƒ½å¯¼è‡´è¯¯å·®åœ¨é…å‡†è¿‡ç¨‹ä¸­ä¼ æ’­ã€‚æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºEnd2Regâ€”â€”ä¸€ç§ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡è”åˆä¼˜åŒ–åˆ†å‰²ä¸é…å‡†ï¼Œæ¶ˆé™¤äº†å¯¹å¼±åˆ†å‰²æ ‡ç­¾å’Œæ‰‹åŠ¨æ­¥éª¤çš„ä¾èµ–ã€‚è¯¥ç½‘ç»œåœ¨ä»…ç”±é…å‡†ç›®æ ‡å¼•å¯¼ã€æ— ç›´æ¥â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13402v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13402.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ æ·±åº¦å­¦ä¹ è¿­ä»£å †å æ–¹æ³•é¢„æµ‹å¤šå­”ä»‹è´¨ä¸­çš„ååº”æ€§æº¶è§£</strong></p>
<p><em>A Deep-Learning Iterative Stacked Approach for Prediction of Reactive Dissolution in Porous Media</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>é‰´äºå…¶åº”ç”¨é¢†åŸŸï¼ˆè®¡ç®—ç‰©ç†ã€åœ°ä¸‹å·¥ç¨‹ï¼‰å’Œæ–¹æ³•è®ºï¼ˆæ·±åº¦å­¦ä¹ åœ¨ç§‘å­¦è®¡ç®—ä¸­çš„åº”ç”¨ï¼‰ï¼Œè¯¥è®ºæ–‡å¯èƒ½å‘è¡¨äº **Journal of Computational Physics**ã€**Water Resources Research** æˆ– **Advances in Water Resources** ç­‰æœŸåˆŠï¼Œæˆ– **NeurIPS**ã€**ICLR** çš„æœºå™¨å­¦ä¹ ä¸ç‰©ç†äº¤å‰æ–¹å‘ç ”è®¨ä¼šã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ·±åº¦å­¦ä¹ è¿­ä»£å †å æ–¹æ³•ï¼Œèƒ½å¤ŸåŒæ—¶åˆ©ç”¨æ—¶ç©ºä¿¡æ¯ï¼Œé¢„æµ‹å¤šå­”ä»‹è´¨ä¸­ååº”æ€§æº¶è§£è¿‡ç¨‹çš„å¤šä¸ªæœªæ¥çŠ¶æ€ï¼Œçªç ´äº†ä»¥å¾€æ–¹æ³•é€šå¸¸åªèƒ½é¢„æµ‹å•ä¸€ç‰©ç†åœºï¼ˆå¦‚é€Ÿåº¦åœºï¼‰çš„é™åˆ¶ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•ä»¥ä¸€ç³»åˆ—è¾“å…¥çŠ¶æ€åºåˆ—ä¸ºåŸºç¡€ï¼Œé€šè¿‡ä¸€ä¸ªç»“åˆäº†æ—¶ç©ºä¿¡æ¯çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä»¥å›ºå®šçš„æ—¶é—´æ­¥é•¿é¢„æµ‹æº¶è§£è¿‡ç¨‹çš„æœªæ¥çŠ¶æ€ï¼Œå…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªè¿­ä»£å¼çš„é¢„æµ‹æ¡†æ¶ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ¨¡æ‹Ÿå¤šå­”ä»‹è´¨ä¸­å›ºä½“çŸ¿ç‰©çš„ååº”æ€§æº¶è§£å…·æœ‰å¹¿æ³›çš„åœ°ä¸‹åº”ç”¨ï¼ŒåŒ…æ‹¬ç¢³æ•é›†ä¸å°å­˜ã€åœ°çƒ­ç³»ç»Ÿä»¥åŠæ²¹æ°”å¼€é‡‡ã€‚ç”±äºä¼ ç»Ÿçš„ç›´æ¥æ•°å€¼æ¨¡æ‹Ÿå™¨è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œå¼€å‘æ›´å¿«é€Ÿé«˜æ•ˆçš„æ›¿ä»£æ–¹æ³•è‡³å…³é‡è¦ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„è§£å†³æ–¹æ¡ˆï¼ˆå¤§å¤šå»ºç«‹åœ¨å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€ä¸Šï¼‰è¢«è®¾è®¡ç”¨äºè§£å†³è¿™ä¸€é—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ¡ˆé€šå¸¸å±€é™äºè¿‘ä¼¼åŸŸå†…çš„å•ä¸€ç‰©ç†åœºï¼ˆå¦‚é€Ÿåº¦åœºï¼‰ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°é¢–çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èåˆæ—¶ç©ºä¿¡æ¯ï¼Œåœ¨ç»™å®šè¾“å…¥çŠ¶æ€åºåˆ—çš„æ¡ä»¶ä¸‹ï¼Œèƒ½å¤Ÿä»¥å›ºå®šâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.08410v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.08410.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ é¢å‘èµ„æºé«˜æ•ˆå°‘æ ·æœ¬æ¤ç‰©ç—…å®³åˆ†ç±»çš„é¢†åŸŸè‡ªé€‚åº”è½»é‡é›†æˆæ–¹æ³•</strong></p>
<p><em>A Domain-Adapted Lightweight Ensemble for Resource-Efficient Few-Shot Plant Disease Classification</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) æˆ– International Conference on Computer Vision (ICCV) çš„Workshopï¼Œæˆ–ç›´æ¥å‘è¡¨äºarXivé¢„å°æœ¬ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§é¢å‘èµ„æºå—é™ç¯å¢ƒçš„è½»é‡çº§å°‘æ ·æœ¬æ¤ç‰©ç—…å®³åˆ†ç±»æ–¹æ³•ï¼Œæ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆäº†é¢†åŸŸè‡ªé€‚åº”çš„è½»é‡çº§ç‰¹å¾æå–å™¨ä¸æ³¨æ„åŠ›å¢å¼ºçš„Bi-LSTMåˆ†ç±»å™¨ï¼Œä»¥åœ¨æ•°æ®ç¨€ç¼ºå’Œè®¡ç®—èµ„æºæœ‰é™æ¡ä»¶ä¸‹å®ç°é²æ£’åˆ†ç±»ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ–¹æ³•æ¡†æ¶é‡‡ç”¨é¢†åŸŸè‡ªé€‚åº”åçš„MobileNetV2å’ŒMobileNetV3ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œé€šè¿‡ç‰¹å¾èåˆæŠ€æœ¯ç”Ÿæˆé²æ£’ç‰¹å¾è¡¨ç¤ºï¼Œå†è¾“å…¥åˆ°ç»“åˆæ³¨æ„åŠ›æœºåˆ¶çš„Bi-LSTMåˆ†ç±»å™¨ä¸­è¿›è¡Œæœ€ç»ˆåˆ†ç±»ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å‡†ç¡®åŠæ—¶åœ°è¯†åˆ«æ¤ç‰©å¶ç‰‡ç—…å®³å¯¹äºæ„å»ºéŸ§æ€§ä¸å¯æŒç»­çš„å†œä¸šä½“ç³»è‡³å…³é‡è¦ï¼Œç„¶è€Œç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•å¤§å¤šä¾èµ–å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†å’Œè®¡ç®—å¯†é›†å‹æ¨¡å‹ï¼Œéš¾ä»¥é€‚ç”¨äºæ•°æ®ç¨€ç¼ºä¸èµ„æºå—é™çš„ç¯å¢ƒã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬ç ”ç©¶æå‡ºä¸€ç§è½»é‡é«˜æ•ˆçš„å°‘æ ·æœ¬å­¦ä¹ æ¡†æ¶ï¼šé€šè¿‡é¢†åŸŸè‡ªé€‚åº”æ”¹è¿›çš„MobileNetV2ä¸MobileNetV3æ¨¡å‹ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œç»“åˆç‰¹å¾èåˆæŠ€æœ¯ç”Ÿæˆé²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚åœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œèåˆç‰¹å¾ç»ç”±åŒå‘é•¿çŸ­æœŸè®°å¿†ç½‘ç»œåˆ†ç±»å™¨å¤„ç†ï¼Œè¯¥â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13428v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13428.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Deep-ERï¼šæ·±åº¦å­¦ä¹ åå¿ƒé‡å»ºæŠ€æœ¯å®ç°å¿«é€Ÿé«˜åˆ†è¾¨ç‡ç¥ç»ä»£è°¢æˆåƒ</strong></p>
<p><em>Deep-ER: Deep Learning ECCENTRIC Reconstruction for fast high-resolution neurometabolic imaging</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>*Magnetic Resonance in Medicine* æˆ– *NeuroImage*ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åä¸ºDeep-ERçš„æ·±åº¦å­¦ä¹ é‡å»ºæ–¹æ³•ï¼Œç”¨äºå¿«é€Ÿã€é«˜è´¨é‡åœ°é‡å»ºé«˜åˆ†è¾¨ç‡ç¥ç»ä»£è°¢æˆåƒæ•°æ®ï¼Œè§£å†³äº†ä¼ ç»Ÿéç¬›å¡å°”å‹ç¼©æ„ŸçŸ¥MRSIé‡å»ºè€—æ—¶é•¿ã€éœ€è¦ä¸“å®¶å¹²é¢„çš„ç“¶é¢ˆé—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•åŸºäºä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œé‡‡ç”¨å¾ªç¯äº¤é”™å·ç§¯å±‚ï¼Œå¹¶ç»“åˆäº†è”åˆåŒç©ºé—´ç‰¹å¾è¡¨ç¤ºï¼Œä»¥ç›´æ¥ä»åŸå§‹é‡‡é›†æ•°æ®ä¸­é«˜æ•ˆé‡å»ºå‡ºé«˜è´¨é‡çš„ä»£è°¢å›¾è°±ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å¼•è¨€ï¼šç¥ç»ä»£è°¢æ”¹å˜æ˜¯è®¸å¤šç¥ç»ç³»ç»Ÿç–¾ç—…å’Œè„‘è‚¿ç˜¤çš„é‡è¦ç—…ç†æœºåˆ¶ï¼Œå¯é€šè¿‡ç£å…±æŒ¯æ³¢è°±æˆåƒï¼ˆMRSIï¼‰è¿›è¡Œæ— åˆ›æ£€æµ‹ã€‚åŸºäºéç¬›å¡å°”å‹ç¼©æ„ŸçŸ¥é‡‡é›†çš„å…ˆè¿›MRSIæŠ€æœ¯èƒ½å¤Ÿå®ç°å¿«é€Ÿé«˜åˆ†è¾¨ç‡ä»£è°¢æˆåƒï¼Œä½†å…¶é‡å»ºæ—¶é—´è¿‡é•¿é™åˆ¶äº†é€šé‡ä¸”éœ€ä¸“å®¶äººå·¥å¹²é¢„ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§ç¨³å¥é«˜æ•ˆçš„æ·±åº¦å­¦ä¹ é‡å»ºæ–¹æ³•ï¼Œä»¥è·å–é«˜è´¨é‡ä»£è°¢å›¾è°±ã€‚æ–¹æ³•ï¼šåœ¨7Tç£å…±æŒ¯æ‰«æä»ªä¸Šé‡‡ç”¨ECCENTRICè„‰å†²åºåˆ—ï¼Œä»¥3.4 mm$^3$å„å‘åŒæ€§åˆ†è¾¨ç‡è¿›è¡Œå¿«é€Ÿé«˜åˆ†è¾¨ç‡å…¨è„‘â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.18303v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.18303.pdf">PDF</a></p>
</div>

<hr>
<h3 id="ğŸ“…-2025-12-14"><a href="#ğŸ“…-2025-12-14" class="headerlink" title="ğŸ“… 2025-12-14"></a>ğŸ“… 2025-12-14</h3><div class="paper-card">

<p><strong>ğŸ“„ PoreTrack3D: A Benchmark for Dynamic 3D Gaussian Splatting in Pore-Scale Facial Trajectory Tracking</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.02648v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.02648.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ High Order Control Lyapunov Function - Control Barrier Function - Quadratic Programming Based Autonomous Driving Controller for Bicyclist Safety</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12776v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12776.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12799v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12799.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GradID: Adversarial Detection via Intrinsic Dimensionality of Gradients</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12827v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12827.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12548v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12548.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.10100v5">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.10100.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12751v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12751.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The Geometry of Intelligence: Deterministic Functional Topology as a Foundation for Real-World Perception</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.05089v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.05089.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ D3D-VLP: Dynamic 3D Vision-Language-Planning Model for Embodied Grounding and Navigation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision and Language Navigation</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12622v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12622.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Diverse LLMs vs. Vulnerabilities: Who Detects and Fixes Them Better?</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12536v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12536.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HyperEdit: Unlocking Instruction-based Text Editing in LLMs via Hypernetworks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12544v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12544.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12597v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12597.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Understanding Syllogistic Reasoning in LLMs from Formal and Natural Language Perspectives</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12620v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12620.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ORIBA: Exploring LLM-Driven Role-Play Chatbot as a Creativity Support Tool for Original Character Artists</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12630v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12630.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark for Evaluating LLM-Based Table Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.13405v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.13405.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLMs Encode Harmfulness and Refusal Separately</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.11878v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.11878.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Fine-Tuning Causal LLMs for Text Classification: Embedding-Based vs. Instruction-Based Approaches</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12677v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12677.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12706v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12706.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Lethe: Layer- and Time-Adaptive KV Cache Pruning for Reasoning-Intensive LLM Serving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.06029v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.06029.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Harnessing Negative Signals: Reinforcement Distillation from Teacher Data for LLM Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.24850v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.24850.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Fine-Grained Energy Prediction For Parallellized LLM Inference With PIE-P</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12801v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12801.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Does Tone Change the Answer? Evaluating Prompt Politeness Effects on Modern LLMs: GPT, Gemini, LLaMA</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12812v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12812.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.23260v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.23260.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Counting Clues: A Lightweight Probabilistic Baseline Can Match an LLM</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12868v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12868.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DATABench: Evaluating Dataset Auditing in Deep Learning from an Adversarial Perspective</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.05622v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.05622.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ StegaVAR: Privacy-Preserving Video Action Recognition via Steganographic Domain Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12586v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12586.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ An Improved Pure Fully Connected Neural Network for Rice Grain Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.03111v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.03111.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SHERLOCK: A Deep Learning Approach To Detect Software Vulnerabilities</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12593v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12593.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Burst-Sampled Spatiotemporal Dynamics</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.10253v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.10253.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Shoot from the HIP: Hessian Interatomic Potentials without derivatives</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.21624v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.21624.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Process mining-driven modeling and simulation to enhance fault diagnosis in cyber-physical systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.21502v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.21502.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Anatomy-Guided Representation Learning Using a Transformer-Based Network for Thyroid Nodule Segmentation in Ultrasound Images</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12662v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12662.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Personalized QoE Prediction: A Demographic-Augmented Machine Learning Framework for 5G Video Streaming Networks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12736v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12736.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Code Smell Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.13801v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.13801.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Network Level Evaluation of Hangup Susceptibility of HRGCs using Deep Learning and Sensing Techniques: A Goal Towards Safer Future</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12832v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12832.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HTMA-Net: Towards Multiplication-Avoiding Neural Networks via Hadamard Transform and In-Memory Computing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.23103v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.23103.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SignRAG: A Retrieval-Augmented System for Scalable Zero-Shot Road Sign Recognition</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12885v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12885.pdf">PDF</a></p>
</div>

<hr>
<h3 id="ğŸ“…-2025-12-13"><a href="#ğŸ“…-2025-12-13" class="headerlink" title="ğŸ“… 2025-12-13"></a>ğŸ“… 2025-12-13</h3><div class="paper-card">

<p><strong>ğŸ“„ GeoTexDensifier: Geometry-Texture-Aware Densification for High-Quality Photorealistic 3D Gaussian Splatting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.16809v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.16809.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Balancing Accuracy and Speed: A Multi-Fidelity Ensemble Kalman Filter with a Machine Learning Surrogate Model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12276v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12276.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Measuring What Matters: Scenario-Driven Evaluation for Trajectory Predictors in Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12211v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12211.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Human Intention to Action Prediction: A Comprehensive Benchmark for Intention-driven End-to-End Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12302v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12302.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Survey on Uncertainty Quantification Methods for Deep Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2302.13425v7">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2302.13425.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.00139v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.00139.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Revolutionizing Finance with LLMs: An Overview of Applications and Insights</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.11641v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.11641.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Learning to Debug: LLM-Organized Knowledge Trees for Solving RTL Assertion Failures</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.17833v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.17833.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Citation-Grounded Code Comprehension: Preventing LLM Hallucination Through Hybrid Retrieval and Graph-Augmented Context</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12117v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12117.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Keep the Lights On, Keep the Lengths in Check: Plug-In Adversarial Detection for Time-Series LLMs in Energy Forecasting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12154v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12154.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12177v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12177.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Cluster-guided LLM-Based Anonymization of Software Analytics Data: Studying Privacy-Utility Trade-offs in JIT Defect Prediction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12224v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12224.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.14479v5">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.14479.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Cognitive-YOLO: LLM-Driven Architecture Synthesis from First Principles of Data for Object Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12281v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12281.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLMs as Span Annotators: A Comparative Study of LLMs and Humans</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.08697v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.08697.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Taint-Based Code Slicing for LLMs-based Malicious NPM Package Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12313v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12313.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Protecting Bystander Privacy via Selective Hearing in Audio LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.06380v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.06380.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ BreakFun: Jailbreaking LLMs via Schema Exploitation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.17904v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.17904.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Incoherence as Oracle-less Measure of Error in LLM-Based Code Generation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.00057v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.00057.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12476v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12476.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Accurate de novo sequencing of the modified proteome with OmniNovo</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12272v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12272.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Fractional Differential Equation Physics-Informed Neural Network and Its Application in Battery State Estimation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12285v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12285.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CSAW-M: An Ordinal Classification Dataset for Benchmarking Mammographic Masking of Cancer</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.01330v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.01330.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MRD: Using Physically Based Differentiable Rendering to Probe Vision Models for 3D Scene Understanding</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12307v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12307.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Dy-mer: An Explainable DNA Sequence Representation Scheme using Dictionary Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.12051v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.12051.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards a pretrained deep learning estimator of the Linfoot informational correlation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12358v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12358.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Synthetic Swarm Mosquito Dataset for Acoustic Classification: A Proof of Concept</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12365v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12365.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ JPEG-Inspired Cloud-Edge Holography</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12367v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12367.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DeepVekua: Geometric-Spectral Representation Learning for Physics-Informed Fields</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12402v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12402.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Translation in the Wild</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.23548v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.23548.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Knowledge-Guided Masked Autoencoder with Linear Spectral Mixing and Spectral-Angle-Aware Reconstruction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12445v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12445.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ U-NetMN and SegNetMN: Modified U-Net and SegNet models for bimodal SAR image segmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.05444v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.05444.pdf">PDF</a></p>
</div>

<hr>
<h3 id="ğŸ“…-2025-12-12"><a href="#ğŸ“…-2025-12-12" class="headerlink" title="ğŸ“… 2025-12-12"></a>ğŸ“… 2025-12-12</h3><div class="paper-card">

<p><strong>ğŸ“„ Lightweight 3D Gaussian Splatting Compression via Video Codec</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11186v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11186.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.08710v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.08710.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Moment-Based 3D Gaussian Splatting: Resolving Volumetric Occlusion with Order-Independent Transmittance</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11800v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11800.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Multi-Mode Structured Light 3D Imaging System with Multi-Source Information Fusion for Underwater Pipeline Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11354v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11354.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ iPINNER: An Iterative Physics-Informed Neural Network with Ensemble Kalman Filter</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.00731v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.00731.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ TransBridge: Boost 3D Object Detection by Scene-Level Completion with Transformer Decoder</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11926v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11926.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11226v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11226.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Elevation Aware 2D&#x2F;3D Co-simulation Framework for Large-scale Traffic Flow and High-fidelity Vehicle Dynamics</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11249v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11249.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SATMapTR: Satellite Image Enhanced Online HD Map Construction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11319v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11319.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Driving Through Uncertainty: Risk-Averse Control with LLM Commonsense for Autonomous Driving under Perception Deficits</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.07020v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.07020.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CarlaNCAP: A Framework for Quantifying the Safety of Vulnerable Road Users in Infrastructure-Assisted Collective Perception Using EuroNCAP Scenarios</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11551v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11551.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11944v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11944.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Evaluating Foundation Modelsâ€™ 3D Understanding Through Multi-View Correspondence Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11574v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11574.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LUCID: Learning-Enabled Uncertainty-Aware Certification of Stochastic Dynamical Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11750v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11750.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10947v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10947.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ VFMF: World Modeling by Forecasting Vision Foundation Model Features</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11225v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11225.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WARPD: World model Assisted Reactive Policy Diffusion</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.14040v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.14040.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11797v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11797.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12080v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12080.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GraphPerf-RT: A Graph-Driven Performance Model for Hardware-Aware Scheduling of OpenMP Codes</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12091v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12091.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11218v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11218.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Benchmarking the Generality of Vision-Language-Action Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11315v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11315.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14396v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.14396.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11584v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11584.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Embodied Image Compression</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11612v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11612.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11769v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11769.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ REMODEL-LLM: Transforming C code to Java using LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11402v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11402.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.06393v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.06393.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11421v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11421.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Decoding Human-LLM Collaboration in Coding: An Empirical Study of Multi-Turn Conversations in the Wild</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10493v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10493.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Does Less Hallucination Mean Less Creativity? An Empirical Investigation in LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11509v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11509.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PD-Swap: Prefill-Decode Logic Swapping for End-to-End LLM Inference on Edge FPGAs via Dynamic Partial Reconfiguration</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11550v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11550.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Verification Burden to Trusted Collaboration: Design Goals for LLM-Assisted Literature Reviews</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11661v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11661.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Evaluating Cooperative Resilience in Multiagent Systems: A Comparison Between Humans and LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11689v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11689.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Text2Graph: Combining Lightweight LLMs and GNNs for Efficient Text Classification in Label-Scarce Scenarios</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10061v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10061.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ REASONING COMPILER: LLM-Guided Optimizations for Efficient Model Serving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.01374v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.01374.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11755v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11755.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Learning to Extract Context for Context-Aware LLM Inference</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11986v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11986.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Efficient Training-Free Online Routing for High-Volume Multi-LLM Serving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.02718v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.02718.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CoopQ: Cooperative Game Inspired Layerwise Mixed Precision Quantization for LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.15455v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.15455.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ RadOnc-GPT: An Autonomous LLM Agent for Real-Time Patient Outcomes Labeling at Scale</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.25540v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.25540.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ VOYAGER: A Training Free Approach for Generating Diverse Datasets using LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12072v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12072.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Do LLM Evaluators Prefer Themselves for a Reason?</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.03846v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.03846.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.23453v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.23453.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ æ‹’ç»ä¸å¦ï¼Ÿï¼šæ™ºèƒ½å®¶å±…åœºæ™¯ä¸‹è¯­éŸ³åŠ©æ‰‹æŸ¥è¯¢æ‹’ç»çš„åŸºå‡†æµ‹è¯•ä¸åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ”¹è¿›æ–¹æ³•</strong></p>
<p><em>Reject or Not?: A Benchmark for Voice Assistant Query Rejection in Smart Home Scenario and an Improved Method Based on LLMs</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>ACL 2025 / EMNLP 2025 / arXiv preprint</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†é¦–ä¸ªé¢å‘ä¸­æ–‡æ™ºèƒ½å®¶å±…åœºæ™¯çš„è¯­éŸ³åŠ©æ‰‹æŸ¥è¯¢æ‹’è¯†å¼€æºåŸºå‡†ä¸è¯„ä¼°å¥—ä»¶ï¼Œå¹¶æ„å»ºäº†é¦–ä¸ªé’ˆå¯¹è¯¥åœºæ™¯çš„å¤šæ¨¡æ€æŸ¥è¯¢æ‹’è¯†æ•°æ®é›†ï¼ˆåŒ…å«11,913ä¸ªæ–‡æœ¬-è¯­éŸ³å¯¹ï¼‰ï¼ŒåŒæ—¶æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä¸ªæ€§åŒ–æŸ¥è¯¢æ‹’è¯†æ–¹æ³•ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æå‡ºäº†ä¸€ç§ä¸‰å±‚åä½œæ¶æ„ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡ŒæŸ¥è¯¢æ‹’è¯†å†³ç­–ï¼Œå…·ä½“æ–¹æ³•ç»†èŠ‚éœ€å‚è€ƒè®ºæ–‡æ­£æ–‡ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åœ¨æ™ºèƒ½å®¶å±…è¯­éŸ³åŠ©æ‰‹åœºæ™¯ä¸­ï¼Œåˆ¤æ–­æ˜¯å¦æ¥å—æˆ–æ‹’ç»ç”¨æˆ·æŸ¥è¯¢æ˜¯è¿›è¡Œä»»ä½•ä¸‹æ¸¸å¤„ç†å‰çš„é¦–è¦æ­¥éª¤ã€‚é’ˆå¯¹å½“å‰è¯­éŸ³åŠ©æ‰‹æŸ¥è¯¢æ‹’è¯†èƒ½åŠ›æœ‰é™çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†é¦–ä¸ªé¢å‘ä¸­æ–‡æ™ºèƒ½å®¶å±…åœºæ™¯çš„å¼€æºåŸºå‡†ä¸è¯„ä¼°å¥—ä»¶ï¼Œå¹¶åŸºäºå¤§è¯­è¨€æ¨¡å‹æå‡ºä¸ªæ€§åŒ–æŸ¥è¯¢æ‹’è¯†æ–¹æ³•ã€‚åœ¨æ•°æ®å±‚é¢ï¼Œæˆ‘ä»¬æ„å»ºäº†é¦–ä¸ªé¢å‘å®¶å±…åœºæ™¯çš„å¤šæ¨¡æ€æŸ¥è¯¢æ‹’è¯†æ•°æ®é›†ï¼ŒåŒ…å«11,913ä¸ªç»äººå·¥æ ‡æ³¨çš„æ–‡æœ¬-è¯­éŸ³å¯¹ï¼Œç³»ç»Ÿè¦†ç›–é—²èŠã€éäººå£°ã€æœ‰æ•ˆæŒ‡ä»¤ã€æ¨¡ç³ŠæŒ‡ä»£ã€è®¾å¤‡æ— å…³è¯·æ±‚ç­‰åäºŒç±»å…¸å‹å¯¹è¯ç±»å‹â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10257v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10257.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ è‡ªé€‚åº”è½¯æ»šåŠ¨é”®å€¼å†»ç»“ä¸ç†µå¼•å¯¼æ¢å¤ï¼šå®ç°é«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„äºšçº¿æ€§å†…å­˜å¢é•¿</strong></p>
<p><em>Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery: Sublinear Memory Growth for Efficient LLM Inference</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒã€æ¨ç†æ—¶é«˜æ•ˆçš„LLMç”Ÿæˆæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¯é€†çš„è½¯å†»ç»“æœºåˆ¶å’ŒåŸºäºç†µçš„æ¢å¤ç­–ç•¥ï¼Œèƒ½åœ¨æ˜¾è‘—å‡å°‘KVç¼“å­˜çš„åŒæ—¶ä¿æŒç”Ÿæˆè´¨é‡ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•é€šè¿‡æ»‘åŠ¨æ³¨æ„åŠ›çª—å£è¯†åˆ«ä½é‡è¦æ€§tokenï¼Œå¹¶å¯¹å…¶KVçŠ¶æ€è¿›è¡Œå¯é€†çš„è½¯å†»ç»“ï¼ˆæš‚åœæ›´æ–°ï¼‰ï¼ŒåŒæ—¶åˆ©ç”¨ç†µå€¼æŒ‡å¯¼æ¢å¤å†»ç»“çš„tokenï¼Œå¹¶é‡‡ç”¨äºšçº¿æ€§çš„å†»ç»“è°ƒåº¦ç­–ç•¥é˜²æ­¢è¿‡åº¦å‹ç¼©ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æˆ‘ä»¬æå‡ºè‡ªé€‚åº”è½¯æ»šåŠ¨KVå†»ç»“ä¸ç†µå¼•å¯¼æ¢å¤ï¼ˆASR-KF-EGRï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„é«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹æ¨ç†æ¡†æ¶ã€‚è¯¥æ–¹æ³•å¼•å…¥å¯é€†è½¯å†»ç»“æœºåˆ¶ï¼Œåœ¨æ»‘åŠ¨æ³¨æ„åŠ›çª—å£å†…å¯¹è¯†åˆ«å‡ºçš„ä½é‡è¦æ€§ä»¤ç‰Œä¸´æ—¶æš‚åœé”®å€¼ï¼ˆKVï¼‰æ›´æ–°ã€‚ä¸æ°¸ä¹…ä¸¢å¼ƒä¸Šä¸‹æ–‡çš„é©±é€å¼æ–¹æ³•ä¸åŒï¼ŒASR-KF-EGRå°†æ‰€æœ‰ä»¤ç‰Œä¿å­˜åœ¨GPUå¤–å­˜å‚¨å™¨ä¸­å¹¶æŒ‰éœ€æ¢å¤ã€‚æˆ‘ä»¬é€šè¿‡äºšçº¿æ€§å†»ç»“è°ƒåº¦æ‰©å±•è¯¥æ¡†æ¶â€”â€”å†»ç»“æ—¶é•¿éšä½é‡è¦æ€§é‡å¤æ£€æµ‹æ¬¡æ•°å‘ˆäºšçº¿æ€§å¢é•¿ï¼Œä»è€Œé¿å…è¿‡åº¦å‹ç¼©ã€‚åœ¨Lâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11221v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11221.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HBLLMï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„åŸºäºå°æ³¢å¢å¼ºçš„é«˜ä¿çœŸ1æ¯”ç‰¹é‡åŒ–æ–¹æ³•</strong></p>
<p><em>HBLLM: Wavelet-Enhanced High-Fidelity 1-Bit Quantization for LLMs</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§åŸºäºHaarå°æ³¢å˜æ¢å¢å¼ºçš„1æ¯”ç‰¹åè®­ç»ƒé‡åŒ–æ–¹æ³•HBLLMï¼Œé€šè¿‡é¢‘ç‡åˆ†è§£æå‡è¡¨è¾¾èƒ½åŠ›ï¼Œå¹¶è®¾è®¡äº†ä¸¤ç§ç»“æ„æ„ŸçŸ¥åˆ†ç»„ç­–ç•¥ä»¥ä¼˜åŒ–é‡åŒ–ä¿çœŸåº¦ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: åˆ©ç”¨Haarå°æ³¢å¯¹æƒé‡è¿›è¡Œé¢‘ç‡åˆ†è§£ï¼Œç»“åˆé¢‘ç‡æ„ŸçŸ¥çš„è¡Œå†…å¤šå‚æ•°åˆ†ç»„å’ŒåŸºäºâ„“â‚‚èŒƒæ•°çš„æ˜¾è‘—æ€§åˆ—é€‰æ‹©ç­–ç•¥ï¼Œå¯¹éæ˜¾è‘—æƒé‡é‡‡ç”¨é¢‘å¸¦å†…å…±äº«å‡å€¼ä»¥æå‡å­˜å‚¨æ•ˆç‡ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æˆ‘ä»¬æå‡ºHBLLMï¼Œä¸€ç§åŸºäºå°æ³¢å¢å¼ºçš„é«˜ä¿çœŸ1æ¯”ç‰¹åè®­ç»ƒé‡åŒ–æ–¹æ³•ï¼Œä¸“ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹è®¾è®¡ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨å“ˆå°”å°æ³¢å˜æ¢è¿›è¡Œé¢‘åŸŸåˆ†è§£ä»¥å¢å¼ºè¡¨è¾¾èƒ½åŠ›ï¼Œåœ¨ä¿æŒæä½å¼€é”€çš„åŒæ—¶æ˜¾è‘—æå‡äº†é‡åŒ–ä¿çœŸåº¦ã€‚HBLLMåŒ…å«ä¸¤é¡¹åˆ›æ–°çš„ç»“æ„æ„ŸçŸ¥åˆ†ç»„ç­–ç•¥ï¼šï¼ˆ1ï¼‰é¢‘ç‡æ„ŸçŸ¥çš„å¤šå‚æ•°è¡Œå†…åˆ†ç»„ï¼›ï¼ˆ2ï¼‰åŸºäº$\ell_2$èŒƒæ•°çš„æ˜¾è‘—æ€§é©±åŠ¨åˆ—é€‰æ‹©ã€‚å¯¹äºéæ˜¾è‘—æ€§æƒé‡ï¼Œæˆ‘ä»¬åœ¨æ¯ä¸ªé¢‘æ®µå†…çš„é‡åŒ–ç»„é—´é‡‡ç”¨å…±äº«å‡å€¼ç­–ç•¥ä»¥ä¼˜åŒ–å­˜å‚¨æ•ˆç‡ã€‚åœ¨OPTå’ŒLLaâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.00862v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.00862.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œç³»ç»Ÿç»¼è¿°çš„æ ‡é¢˜ä¸æ‘˜è¦ç­›é€‰ï¼šä¸€ç§ç»æµé«˜æ•ˆçš„åŠ¨æ€å°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•</strong></p>
<p><em>Leveraging LLMs for Title and Abstract Screening for Systematic Review: A Cost-Effective Dynamic Few-Shot Learning Approach</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>å¯èƒ½å‘è¡¨äºåŒ»å­¦ä¿¡æ¯å­¦æˆ–äººå·¥æ™ºèƒ½åº”ç”¨é¢†åŸŸçš„ä¼šè®®æˆ–æœŸåˆŠï¼Œå¦‚ Journal of Biomedical Informaticsã€AMIA Annual Symposium æˆ– AAAI ç­‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§ç”¨äºç³»ç»Ÿç»¼è¿°æ–‡çŒ®ç­›é€‰çš„ä¸¤é˜¶æ®µåŠ¨æ€å°‘æ ·æœ¬å­¦ä¹ ï¼ˆDFSLï¼‰æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆä½æˆæœ¬å’Œé«˜æ€§èƒ½å¤§è¯­è¨€æ¨¡å‹ï¼Œåœ¨æ§åˆ¶è®¡ç®—æˆæœ¬çš„åŒæ—¶æå‡ç­›é€‰æ•ˆç‡ä¸æ€§èƒ½ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•é¦–å…ˆä½¿ç”¨ä½æˆæœ¬å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œåˆæ­¥ç­›é€‰ï¼Œç„¶åå¯¹ä½ç½®ä¿¡åº¦çš„æ ·æœ¬ä½¿ç”¨é«˜æ€§èƒ½å¤§è¯­è¨€æ¨¡å‹è¿›è¡ŒäºŒæ¬¡è¯„ä¼°ï¼Œä»è€Œå®ç°æˆæœ¬ä¸æ€§èƒ½çš„å¹³è¡¡ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç³»ç»Ÿç»¼è¿°æ˜¯å¾ªè¯åŒ»å­¦çš„å…³é”®ç»„æˆéƒ¨åˆ†ï¼Œåœ¨ç»¼åˆç°æœ‰ç ”ç©¶è¯æ®å’ŒæŒ‡å¯¼ä¸´åºŠå†³ç­–æ–¹é¢å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç„¶è€Œï¼Œéšç€ç ”ç©¶æ–‡çŒ®çš„å¿«é€Ÿå¢é•¿ï¼Œå¼€å±•ç³»ç»Ÿç»¼è¿°çš„å·¥ä½œè´Ÿæ‹…æ—¥ç›ŠåŠ é‡ï¼Œå…¶ä¸­æ ‡é¢˜ä¸æ‘˜è¦ç­›é€‰ç¯èŠ‚å°¤ä¸ºè€—æ—¶è€—åŠ›ã€‚ä¸ºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä¸¤é˜¶æ®µåŠ¨æ€å°‘æ ·æœ¬å­¦ä¹ ï¼ˆDFSLï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ ‡é¢˜ä¸æ‘˜è¦ç­›é€‰ä»»åŠ¡ä¸­çš„æ•ˆç‡ä¸æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•é¦–å…ˆä½¿ç”¨ä½æˆæœ¬LLMè¿›è¡Œåˆæ­¥ç­›é€‰ï¼Œéšåé‡‡ç”¨é«˜æ€§èƒ½LLMå¯¹ä½ç½®â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11261v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11261.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A-LAMPï¼šåŸºäºæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–MDPå»ºæ¨¡ä¸ç­–ç•¥ç”Ÿæˆæ¡†æ¶</strong></p>
<p><em>A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>ICLR 2025 æˆ– NeurIPS 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºé¦–ä¸ªåŸºäºæ™ºèƒ½ä½“åŒ–å¤§è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–æ¡†æ¶A-LAMPï¼Œèƒ½å¤Ÿå°†éæ­£å¼çš„è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°è‡ªåŠ¨è½¬åŒ–ä¸ºå®Œæ•´çš„MDPæ¨¡å‹å’Œè®­ç»ƒå¥½çš„ç­–ç•¥ï¼Œå¹¶é€šè¿‡å¯éªŒè¯çš„é˜¶æ®µåˆ†è§£ç¡®ä¿è¯­ä¹‰å¯¹é½ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ¡†æ¶å°†å»ºæ¨¡ã€ç¼–ç å’Œè®­ç»ƒåˆ†è§£ä¸ºå¤šä¸ªå¯éªŒè¯çš„é˜¶æ®µï¼Œåˆ©ç”¨æ™ºèƒ½ä½“åŒ–LLMè‡ªåŠ¨å®Œæˆä»ä»»åŠ¡æè¿°åˆ°MDPå½¢å¼åŒ–ã€ç¯å¢ƒä»£ç å®ç°åŠç­–ç•¥ç”Ÿæˆçš„å…¨æµç¨‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºç°å®ä»»åŠ¡éœ€è¦å°†éå½¢å¼åŒ–æè¿°è½¬åŒ–ä¸ºå½¢å¼åŒ–çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œå®ç°å¯æ‰§è¡Œç¯å¢ƒï¼Œå¹¶è®­ç»ƒç­–ç•¥æ™ºèƒ½ä½“ã€‚ç”±äºå»ºæ¨¡è¯¯å·®ã€ä»£ç è„†å¼±æ€§åŠç›®æ ‡é”™ä½ç­‰é—®é¢˜å¸¸é˜»ç¢ç­–ç•¥è®­ç»ƒï¼Œè‡ªåŠ¨åŒ–è¿™ä¸€è¿‡ç¨‹é¢‡å…·æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºä¸€ç§åŸºäºæ™ºèƒ½ä½“åŒ–å¤§è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–MDPå»ºæ¨¡ä¸ç­–ç•¥ç”Ÿæˆæ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å°†è‡ªç”±å½¢å¼çš„è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°è½¬åŒ–ä¸ºMDPå½¢å¼åŒ–è¡¨è¿°åŠè®­ç»ƒå®Œæˆçš„ç­–ç•¥ã€‚è¯¥æ¡†æ¶å°†å»ºæ¨¡ã€ç¼–ç ä¸è®­ç»ƒåˆ†è§£ä¸ºå¯éªŒè¯çš„é˜¶æ®µï¼Œç¡®ä¿å…¨æµç¨‹çš„è¯­ä¹‰å¯¹é½ã€‚åœ¨â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11270v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11270.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ BAMBOï¼šé€šè¿‡è´å¶æ–¯è‡ªé€‚åº”å¤šç›®æ ‡åˆ†å—ä¼˜åŒ–æ„å»ºèƒ½åŠ›ä¸æ•ˆç‡å¹¶é‡çš„LLMå¸•ç´¯æ‰˜é›†</strong></p>
<p><em>BAMBO: Construct Ability and Efficiency LLM Pareto Set via Bayesian Adaptive Multi-objective Block-wise Optimization</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºBAMBOæ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥æ··åˆæœ€ä¼˜å—åˆ’åˆ†ç­–ç•¥ï¼Œå°†é«˜ç»´æœç´¢ç©ºé—´é™ç»´ï¼Œé¦–æ¬¡å®ç°äº†åœ¨å¯è®¡ç®—å¤æ‚åº¦ä¸‹è‡ªåŠ¨æ„å»ºå¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›ä¸æ•ˆç‡çš„å¸•ç´¯æ‰˜å‰æ²¿ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: å°†æ¨¡å‹åˆ’åˆ†å»ºæ¨¡ä¸ºä¸€ç»´èšç±»é—®é¢˜ï¼Œåˆ©ç”¨åŠ¨æ€è§„åˆ’è‡ªåŠ¨å¹³è¡¡å—å†…åŒè´¨æ€§ä¸å—é—´ä¿¡æ¯åˆ†å¸ƒï¼Œä»è€Œåœ¨ä¿æŒå…³é”®ç²’åº¦çš„åŒæ—¶å¤§å¹…é™ä½æœç´¢ç»´åº¦ï¼Œå®ç°å¸•ç´¯æ‰˜é›†çš„è´å¶æ–¯è‡ªé€‚åº”å¤šç›®æ ‡ä¼˜åŒ–ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ„å»ºå¸•ç´¯æ‰˜é›†å¯¹äºæƒè¡¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›ä¸æ•ˆç‡è‡³å…³é‡è¦ï¼Œç„¶è€Œç°æœ‰èåˆæŠ€æœ¯ä»éš¾ä»¥èƒœä»»æ­¤ä»»åŠ¡ã€‚ç²—ç²’åº¦çš„æ¨¡å‹çº§æ–¹æ³•ä»…èƒ½ç”Ÿæˆç¨€ç–çš„æ¬¡ä¼˜è§£é›†ï¼Œè€Œç»†ç²’åº¦çš„åˆ†å±‚æ–¹æ³•åˆ™å—å›°äºâ€ç»´åº¦ç¾éš¾â€ï¼Œå¯¼è‡´æœç´¢ç©ºé—´åœ¨è®¡ç®—ä¸Šéš¾ä»¥å¤„ç†ã€‚ä¸ºç ´è§£è¿™ä¸€å›°å¢ƒï¼Œæˆ‘ä»¬æå‡ºBAMBOï¼ˆè´å¶æ–¯è‡ªé€‚åº”å¤šç›®æ ‡å—ä¼˜åŒ–ï¼‰â€”â€”ä¸€ç§è‡ªåŠ¨æ„å»ºLLMå¸•ç´¯æ‰˜é›†çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥æ··åˆæœ€ä¼˜å—åˆ’åˆ†ç­–ç•¥ï¼Œä½¿æœç´¢è¿‡ç¨‹å˜å¾—å¯å¤„ç†ã€‚è¯¥ç­–ç•¥è¢«æ„å»ºä¸ºä¸€ç»´èšç±»é—®é¢˜ï¼Œé‡‡â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09972v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09972.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åœŸæ˜Ÿï¼šåŸºäºSATçš„å¼ºåŒ–å­¦ä¹ é‡Šæ”¾å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›</strong></p>
<p><em>SATURN: SAT-based Reinforcement Learning to Unleash LLMs Reasoning</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºSATURNæ¡†æ¶ï¼Œé¦–æ¬¡å°†å¸ƒå°”å¯æ»¡è¶³æ€§é—®é¢˜ï¼ˆSATï¼‰ä½œä¸ºå¼ºåŒ–å­¦ä¹ ä»»åŠ¡ï¼Œä»¥å¯æ‰©å±•ã€å¯éªŒè¯ä¸”éš¾åº¦å¯æ§çš„æ–¹å¼è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: åˆ©ç”¨SATé—®é¢˜è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œé€šè¿‡åŸºäºè§„åˆ™çš„éªŒè¯ç¡®ä¿è¾“å‡ºæ­£ç¡®æ€§ï¼Œå¹¶è®¾è®¡è¯¾ç¨‹å­¦ä¹ æµç¨‹ï¼Œä½¿æ¨¡å‹ä»æ˜“åˆ°éš¾é€æ­¥æå‡æ¨ç†èƒ½åŠ›ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å¦‚ä½•è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆæ¿€å‘å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ï¼Œä»æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚ç°æœ‰å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ï¼ˆå¦‚æ•°å­¦ã€ç¼–ç¨‹å’Œæ¨ç†æ„å»ºä»»åŠ¡ï¼‰å­˜åœ¨ä¸‰ä¸ªå…³é”®å±€é™ï¼šï¼ˆ1ï¼‰å¯æ‰©å±•æ€§ä¸è¶³ã€‚è¿™äº›ä»»åŠ¡ä¸¥é‡ä¾èµ–äººå·¥æ ‡æ³¨æˆ–æ˜‚è´µçš„å¤§è¯­è¨€æ¨¡å‹åˆæˆæ¥ç”Ÿæˆè¶³é‡è®­ç»ƒæ•°æ®ã€‚ï¼ˆ2ï¼‰å¯éªŒè¯æ€§ç¼ºå¤±ã€‚å¤§è¯­è¨€æ¨¡å‹çš„è¾“å‡ºéš¾ä»¥å®ç°è‡ªåŠ¨åŒ–å¯é éªŒè¯ã€‚ï¼ˆ3ï¼‰éš¾åº¦å¯æ§æ€§å¼±ã€‚å¤šæ•°ä»»åŠ¡ç¼ºä¹ç»†ç²’åº¦éš¾åº¦æ§åˆ¶ï¼Œéš¾ä»¥å®ç°ä»æ˜“åˆ°éš¾çš„æ¸è¿›å¼æ¨ç†èƒ½åŠ›è®­ç»ƒã€‚ä¸ºçªç ´è¿™äº›å±€é™ï¼Œæˆ‘ä»¬æå‡ºSâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.16368v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.16368.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ å¤§è¯­è¨€æ¨¡å‹ä¸­çš„è®°å¿†åŒ–ç°è±¡ï¼šæœºåˆ¶ã€æµ‹é‡ä¸ç¼“è§£ç­–ç•¥</strong></p>
<p><em>The Landscape of Memorization in LLMs: Mechanisms, Measurement, and Mitigation</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– ç»¼è¿°ç±»é¡¶ä¼š/æœŸåˆŠï¼ˆå¦‚ ACM Computing Surveys, Foundations and TrendsÂ® in Machine Learningï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æœ¬æ–‡å¹¶éæå‡ºå•ä¸€æ–°æ–¹æ³•ï¼Œè€Œæ˜¯å¯¹LLMè®°å¿†åŒ–ç°è±¡è¿›è¡Œäº†ç³»ç»Ÿæ€§ç»¼è¿°ï¼Œæ•´åˆäº†å…¶æœºåˆ¶ã€æµ‹é‡ä¸ç¼“è§£ç­–ç•¥ï¼Œå¹¶æ¢è®¨äº†æ³•å¾‹ä¸ä¼¦ç†ç­‰æ›´å¹¿æ³›çš„å½±å“ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è®ºæ–‡æ„å»ºäº†ä¸€ä¸ªåˆ†ææ¡†æ¶ï¼Œä»è®­ç»ƒæ•°æ®é‡å¤ã€è®­ç»ƒåŠ¨æ€å’Œå¾®è°ƒç­‰é©±åŠ¨å› ç´ å‡ºå‘ï¼Œç³»ç»Ÿæ¢³ç†äº†åŸºäºå‰ç¼€æå–ã€æˆå‘˜æ¨æ–­å’Œå¯¹æŠ—æç¤ºç­‰æ£€æµ‹ä¸æµ‹é‡æ–¹æ³•ï¼Œå¹¶è®¨è®ºäº†ç›¸åº”çš„ç¼“è§£ç­–ç•¥ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²åœ¨å¹¿æ³›ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šèƒ½åŠ›ï¼Œä½†å…¶å¯¹è®­ç»ƒæ•°æ®çš„è®°å¿†ç°è±¡ä¹Ÿæ—¥ç›Šå‡¸æ˜¾ã€‚è¿™ä¸€ç°è±¡å¼•å‘äº†å…³äºæ¨¡å‹è¡Œä¸ºã€éšç§é£é™©ä»¥åŠå­¦ä¹ ä¸è®°å¿†è¾¹ç•Œçš„æ·±åˆ»æ€è€ƒã€‚æœ¬æ–‡ç»¼åˆè¿‘æœŸç ”ç©¶ï¼Œç³»ç»Ÿæ¢è®¨äº†è®°å¿†ç°è±¡çš„è¡¨ç°å½¢å¼ã€å½±å“å› ç´ åŠå…¶æ£€æµ‹ä¸ç¼“è§£æ–¹æ³•ã€‚æˆ‘ä»¬åˆ†æäº†è®­ç»ƒæ•°æ®é‡å¤ã€è®­ç»ƒåŠ¨æ€è¿‡ç¨‹åŠå¾®è°ƒç¨‹åºç­‰å½±å“æ•°æ®è®°å¿†çš„å…³é”®é©±åŠ¨å› ç´ ï¼Œå¹¶è¯„ä¼°äº†åŸºäºå‰ç¼€çš„æå–ã€æˆå‘˜æ¨ç†å’Œå¯¹æŠ—æ€§æç¤ºç­‰æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚é™¤æŠ€æœ¯åˆ†æå¤–ï¼Œæœ¬æ–‡è¿˜æ¢è®¨äº†è®°å¿†ç°è±¡â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.05578v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.05578.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MemoryBenchï¼šå¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿä¸­çš„è®°å¿†ä¸æŒç»­å­¦ä¹ åŸºå‡†æµ‹è¯•</strong></p>
<p><em>MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ä¸ªåä¸ºMemoryBenchçš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿåœ¨æŒç»­å­¦ä¹ æ–¹é¢çš„èƒ½åŠ›ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºé€šè¿‡æ¨¡æ‹Ÿç”¨æˆ·åé¦ˆæ¥æµ‹è¯•æ¨¡å‹ä»æœåŠ¡æœŸé—´ç´¯ç§¯ç»éªŒä¸­å­¦ä¹ çš„èƒ½åŠ›ï¼Œè€Œéä»…é’ˆå¯¹é•¿æ–‡æœ¬é˜…è¯»ç†è§£ä»»åŠ¡ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ„å»ºäº†ä¸€ä¸ªç”¨æˆ·åé¦ˆæ¨¡æ‹Ÿæ¡†æ¶å’Œä¸€ä¸ªè¦†ç›–å¤šé¢†åŸŸã€å¤šè¯­è¨€ã€å¤šä»»åŠ¡ç±»å‹çš„ç»¼åˆæ€§åŸºå‡†ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿåœ¨æŒç»­å­¦ä¹ åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ‰©å¤§æ•°æ®è§„æ¨¡ã€å‚æ•°è§„æ¨¡ä»¥åŠæµ‹è¯•æ—¶çš„è®¡ç®—é‡ï¼Œä¸€ç›´æ˜¯æå‡å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿï¼ˆLLMsysï¼‰çš„ä¸»æµæ–¹æ³•ï¼Œä½†ç”±äºé«˜è´¨é‡æ•°æ®é€æ¸è€—å°½ï¼Œä»¥åŠæ›´å¤§è®¡ç®—èµ„æºæ¶ˆè€—å¸¦æ¥çš„è¾¹é™…æ”¶ç›Šé€’å‡ï¼Œè¿™äº›æ–¹æ³•çš„ä¸Šé™å·²è¿‘åœ¨çœ¼å‰ã€‚å—äººç±»å’Œä¼ ç»Ÿäººå·¥æ™ºèƒ½ç³»ç»Ÿä»å®è·µä¸­å­¦ä¹ çš„èƒ½åŠ›å¯å‘ï¼Œä¸ºLLMsysæ„å»ºè®°å¿†ä¸æŒç»­å­¦ä¹ æ¡†æ¶å·²æˆä¸ºè¿‘å¹´æ–‡çŒ®ä¸­é‡è¦ä¸”çƒ­é—¨çš„ç ”ç©¶æ–¹å‘ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹è®°å¿†åŸºå‡†æµ‹è¯•å¾€å¾€ä¾§é‡äºè¯„ä¼°ç³»ç»Ÿåœ¨é•¿æ–‡æœ¬è¾“å…¥çš„åŒè´¨é˜…è¯»ç†è§£ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.17281v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.17281.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ é›¶æ ·æœ¬ä¸‰ç»´åœ°å›¾ç”Ÿæˆä¸LLMæ™ºèƒ½ä½“ï¼šä¸€ç§ç”¨äºç¨‹åºåŒ–å†…å®¹ç”Ÿæˆçš„åŒæ™ºèƒ½ä½“æ¶æ„</strong></p>
<p><em>Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– ICLR 2025ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„åŒæ™ºèƒ½ä½“æ¶æ„ï¼Œåˆ©ç”¨LLMæ™ºèƒ½ä½“å®ç°é›¶æ ·æœ¬çš„ç¨‹åºåŒ–å†…å®¹ç”Ÿæˆå‚æ•°é…ç½®ï¼Œé€šè¿‡è¿­ä»£æ¨ç†å’Œä¼˜åŒ–æ¥å¼¥åˆç”¨æˆ·æŒ‡ä»¤ä¸ä¸¥æ ¼å‚æ•°è§„èŒƒä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é‡‡ç”¨â€œæ‰§è¡Œè€…-è¯„è®ºè€…â€åŒæ™ºèƒ½ä½“æ¶æ„ï¼Œæ‰§è¡Œè€…è´Ÿè´£ç”Ÿæˆå‚æ•°é…ç½®ï¼Œè¯„è®ºè€…è´Ÿè´£è¯„ä¼°å’Œåé¦ˆï¼Œé€šè¿‡ä¸¤è€…åä½œçš„è¿­ä»£å·¥ä½œæµï¼Œä½¿ç³»ç»Ÿèƒ½è‡ªä¸»æ¨ç†å¹¶é€æ­¥ä¼˜åŒ–é…ç½®ä»¥ç¬¦åˆäººç±»è®¾è®¡åå¥½ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç¨‹åºåŒ–å†…å®¹ç”Ÿæˆï¼ˆPCGï¼‰ä¸ºç®—æ³•åŒ–åˆ›å»ºå¤æ‚ã€å¯å®šåˆ¶çš„ä¸–ç•Œæä¾›äº†å¯æ‰©å±•çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œæ§åˆ¶è¿™äº›æµç¨‹éœ€è¦å¯¹ä¸é€æ˜çš„æŠ€æœ¯å‚æ•°è¿›è¡Œç²¾ç¡®é…ç½®ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å…è®­ç»ƒæ¶æ„ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“å®ç°é›¶æ ·æœ¬PCGå‚æ•°é…ç½®ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹æœ‰æœ›ä¸ºPCGå·¥å…·æä¾›è‡ªç„¶è¯­è¨€æ¥å£ï¼Œä½†ç°æˆæ¨¡å‹å¾€å¾€éš¾ä»¥å¼¥åˆæŠ½è±¡ç”¨æˆ·æŒ‡ä»¤ä¸ä¸¥æ ¼å‚æ•°è§„èŒƒä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿã€‚æˆ‘ä»¬çš„ç³»ç»Ÿå°†æ‰§è¡Œè€…æ™ºèƒ½ä½“ä¸è¯„å®¡è€…æ™ºèƒ½ä½“é…å¯¹ï¼Œé€šè¿‡è¿­ä»£å·¥ä½œæµç¨‹ä½¿ç³»ç»Ÿèƒ½å¤Ÿè‡ªä¸»æ¨ç†å·¥å…·å‚â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10501v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10501.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ é€šè¿‡ä¼˜é€‰æ•°æ®æå‡LLMå¾®è°ƒç¿»è¯‘è´¨é‡ï¼šä¸€é¡¹å¯¹æ¯”åˆ†æ</strong></p>
<p><em>Improving Translation Quality by Selecting Better Data for LLM Fine-Tuning: A Comparative Analysis</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„é¡¶çº§ä¼šè®®ï¼ˆå¦‚ ACL, EMNLP, NAACLï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: é€šè¿‡å®è¯ç ”ç©¶å‘ç°ï¼Œåœ¨ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœºå™¨ç¿»è¯‘ä»»åŠ¡è¿›è¡Œå¾®è°ƒæ—¶ï¼ŒåŸºäºè¯­ä¹‰çš„æ•°æ®é€‰æ‹©æ–¹æ³•ï¼ˆå¦‚COMET Kiwiã€QuRateï¼‰æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„åŸºäºè¯æ±‡æˆ–å‡ ä½•çš„å¯å‘å¼æ–¹æ³•ï¼Œå¹¶æ­ç¤ºäº†å³ä½¿æ‰€é€‰æ•°æ®å·®å¼‚æå°ï¼ˆ&lt;3%ï¼‰ï¼Œå¯¹æœ€ç»ˆæ¨¡å‹æ€§èƒ½ä¹Ÿæœ‰æ˜¾è‘—å½±å“ï¼Œè¿™å‡¸æ˜¾äº†å¾®è°ƒè¿‡ç¨‹å¯¹æ•°æ®è´¨é‡çš„æç«¯æ•æ„Ÿæ€§ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: ç ”ç©¶åœ¨æ—¥è‹±ç¿»è¯‘ä»»åŠ¡ä¸Šï¼Œé‡‡ç”¨æ§åˆ¶å˜é‡å®éªŒï¼Œç³»ç»Ÿæ¯”è¾ƒäº†TF-IDFï¼ˆè¯æ±‡ï¼‰ã€COMET Kiwiï¼ˆè¯­ä¹‰è´¨é‡ï¼‰ã€QuRateï¼ˆè¯­ä¹‰å¤šæ ·æ€§ï¼‰ã€FD-Scoreï¼ˆå‡ ä½•ï¼‰å’Œéšæœºé€‰æ‹©è¿™äº”ç§æ•°æ®é€‰æ‹©å™¨å¯¹LLMå¾®è°ƒæ•ˆæœçš„å½±å“ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æœ¬ç ”ç©¶æ¢è®¨äº†æ•°æ®é€‰æ‹©å¯¹å¼€æ”¾å¤§è¯­è¨€æ¨¡å‹æœºå™¨ç¿»è¯‘å¾®è°ƒçš„å½±å“ã€‚åŸºäºæ—¥è‹±å¹³è¡Œè¯­æ–™ï¼Œæˆ‘ä»¬åœ¨å—æ§è®­ç»ƒæ¡ä»¶ä¸‹æ¯”è¾ƒäº†äº”ç§æ•°æ®é€‰æ‹©æ–¹æ³•ï¼šTF-IDFã€COMET Kiwiã€QuRateã€FD-ScoreåŠéšæœºé€‰æ‹©ã€‚å®éªŒå‘ç°ï¼ŒåŸºäºè¯­ä¹‰çš„é€‰æ‹©æ–¹æ³•åœ¨æ€§èƒ½ä¸ŠæŒç»­ä¼˜äºåŸºäºè¯æ±‡å’Œå‡ ä½•ç‰¹å¾çš„å¯å‘å¼æ–¹æ³•ï¼›å³ä½¿æ‰€é€‰æ•°æ®å·®å¼‚ä¸è¶³3%ï¼Œå¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ä¾ç„¶æ˜¾è‘—ï¼Œè¿™å‡¸æ˜¾äº†å¾®è°ƒè¿‡ç¨‹å¯¹æ•°æ®è´¨é‡çš„é«˜åº¦æ•æ„Ÿæ€§ã€‚</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11388v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11388.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ æ·±åº¦å­¦ä¹ åŠ é€Ÿå¤šèµ·ç‚¹å¤§é‚»åŸŸæœç´¢åœ¨å®æ—¶è´§è¿æ†ç»‘ä¸­çš„åº”ç”¨</strong></p>
<p><em>Deep Learningâ€“Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>ICAPS 2025 æˆ– Transportation Science</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§ç»“åˆTransformerç¥ç»ç½‘ç»œæ„å»ºç­–ç•¥ä¸å¤šèµ·ç‚¹å¤§é‚»åŸŸæœç´¢å…ƒå¯å‘å¼ç®—æ³•çš„æ··åˆæœç´¢æ¡†æ¶ï¼Œç”¨äºè§£å†³åœ¨çº¿è´§è¿äº¤æ˜“ç³»ç»Ÿä¸­å®æ—¶è´§è¿æ†ç»‘ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œå®ç°äº†äºšç§’çº§å»¶è¿Ÿä¸‹çš„é«˜æ•ˆæ±‚è§£ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: é‡‡ç”¨æ»šåŠ¨æ—¶åŸŸæ–¹æ¡ˆï¼Œå°†åŠ¨æ€å¸‚åœºå†»ç»“ä¸ºé™æ€å¿«ç…§ï¼Œé€šè¿‡åŸºäºTransformerçš„æ„é€ æ€§ç­–ç•¥ç”Ÿæˆåˆå§‹è§£ï¼Œå†è¿ç”¨åˆ›æ–°çš„å¤šèµ·ç‚¹å¤§é‚»åŸŸæœç´¢è¿›è¡Œå¿«é€Ÿä¼˜åŒ–ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: åœ¨çº¿è´§è¿äº¤æ˜“ç³»ç»Ÿé€šè¿‡å®æ—¶åŒ¹é…è´§ä¸»ä¸æ‰¿è¿å•†ï¼Œåœ¨ç°ä»£è´§è¿ç‰©æµä¸­å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚ç„¶è€Œï¼Œè¿è¾“ä»»åŠ¡çš„ç»„åˆæ‰“åŒ…æ•ˆç‡ä»æ˜¯ç“¶é¢ˆã€‚æˆ‘ä»¬å°†è¯¥ç³»ç»Ÿçš„ç»„åˆæ‰“åŒ…é—®é¢˜å»ºæ¨¡ä¸ºå¤šå•†å“ä¸€å¯¹ä¸€å–é€è´§é€‰æ‹©æ€§æ—…è¡Œå•†é—®é¢˜ï¼Œåœ¨å®¹é‡ã€ä¼˜å…ˆçº§å’Œè·¯çº¿é•¿åº¦çº¦æŸä¸‹ä¼˜åŒ–æ”¶ç›Šé©±åŠ¨çš„è´§è¿æ‰“åŒ…ã€‚æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºäºšç§’çº§å»¶è¿Ÿä¸‹å®ç°ç»„åˆæ‰“åŒ…é€‰æ‹©ä¸å–é€è´§è·¯å¾„è§„åˆ’çš„ååŒã€‚æˆ‘ä»¬æå‡ºä¸€ç§å­¦ä¹ åŠ é€Ÿæ··åˆæœç´¢æ¡†æ¶ï¼šåœ¨æ»šåŠ¨æ—¶åŸŸæ–¹æ¡ˆä¸­ï¼Œå¹³å°å°†åŠ¨æ€å¸‚åœºåå¤å†»ç»“ä¸ºé™æ€å¿«ç…§ï¼Œé€šè¿‡åŸºäºTranâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11187v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11187.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MetaVoxelï¼šå½±åƒä¸ä¸´åºŠå…ƒæ•°æ®çš„è”åˆæ‰©æ•£å»ºæ¨¡</strong></p>
<p><em>MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>MICCAI 2024 / Medical Image Analysis æœŸåˆŠ æˆ– arXiv preprintã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºMetaVoxelï¼Œä¸€ç§è”åˆæ‰©æ•£å»ºæ¨¡æ¡†æ¶ï¼Œé€šè¿‡å•ä¸€æ‰©æ•£è¿‡ç¨‹ç»Ÿä¸€å»ºæ¨¡åŒ»å­¦å½±åƒä¸ä¸´åºŠå…ƒæ•°æ®çš„è”åˆåˆ†å¸ƒï¼Œå®ç°äº†å¤šä»»åŠ¡ï¼ˆå¦‚å›¾åƒç”Ÿæˆã€å¹´é¾„æ€§åˆ«é¢„æµ‹ï¼‰çš„é›¶æ ·æœ¬çµæ´»æ¨ç†ï¼Œæ— éœ€ä¸ºä¸åŒä»»åŠ¡å•ç‹¬è®­ç»ƒæ¨¡å‹ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯å­¦ä¹ ä¸€ä¸ªè¦†ç›–æ‰€æœ‰å˜é‡ï¼ˆå½±åƒå’Œå…ƒæ•°æ®ï¼‰çš„å•ä¸€æ‰©æ•£è¿‡ç¨‹ï¼Œä»è€Œæ•è·å…¶è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œæ”¯æŒä»¥ä»»æ„è¾“å…¥å­é›†ä¸ºæ¡ä»¶è¿›è¡Œç”Ÿæˆæˆ–é¢„æµ‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç°ä»£æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨ç–¾ç—…åˆ†ç±»ã€è¿ç»­ç”Ÿç‰©æ ‡å¿—ç‰©ä¼°è®¡ä¹ƒè‡³ç”Ÿæˆé€¼çœŸåŒ»å­¦å›¾åƒç­‰ä»»åŠ¡ä¸Šå–å¾—äº†ä»¤äººç©ç›®çš„æˆæœã€‚è¿™äº›æ–¹æ³•å¤§å¤šé€šè¿‡ç‰¹å®šé¢„æµ‹æ–¹å‘ä¸ç‰¹å®šè¾“å…¥å˜é‡é›†æ¥è®­ç»ƒæ¡ä»¶åˆ†å¸ƒæ¨¡å‹ã€‚æˆ‘ä»¬æå‡ºMetaVoxelâ€”â€”ä¸€ç§ç”Ÿæˆå¼è”åˆæ‰©æ•£å»ºæ¨¡æ¡†æ¶ï¼Œé€šè¿‡å­¦ä¹ è¦†ç›–æ‰€æœ‰å˜é‡çš„å•ä¸€æ‰©æ•£è¿‡ç¨‹ï¼Œå¯¹å½±åƒæ•°æ®ä¸ä¸´åºŠå…ƒæ•°æ®çš„è”åˆåˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡æ•æ‰è”åˆåˆ†å¸ƒï¼ŒMetaVoxelç»Ÿä¸€äº†ä¼ ç»Ÿä¸Šéœ€è¦ç‹¬ç«‹æ¡ä»¶æ¨¡å‹çš„ä»»åŠ¡ï¼Œå¹¶æ”¯æŒä½¿ç”¨ä»»æ„è¾“å…¥å­é›†è¿›è¡Œçµæ´»çš„â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10041v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10041.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DoDo-Codeï¼šä¸€ç§åŸºäºLevenshteinè·ç¦»åµŒå…¥çš„é«˜æ•ˆå››å…ƒIDSä¿¡é“ç¼–ç </strong></p>
<p><em>DoDo-Code: an Efficient Levenshtein Distance Embedding-based Code for 4-ary IDS Channel</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE Transactions on Information Theory æˆ– ISITï¼ˆå›½é™…ä¿¡æ¯è®ºç ”è®¨ä¼šï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§åŸºäºæ·±åº¦Levenshteinè·ç¦»åµŒå…¥çš„é«˜ç ç‡å•æ¬¡æ’å…¥ã€åˆ é™¤å’Œæ›¿æ¢ï¼ˆIDSï¼‰çº é”™ç è®¾è®¡æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰çŸ­ç é•¿ä¸‹ç ç‡ä½çš„é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹å°†åºåˆ—æ˜ å°„ä¸ºåµŒå…¥å‘é‡ï¼Œä½¿å‘é‡é—´çš„è·ç¦»ä¿æŒåŸå§‹åºåˆ—çš„Levenshteinè·ç¦»ï¼Œä»è€Œé«˜æ•ˆç”Ÿæˆçº é”™ç ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: éšç€æ–°å‹å­˜å‚¨ä¸é€šä¿¡æ–¹å¼çš„å‡ºç°ï¼Œæ’å…¥ã€åˆ é™¤ä¸æ›¿æ¢ï¼ˆIDSï¼‰ä¿¡é“å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå…³äºIDSä¿¡é“åŠå…¶ç›¸å…³è±æ–‡æ–¯å¦è·ç¦»çš„è¯¸å¤šé—®é¢˜ä»æœªè§£å†³ï¼Œä½¿å¾—æ–°å‹IDSçº é”™ç çš„è®¾è®¡æˆä¸ºä¸€é¡¹è‰°å·¨ä»»åŠ¡ã€‚ç°æœ‰å•IDSçº é”™ç çš„ç ”ç©¶ä¸å®é™…åº”ç”¨ä¸­éœ€çº æ­£å¤šé‡é”™è¯¯çš„éœ€æ±‚å­˜åœ¨åå·®ï¼Œå½“å‰æŠ˜è¡·æ–¹æ¡ˆé€šè¿‡ç¼©çŸ­ç å­—æ¥é™ä½å¤šé‡é”™è¯¯å‘ç”Ÿæ¦‚ç‡ï¼Œä½†çŸ­ç é•¿ä¸‹ç°æœ‰ç¼–ç æ–¹æ¡ˆçš„ç ç‡è¡¨ç°æ¬ ä½³ï¼Œå¯¼è‡´æ•´ä½“å­˜å‚¨å¯†åº¦é™ä½ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§é€šè¿‡æ·±åº¦è±æ–‡æ–¯å¦è·ç¦»åµŒå…¥è®¾è®¡é«˜ç â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.12717v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.12717.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ é¢å‘ç»ˆèº«æ·±åº¦å­¦ä¹ çš„ä»»åŠ¡æ„ŸçŸ¥å¤šä¸“å®¶æ¶æ„</strong></p>
<p><em>Task-Aware Multi-Expert Architecture For Lifelong Deep Learning</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åŸºäºä»»åŠ¡ç›¸ä¼¼æ€§çš„ç»ˆèº«å­¦ä¹ ç®—æ³•TAMEï¼Œé€šè¿‡ä»»åŠ¡æ„ŸçŸ¥çš„å¤šä¸“å®¶é€‰æ‹©å’Œæ³¨æ„åŠ›æœºåˆ¶å¼•å¯¼çš„çŸ¥è¯†è¿ç§»ä¸é‡æ”¾ï¼Œåœ¨æå‡æ–°ä»»åŠ¡æ€§èƒ½çš„åŒæ—¶æœ‰æ•ˆç¼“è§£ç¾éš¾æ€§é—å¿˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: TAMEç»´æŠ¤ä¸€ä¸ªé¢„è®­ç»ƒä¸“å®¶æ± ï¼Œæ ¹æ®ä»»åŠ¡ç›¸ä¼¼æ€§æ¿€æ´»æœ€ç›¸å…³ä¸“å®¶ï¼Œå¹¶ç»“åˆå…±äº«ç¨ å¯†å±‚è¿›è¡Œé¢„æµ‹ï¼›é€šè¿‡å­˜å‚¨å†å²ä»»åŠ¡æ ·æœ¬ä¸åµŒå…¥çš„é‡æ”¾ç¼“å†²åŒºï¼Œå¹¶åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶ä¼˜å…ˆé‡ç”¨æœ€ç›¸å…³çš„å†å²ä¿¡æ¯æ¥ä¿ç•™çŸ¥è¯†ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç»ˆèº«æ·±åº¦å­¦ä¹ ï¼ˆLDLï¼‰æ—¨åœ¨è®­ç»ƒç¥ç»ç½‘ç»œåœ¨ä»»åŠ¡åºåˆ—ä¸­æŒç»­å­¦ä¹ ï¼ŒåŒæ—¶ä¿ç•™å·²æœ‰çŸ¥è¯†ã€‚æœ¬æ–‡æå‡ºä»»åŠ¡æ„ŸçŸ¥å¤šä¸“å®¶æ¨¡å‹ï¼ˆTAMEï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ä»»åŠ¡ç›¸ä¼¼æ€§æŒ‡å¯¼ä¸“å®¶é€‰æ‹©ä¸çŸ¥è¯†è¿ç§»çš„æŒç»­å­¦ä¹ ç®—æ³•ã€‚TAMEç»´æŠ¤ä¸€ä¸ªé¢„è®­ç»ƒç¥ç»ç½‘ç»œæ± ï¼Œé’ˆå¯¹æ¯ä¸ªæ–°ä»»åŠ¡æ¿€æ´»æœ€ç›¸å…³çš„ä¸“å®¶æ¨¡å‹ï¼Œå¹¶é€šè¿‡å…±äº«å¯†é›†å±‚æ•´åˆæ‰€é€‰ä¸“å®¶çš„ç‰¹å¾ä»¥ç”Ÿæˆé¢„æµ‹ã€‚ä¸ºç¼“è§£ç¾éš¾æ€§é—å¿˜ï¼ŒTAMEé‡‡ç”¨å›æ”¾ç¼“å†²åŒºå­˜å‚¨å†å²ä»»åŠ¡çš„ä»£è¡¨æ€§æ ·æœ¬ä¸åµŒå…¥å‘é‡ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¤ç”¨è¿™äº›ä¿¡æ¯ã€‚æ³¨â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11243v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11243.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FuncGenFoilï¼šåŸºäºå‡½æ•°ç©ºé—´çš„ç¿¼å‹ç”Ÿæˆä¸ç¼–è¾‘æ¨¡å‹</strong></p>
<p><em>FuncGenFoil: Airfoil Generation and Editing Model in Function Space</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 / ICLR 2025 / NeurIPS 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åœ¨å‡½æ•°ç©ºé—´ä¸­ç›´æ¥ç”Ÿæˆå’Œç¼–è¾‘ç¿¼å‹å‡ ä½•çš„ç”Ÿæˆæ¨¡å‹FuncGenFoilï¼Œå®ƒç»“åˆäº†å‚æ•°åŒ–è¡¨ç¤ºçš„ä»»æ„åˆ†è¾¨ç‡é‡‡æ ·ä¼˜åŠ¿ä¸ç¦»æ•£ç‚¹è¡¨ç¤ºçš„å¼ºè¡¨è¾¾èƒ½åŠ›ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨è¡¨è¾¾åŠ›ä¸åˆ†è¾¨ç‡é€‚åº”æ€§ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ç›´æ¥åœ¨å‡½æ•°ç©ºé—´ä¸­é‡æ„ç¿¼å‹å‡ ä½•æ›²çº¿ï¼Œè€Œéä¾èµ–é¢„å®šä¹‰çš„å‚æ•°åŒ–è¡¨ç¤ºæˆ–ç¦»æ•£ç‚¹é›†ï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸã€å¯æ§ä¸”å¯ç¼–è¾‘çš„ç¿¼å‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: é£æœºåˆ¶é€ æ˜¯å·¥ä¸šçš‡å† ä¸Šçš„æ˜ç ï¼Œå…¶ä¸­ç”Ÿæˆå…·æœ‰å¯æ§å¯ç¼–è¾‘è¡¨å¾çš„é«˜ä¿çœŸç¿¼å‹å‡ ä½•å½¢çŠ¶ä»æ˜¯ä¸€é¡¹åŸºç¡€æ€§æŒ‘æˆ˜ã€‚ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•é€šå¸¸ä¾èµ–é¢„å®šä¹‰çš„å‚æ•°åŒ–è¡¨å¾ï¼ˆå¦‚è´å¡å°”æ›²çº¿ï¼‰æˆ–ç¦»æ•£ç‚¹é›†ï¼Œåœ¨è¡¨è¾¾èƒ½åŠ›ä¸åˆ†è¾¨ç‡é€‚åº”æ€§ä¹‹é—´å­˜åœ¨å›ºæœ‰çŸ›ç›¾ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºFuncGenFoilâ€”â€”ä¸€ç§åˆ›æ–°çš„å‡½æ•°ç©ºé—´ç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿç›´æ¥å°†ç¿¼å‹å‡ ä½•é‡æ„ä¸ºå‡½æ•°æ›²çº¿ã€‚è¯¥æ–¹æ³•ç»§æ‰¿äº†å‚æ•°åŒ–å‡½æ•°ä»»æ„åˆ†è¾¨ç‡é‡‡æ ·ä¸å¹³æ»‘æ€§çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶å…¼å…·åŸºäºç¦»æ•£ç‚¹è¡¨å¾çš„å¼ºå¤§è¡¨â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.10712v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.10712.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ BugSweeperï¼šåŸºäºå›¾ç¥ç»ç½‘ç»œçš„æ™ºèƒ½åˆçº¦å‡½æ•°çº§æ¼æ´æ£€æµ‹</strong></p>
<p><em>BugSweeper: Function-Level Detection of Smart Contract Vulnerabilities Using Graph Neural Networks</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>æ ¹æ®å…¶èšç„¦äºè½¯ä»¶å®‰å…¨ã€æ™ºèƒ½åˆçº¦å¹¶é‡‡ç”¨å‰æ²¿å›¾ç¥ç»ç½‘ç»œæŠ€æœ¯çš„ç‰¹ç‚¹ï¼Œå¯èƒ½å‘è¡¨äºç½‘ç»œå®‰å…¨æˆ–è½¯ä»¶å·¥ç¨‹é¢†åŸŸçš„é¡¶çº§ä¼šè®®ï¼Œå¦‚ **USENIX Security**ã€**IEEE S&amp;P** æˆ– **ISSTA**ï¼Œä¹Ÿå¯èƒ½å…ˆä»¥ **arXiv preprint** å½¢å¼å‘å¸ƒã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åä¸ºBugSweeperçš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°æ˜¯è®¾è®¡äº†å‡½æ•°çº§æŠ½è±¡è¯­æ³•å›¾ï¼ˆFLAGï¼‰ï¼Œè¯¥å›¾èåˆäº†æŠ½è±¡è¯­æ³•æ ‘å¹¶ä¸°å¯Œäº†æ§åˆ¶æµå’Œæ•°æ®æµè¯­ä¹‰ï¼Œä»è€Œæ— éœ€ä¾èµ–ä¸“å®¶è®¾è®¡çš„è§„åˆ™è¿›è¡Œé¢„å¤„ç†å³å¯ç›´æ¥ä»æºä»£ç æ£€æµ‹æ™ºèƒ½åˆçº¦æ¼æ´ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•é¦–å…ˆå°†Solidityå‡½æ•°è¡¨ç¤ºä¸ºFLAGå›¾ï¼Œç„¶åé‡‡ç”¨ä¸¤é˜¶æ®µå›¾ç¥ç»ç½‘ç»œè¿›è¡Œåˆ†æï¼šç¬¬ä¸€é˜¶æ®µGNNè¿‡æ»¤è¯­æ³•å›¾ä¸­çš„å™ªå£°ï¼Œç¬¬äºŒé˜¶æ®µGNNè¿›è¡Œé«˜çº§è¡¨ç¤ºå­¦ä¹ ä»¥å®Œæˆæ¼æ´æ£€æµ‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ä»¥å¤ªåŠçš„å¿«é€Ÿå‘å±•ä½¿å¾—å¿«é€Ÿå‡†ç¡®åœ°æ£€æµ‹æ™ºèƒ½åˆçº¦æ¼æ´å˜å¾—æ„ˆå‘é‡è¦ã€‚è™½ç„¶åŸºäºæœºå™¨å­¦ä¹ çš„æ–¹æ³•å·²å±•ç°å‡ºä¸€å®šæ½œåŠ›ï¼Œä½†è®¸å¤šæ–¹æ³•ä»ä¾èµ–é¢†åŸŸä¸“å®¶è®¾è®¡çš„åŸºäºè§„åˆ™çš„é¢„å¤„ç†ã€‚åŸºäºè§„åˆ™çš„é¢„å¤„ç†æ–¹æ³•å¾€å¾€ä¼šä¸¢å¼ƒæºä»£ç ä¸­çš„å…³é”®ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯èƒ½å¯¼è‡´æŸäº›æ¼æ´è¢«å¿½è§†ï¼Œå¹¶é™åˆ¶äº†å¯¹æ–°å‡ºç°å¨èƒçš„é€‚åº”èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºBugSweeperâ€”â€”ä¸€ç§ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå¯ç›´æ¥ä»æºä»£ç æ£€æµ‹æ¼æ´è€Œæ— éœ€äººå·¥å·¥ç¨‹å¹²é¢„ã€‚BugSweeperå°†æ¯ä¸ªSoliditâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09385v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09385.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ è¶…è¶Šç«¯ç‚¹ï¼šé¢å‘çŸ¢é‡è¶Šé‡ç½‘ç»œæå–çš„è·¯å¾„ä¸­å¿ƒæ¨ç†</strong></p>
<p><em>Beyond Endpoints: Path-Centric Reasoning for Vectorized Off-Road Network Extraction</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ECCV 2024</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†é¦–ä¸ªé¢å‘è¶Šé‡è·¯ç½‘æå–çš„å…¨å±€æ•°æ®é›†WildRoadï¼Œå¹¶è®¾è®¡äº†ä¸€ç§ä»¥è·¯å¾„ä¸ºä¸­å¿ƒè€Œéä»¥èŠ‚ç‚¹ä¸ºä¸­å¿ƒçš„æ¨ç†æ¡†æ¶MaGRoadï¼Œä»¥è§£å†³ç°æœ‰æ–¹æ³•åœ¨å¤æ‚è¶Šé‡åœºæ™¯ä¸­æ‹“æ‰‘ç»“æ„æ˜“é”™çš„é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: MaGRoadæ¡†æ¶çš„æ ¸å¿ƒæ˜¯è·¯å¾„ä¸­å¿ƒåŒ–æ¨ç†ï¼Œå®ƒé€šè¿‡èšåˆå€™é€‰è·¯å¾„ä¸Šçš„å¤šå°ºåº¦è§†è§‰è¯æ®æ¥é²æ£’åœ°æ¨æ–­é“è·¯è¿é€šæ€§ï¼Œä»è€Œå…‹æœäº†ä¼ ç»ŸèŠ‚ç‚¹ä¸­å¿ƒåŒ–æ–¹æ³•åœ¨é®æŒ¡å’Œæ¨¡ç³Šè·¯å£å¤„çš„è„†å¼±æ€§ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ·±åº¦å­¦ä¹ åœ¨åŸå¸‚ç¯å¢ƒä¸­çš„çŸ¢é‡åŒ–é“è·¯æå–æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†è¶Šé‡ç¯å¢ƒçš„ç ”ç©¶ä»æ˜¾ä¸è¶³ä¸”å……æ»¡æŒ‘æˆ˜ã€‚æ˜¾è‘—çš„é¢†åŸŸå·®è·å¯¼è‡´å…ˆè¿›æ¨¡å‹åœ¨é‡å¤–åœ°å½¢ä¸­å¤±æ•ˆï¼Œè¿™ä¸»è¦æºäºä¸¤ä¸ªå…³é”®é—®é¢˜ï¼šç¼ºä¹å¤§è§„æ¨¡çŸ¢é‡åŒ–æ•°æ®é›†ä»¥åŠä¸»æµæ–¹æ³•å­˜åœ¨ç»“æ„ç¼ºé™·ã€‚è¯¸å¦‚SAM-Roadç­‰æ¨¡å‹é‡‡ç”¨ä»¥èŠ‚ç‚¹ä¸ºä¸­å¿ƒçš„èŒƒå¼ï¼Œåœ¨ç¨€ç–ç«¯ç‚¹è¿›è¡Œæ¨ç†ï¼Œä½¿å…¶åœ¨è¶Šé‡åœºæ™¯ä¸­æ˜“å—é®æŒ¡å’Œæ¨¡ç³Šè·¯å£çš„å½±å“ï¼Œå¯¼è‡´æ‹“æ‰‘é”™è¯¯ã€‚æœ¬ç ”ç©¶é€šè¿‡ä¸¤ç§äº’è¡¥æ–¹å¼è§£å†³è¿™äº›å±€é™æ€§ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å‘å¸ƒäº†WildRoadâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10416v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10416.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ç£èŠ¯æŸè€—çš„è°±ç†µå…ˆéªŒå¼•å¯¼æ·±åº¦ç‰¹å¾èåˆæ¶æ„</strong></p>
<p><em>Spectral entropy prior-guided deep feature fusion architecture for magnetic core loss</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE Transactions on Power Electronics æˆ– IEEE Journal of Emerging and Selected Topics in Power Electronicsã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§èåˆç‰©ç†å…ˆéªŒä¸æ·±åº¦å­¦ä¹ çš„æ··åˆæ¨¡å‹ï¼ˆSEPI-TFPNetï¼‰ï¼Œé€šè¿‡è°±ç†µåˆ¤åˆ«æœºåˆ¶åŠ¨æ€é€‰æ‹©æœ€ä¼˜ç»éªŒæ¨¡å‹ï¼Œä»¥æå‡ç£èŠ¯æŸè€—é¢„æµ‹çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ¨¡å‹åŒ…å«ç‰©ç†å…ˆéªŒå­æ¨¡å—ï¼ˆåŸºäºè°±ç†µé€‰æ‹©ç»éªŒæ¨¡å‹ï¼‰å’Œæ•°æ®é©±åŠ¨å­æ¨¡å—ï¼ˆç»“åˆCNNä¸Transformeræå–ç‰¹å¾ï¼‰ï¼Œé€šè¿‡ç‰¹å¾èåˆå®ç°é«˜ç²¾åº¦é¢„æµ‹ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç²¾ç¡®çš„ç£èŠ¯æŸè€—å»ºæ¨¡å¯¹äºè®¾è®¡é«˜æ•ˆç‡ç”µåŠ›ç”µå­ç³»ç»Ÿè‡³å…³é‡è¦ã€‚ä¼ ç»Ÿç£èŠ¯æŸè€—å»ºæ¨¡æ–¹æ³•åœ¨é¢„æµ‹ç²¾åº¦ä¸Šå­˜åœ¨å±€é™ã€‚ä¸ºæ¨åŠ¨è¯¥é¢†åŸŸå‘å±•ï¼ŒIEEEç”µåŠ›ç”µå­å­¦ä¼šäº2023å¹´å‘èµ·é¦–å±Šèšç„¦æ•°æ®é©±åŠ¨ç”µåŠ›ç”µå­è®¾è®¡æ–¹æ³•çš„å›½é™…ç«èµ›â€”â€”MagNetæŒ‘æˆ˜èµ›ï¼Œæ—¨åœ¨é€šè¿‡æ•°æ®é©±åŠ¨èŒƒå¼æ­ç¤ºç£æ€§å…ƒä»¶çš„å¤æ‚æŸè€—è§„å¾‹ã€‚è™½ç„¶çº¯æ•°æ®é©±åŠ¨æ¨¡å‹å±•ç°å‡ºè¾ƒå¼ºçš„æ‹Ÿåˆæ€§èƒ½ï¼Œä½†å…¶å¯è§£é‡Šæ€§ä¸è·¨åˆ†å¸ƒæ³›åŒ–èƒ½åŠ›ä»å­˜åœ¨ä¸è¶³ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºèåˆç»éªŒæ¨¡å‹ä¸æ·±åº¦å­¦ä¹ çš„æ··åˆæ¨¡å‹Sâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11334v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11334.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ M2NOï¼šé¢å‘åŠ¨æ€å¤šå°ºåº¦åå¾®åˆ†æ–¹ç¨‹æ±‚è§£å™¨çš„é«˜æ•ˆå¤šåˆ†è¾¨ç‡ç®—å­æ¡†æ¶</strong></p>
<p><em>M2NO: An Efficient Multi-Resolution Operator Framework for Dynamic Multi-Scale PDE Solvers</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>ICLR 2025 æˆ– NeurIPS 2025ï¼ˆåŸºäºå…¶æ·±åº¦å­¦ä¹ ä¸PDEæ±‚è§£ç»“åˆçš„åˆ›æ–°æ€§åŠå®éªŒå¹¿åº¦ï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§ç»“åˆå¤šç½‘æ ¼ç»“æ„ä¸å¤šå°æ³¢ç©ºé—´çš„å¤šåˆ†è¾¨ç‡ç®—å­æ¡†æ¶ï¼ˆM2NOï¼‰ï¼Œé€šè¿‡é€‰æ‹©æ€§ä¼ é€’ä½é¢‘è¯¯å·®åˆ†é‡è‡³ç²—ç½‘æ ¼å¹¶ä¿ç•™ç»†ç½‘æ ¼é«˜é¢‘ç»†èŠ‚ï¼Œåœ¨æå‡ç²¾åº¦ä¸è®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œå¯ä½œä¸ºè¿­ä»£æ±‚è§£å™¨çš„æœ‰æ•ˆé¢„å¤„ç†å™¨ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: M2NOæ¡†æ¶åŸºäºå¤šåˆ†è¾¨ç‡åˆ†æï¼Œåˆ©ç”¨é¢„å®šä¹‰çš„å¤šå°æ³¢ç©ºé—´åœ¨å¤šå±‚ç½‘æ ¼ä¸Šå¤„ç†å¤šå°ºåº¦ç‰¹å¾ï¼Œå®ç°åŠ¨æ€PDEæ±‚è§£ä¸­è¯¯å·®æˆåˆ†çš„é«˜æ•ˆåˆ†è§£ä¸ä¼ é€’ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: é«˜æ•ˆæ±‚è§£é«˜ç»´åå¾®åˆ†æ–¹ç¨‹éœ€è¦å¤„ç†ä¸åŒåˆ†è¾¨ç‡ä¸‹çš„å¤šå°ºåº¦ç‰¹å¾ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºåŸºäºå¤šå°æ³¢çš„å¤šé‡ç½‘æ ¼ç¥ç»ç®—å­ï¼ˆM2NOï¼‰â€”â€”ä¸€ç§å°†å¤šé‡ç½‘æ ¼ç»“æ„ä¸é¢„å®šä¹‰å¤šå°æ³¢ç©ºé—´ç›¸èåˆçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚M2NOåˆ©ç”¨å¤šåˆ†è¾¨ç‡åˆ†æï¼Œé€‰æ‹©æ€§åœ°å°†ä½é¢‘è¯¯å·®åˆ†é‡ä¼ é€’è‡³ç²—ç½‘æ ¼ï¼ŒåŒæ—¶åœ¨ç»†ç½‘æ ¼å±‚çº§ä¿ç•™é«˜é¢‘ç»†èŠ‚ã€‚è¯¥è®¾è®¡åœ¨ä¸å¼•å…¥é¢å¤–å¤æ‚åº¦çš„å‰æä¸‹ï¼ŒåŒæ­¥æå‡äº†è®¡ç®—ç²¾åº¦ä¸æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒM2NOå¯ä½œä¸ºè¿­ä»£æ±‚è§£å™¨çš„æœ‰æ•ˆé¢„å¤„ç†å™¨ï¼Œè¿›ä¸€æ­¥åŠ é€Ÿå¤§è§„æ¨¡åå¾®â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.04822v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.04822.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ å·´åŠ ç“¦ç«‹æ–¹å¯å‘çš„ç»“æ„åŒ–ç¥ç»åµŒå…¥äºŒæ¬¡æ­£åˆ™åŒ–</strong></p>
<p><em>Bhargava Cubeâ€“Inspired Quadratic Regularization for Structured Neural Embeddings</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>ICLR 2025 æˆ– NeurIPS 2025ã€‚è¯¥å·¥ä½œå°†æ·±åº¦å­¦ä¹ æ–¹æ³•ä¸ç†è®ºæ•°å­¦ç»“æ„ï¼ˆæ•°è®ºï¼‰ç›¸ç»“åˆï¼Œå¼ºè°ƒè¡¨ç¤ºçš„å¯è§£é‡Šæ€§ä¸æ•°å­¦ä¸€è‡´æ€§ï¼Œè¿™ç¬¦åˆICLRå’ŒNeurIPSè¿‘å¹´æ¥å¯¹æœºå™¨å­¦ä¹ ç†è®ºåŸºç¡€ä¸å¯è§£é‡Šæ€§ç ”ç©¶çš„é‡è§†ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§å—æ•°è®ºä¸­Bhargavaç«‹æ–¹ä½“å¯å‘çš„ç¥ç»è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„äºŒæ¬¡å…³ç³»ä½œä¸ºä»£æ•°çº¦æŸæ¥æ­£åˆ™åŒ–ä¸‰ç»´æ½œåœ¨ç©ºé—´ï¼Œä»è€Œè·å¾—å…¼å…·é«˜ç²¾åº¦å’Œæ•°å­¦ç»“æ„å¯è§£é‡Šæ€§çš„åµŒå…¥è¡¨ç¤ºã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è®¾è®¡äº†ä¸€ä¸ªç‹¬ç«‹äºåˆ†ç±»ç›®æ ‡çš„ã€å¯å¾®åˆ†çš„è¾…åŠ©æŸå¤±å‡½æ•°ï¼Œå°†è¾“å…¥æ•°æ®æ˜ å°„åˆ°å—çº¦æŸçš„ä¸‰ç»´æ½œåœ¨ç©ºé—´ï¼Œå¹¶å¼ºåˆ¶åµŒå…¥æ»¡è¶³ä»Bhargavaç»„åˆç»“æ„æ¨å¯¼å‡ºçš„äºŒæ¬¡å…³ç³»ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¥ç»è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èå…¥äº†å—æ•°è®ºä¸­Bhargavaç«‹æ–¹ä½“å¯å‘çš„ä»£æ•°çº¦æŸã€‚ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨ç¼ºä¹å¯è§£é‡Šæ€§å’Œæ•°å­¦ä¸€è‡´æ€§çš„éç»“æ„åŒ–æ½œåœ¨ç©ºé—´ä¸­å­¦ä¹ è¡¨ç¤ºã€‚æˆ‘ä»¬çš„æ¡†æ¶å°†è¾“å…¥æ•°æ®æ˜ å°„åˆ°å—çº¦æŸçš„ä¸‰ç»´æ½œåœ¨ç©ºé—´ï¼Œå…¶ä¸­åµŒå…¥å‘é‡é€šè¿‡æ­£åˆ™åŒ–å¤„ç†ï¼Œä»¥æ»¡è¶³ä»Bhargavaç»„åˆç»“æ„æ¨å¯¼å‡ºçš„äºŒæ¬¡å…³ç³»ã€‚è¯¥æ¶æ„é‡‡ç”¨ç‹¬ç«‹äºåˆ†ç±»ç›®æ ‡çš„å¯å¾®åˆ†è¾…åŠ©æŸå¤±å‡½æ•°ï¼Œå¼•å¯¼æ¨¡å‹å½¢æˆå…·æœ‰æ•°å­¦ç»“æ„çš„è¡¨ç¤ºã€‚æˆ‘ä»¬åœ¨MNISTæ•°æ®é›†ä¸Šè¿›è¡Œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11392v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11392.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FT-MoEï¼šé¢å‘å®¹é”™è®¡ç®—çš„å¯æŒç»­å­¦ä¹ ä¸“å®¶æ··åˆæ¨¡å‹</strong></p>
<p><em>FT-MoE: Sustainable-learning Mixture of Experts for Fault-Tolerant Computing</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE Transactions on Parallel and Distributed Systems (TPDS) æˆ– IEEE International Conference on Distributed Computing Systems (ICDCS)ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§åŸºäºæ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¶æ„çš„å¯æŒç»­å­¦ä¹ å®¹é”™è®¡ç®—æ¡†æ¶FT-MoEï¼Œé€šè¿‡åŒè·¯å¾„æ¶æ„å’Œä¸¤é˜¶æ®µå­¦ä¹ æ–¹æ¡ˆï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•å› æ•…éšœçŸ¥è¯†å¼‚è´¨æ€§å’Œæ•°æ®é™åˆ¶å¯¼è‡´çš„æ£€æµ‹è´¨é‡ä¸è®­ç»ƒæ•ˆç‡é—®é¢˜ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ ¸å¿ƒæ˜¯é‡‡ç”¨æ··åˆä¸“å®¶æ¶æ„ï¼Œä½¿ä¸åŒå‚æ•°å­¦ä¹ ä¸åŒçš„æ•…éšœçŸ¥è¯†ï¼›å¹¶è®¾è®¡äº†ä¸¤é˜¶æ®µå­¦ä¹ æ–¹æ¡ˆï¼Œç»“åˆå…¨é¢çš„ç¦»çº¿è®­ç»ƒä¸æŒç»­çš„åœ¨çº¿è°ƒä¼˜ï¼Œä»¥å®ç°é«˜ç²¾åº¦çš„æ•…éšœæ£€æµ‹ä¸åˆ†ç±»ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ™ºèƒ½å®¹é”™è®¡ç®—è¿‘æœŸåœ¨ä¸»åŠ¨é¢„æµ‹ä¸è¯Šæ–­æ•…éšœã€ç¡®ä¿æœåŠ¡å¯é äº¤ä»˜æ–¹é¢å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œç”±äºæ•…éšœçŸ¥è¯†çš„å¼‚æ„æ€§ã€åŠ¨æ€å·¥ä½œè´Ÿè½½åŠæœ‰é™æ•°æ®æ”¯æŒï¼Œç°æœ‰åŸºäºæ·±åº¦å­¦ä¹ çš„å®¹é”™ç®—æ³•åœ¨æ•…éšœæ£€æµ‹è´¨é‡ä¸è®­ç»ƒæ•ˆç‡æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚è¿™ä¸»è¦æºäºå…¶å¯¹æ•…éšœçŸ¥è¯†æ„ŸçŸ¥çš„åŒè´¨åŒ–å¤„ç†éš¾ä»¥å……åˆ†æ•æ‰å¤šæ ·å¤æ‚çš„æ•…éšœæ¨¡å¼ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºFT-MoEâ€”â€”ä¸€ç§åŸºäºåŒè·¯å¾„æ¶æ„çš„å¯æŒç»­å­¦ä¹ å®¹é”™è®¡ç®—æ¡†æ¶ï¼Œå¯å®ç°é«˜ç²¾åº¦æ•…éšœæ£€æµ‹ä¸åˆ†ç±»ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ä¸“å®¶æ··åˆæ¶æ„ï¼Œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.20446v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.20446.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ æ”»é˜²å…¼å¤‡ï¼šç¨³å¥æ¨¡å‹å¦‚ä½•èœ•å˜ä¸ºæ›´å¼ºå¤§çš„æ”»å‡»è€…</strong></p>
<p><em>Defense That Attacks: How Robust Models Become Better Attackers</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>CVPR 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ­ç¤ºäº†å¯¹æŠ—è®­ç»ƒçš„ä¸€ä¸ªæ½œåœ¨å‰¯ä½œç”¨ï¼šç»è¿‡å¯¹æŠ—è®­ç»ƒçš„é²æ£’æ¨¡å‹ï¼Œå…¶ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬åè€Œå…·æœ‰æ›´å¼ºçš„å¯è¿ç§»æ€§ï¼Œè¿™æ„æˆäº†æ–°çš„å®‰å…¨é£é™©ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: ç ”ç©¶é€šè¿‡è®­ç»ƒä¸€ä¸ªåŒ…å«36ä¸ªä¸åŒæ¶æ„ï¼ˆå¦‚CNNå’ŒViTï¼‰çš„æ¨¡å‹åº“ï¼Œå¹¶è®¾è®¡å…¨é¢çš„å¯è¿ç§»æ€§å®éªŒï¼Œå®è¯åˆ†æäº†å¯¹æŠ—è®­ç»ƒå¯¹æ”»å‡»å¯è¿ç§»æ€§çš„å½±å“ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†å…¶å¯¹æŠ—æ”»å‡»çš„è„†å¼±æ€§ä¾ç„¶å­˜åœ¨ã€‚å¯¹æŠ—è®­ç»ƒä½œä¸ºæå‡æ¨¡å‹é²æ£’æ€§çš„ä¸»æµé˜²å¾¡æ–¹æ³•ï¼Œå…¶å¯¹äºæ”»å‡»å¯è¿ç§»æ€§çš„å½±å“å°šæœªå¾—åˆ°å……åˆ†æ¢ç©¶ã€‚æœ¬ç ”ç©¶æ—¨åœ¨æ¢è®¨å¯¹æŠ—è®­ç»ƒæ˜¯å¦ä¼šæ— æ„ä¸­å¢å¼ºå¯¹æŠ—æ ·æœ¬çš„å¯è¿ç§»æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®­ç»ƒäº†åŒ…å«CNNå’ŒViTåœ¨å†…çš„36ä¸ªå¤šæ ·åŒ–æ¨¡å‹ï¼Œå¹¶è¿›è¡Œäº†å…¨é¢çš„å¯è¿ç§»æ€§å®éªŒã€‚ç ”ç©¶ç»“æœæ­ç¤ºäº†ä¸€ä¸ªæ˜æ˜¾çš„æ‚–è®ºï¼šç»è¿‡å¯¹æŠ—è®­ç»ƒçš„æ¨¡å‹æ‰€äº§ç”Ÿçš„æ‰°åŠ¨ï¼Œæ¯”æ ‡å‡†æ¨¡å‹ç”Ÿæˆçš„æ‰°åŠ¨å…·æœ‰æ›´å¼ºçš„å¯è¿ç§»æ€§ï¼Œâ€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.02830v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.02830.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ æ·±åº¦å­¦ä¹ ç»Ÿè®¡ç‰©ç†å­¦ï¼šæ’å€¼é™„è¿‘å¤šå±‚æ„ŸçŸ¥å™¨çš„æœ€ä¼˜å­¦ä¹ </strong></p>
<p><em>Statistical physics of deep learning: Optimal learning of a multi-layer perceptron near interpolation</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>NeurIPS 2025 æˆ– ICLR 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æœ¬æ–‡é¦–æ¬¡å°†ç»Ÿè®¡ç‰©ç†æ¡†æ¶æˆåŠŸåº”ç”¨äºåˆ†æå…·æœ‰ç‰¹å¾å­¦ä¹ èƒ½åŠ›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰ï¼Œçªç ´äº†ä»¥å¾€ä»…èƒ½åˆ†æçª„ç½‘ç»œæˆ–æ ¸æ–¹æ³•çš„å±€é™ï¼Œå¹¶èšç„¦äºå‚æ•°ä¸æ•°æ®é‡ç›¸å½“çš„æŒ‘æˆ˜æ€§æ’å€¼åŒºåŸŸï¼Œæ­ç¤ºäº†å­¦ä¹ éšæœºæ·±åº¦ç¥ç»ç½‘ç»œç›®æ ‡çš„åŸºæœ¬æé™ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: ç ”ç©¶é‡‡ç”¨å¸ˆç”ŸåŒ¹é…è®¾ç½®ï¼Œåˆ†æè¾“å…¥ç»´åº¦å°ºåº¦å®½åº¦çš„å¤šå±‚æ„ŸçŸ¥æœºåœ¨ç›‘ç£å­¦ä¹ ä¸­çš„è¡Œä¸ºï¼Œé€šè¿‡ç»Ÿè®¡ç‰©ç†æ–¹æ³•æ¨å¯¼å‡ºæœ€ä¼˜è®­ç»ƒä¸‹æ¨¡å‹å­¦ä¹ åˆ°çš„å……åˆ†ç»Ÿè®¡é‡ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: å››åå¹´æ¥ï¼Œç»Ÿè®¡ç‰©ç†å­¦ä¸€ç›´ä¸ºåˆ†æç¥ç»ç½‘ç»œæä¾›ç†è®ºæ¡†æ¶ã€‚ç„¶è€Œï¼Œå…¶èƒ½å¦å¤„ç†å…·æœ‰ä¸°å¯Œç‰¹å¾å­¦ä¹ æ•ˆåº”çš„æ·±åº¦å­¦ä¹ æ¨¡å‹â€”â€”å³è¶…è¶Šç›®å‰æ‰€ç ”ç©¶çš„çª„ç½‘ç»œæˆ–æ ¸æ–¹æ³•â€”â€”è¿™ä¸€é•¿æœŸé—®é¢˜å§‹ç»ˆæ‚¬è€Œæœªå†³ã€‚æˆ‘ä»¬é€šè¿‡å¯¹å¤šå±‚æ„ŸçŸ¥å™¨ç›‘ç£å­¦ä¹ çš„ç ”ç©¶ç»™å‡ºäº†è‚¯å®šç­”æ¡ˆã€‚å…³é”®ä¹‹å¤„åœ¨äºï¼š(i) å…¶å®½åº¦ä¸è¾“å…¥ç»´åº¦åŒé˜¶ç¼©æ”¾ï¼Œè¿™ä½¿å¾—å®ƒæ¯”è¶…å®½ç½‘ç»œæ›´æ˜“äºè¿›è¡Œç‰¹å¾å­¦ä¹ ï¼ŒåŒæ—¶æ¯”çª„ç½‘ç»œæˆ–å…·æœ‰å›ºå®šåµŒå…¥å±‚çš„ç½‘ç»œæ›´å…·è¡¨è¾¾èƒ½åŠ›ï¼›(ii) æˆ‘ä»¬èšç„¦äºå…·æœ‰æŒ‘æˆ˜æ€§çš„æ’å€¼åŒºåŸŸï¼Œå…¶ä¸­å¯â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.24616v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.24616.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºLiDARé«˜åˆ†è¾¨ç‡å‚è€ƒæ•°æ®çš„Sentinel-2æ—¶åºå½±åƒè¶…åˆ†è¾¨ç‡å† å±‚é«˜åº¦åˆ¶å›¾â€”â€”ä»¥æ³•å›½å¤§éƒ½å¸‚åŒºä¸ºä¾‹</strong></p>
<p><em>Super-Resolved Canopy Height Mapping from Sentinel-2 Time Series Using LiDAR HD Reference Data across Metropolitan France</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>é¥æ„Ÿæˆ–åœ°çƒç§‘å­¦é¢†åŸŸçš„é¡¶çº§æœŸåˆŠï¼Œå¦‚ *Remote Sensing of Environment* æˆ– *ISPRS Journal of Photogrammetry and Remote Sensing*ï¼›ä¹Ÿå¯èƒ½å‘è¡¨äºæœºå™¨å­¦ä¹ åº”ç”¨ä¼šè®®å¦‚NeurIPSçš„Tackling Climate Change with MLç ”è®¨ä¼šæˆ–IGARSSã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºTHREASURE-Netï¼Œä¸€ç§ä»…åˆ©ç”¨Sentinel-2æ—¶åºæ•°æ®å’ŒLiDARé«˜åº¦å‚è€ƒï¼ˆæ— éœ€é¢„è®­ç»ƒæ¨¡å‹æˆ–è¶…é«˜åˆ†è¾¨ç‡å…‰å­¦å½±åƒï¼‰è¿›è¡Œæ ‘é«˜å›å½’ä¸è¶…åˆ†è¾¨çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œå®ç°äº†å¤šåˆ†è¾¨ç‡ï¼ˆ2.5ç±³è‡³10ç±³ï¼‰çš„å¹´åº¦æ ‘é«˜åˆ¶å›¾ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: åŸºäºæ·±åº¦å­¦ä¹ çš„æ¡†æ¶ï¼Œé€šè¿‡æ•´åˆSentinel-2æ—¶é—´åºåˆ—çš„å…‰è°±ã€æ—¶ç©ºä¿¡å·ï¼Œç›´æ¥ä»¥LiDAR HDæ•°æ®ç”Ÿæˆçš„é«˜åº¦æŒ‡æ ‡ä¸ºç›‘ç£ï¼Œå­¦ä¹ ä»ä½åˆ†è¾¨ç‡è¾“å…¥åˆ°é«˜åˆ†è¾¨ç‡æ ‘é«˜å›¾çš„æ˜ å°„ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: ç²¾ç»†å°ºåº¦çš„æ£®æ—ç›‘æµ‹å¯¹äºç†è§£å† å±‚ç»“æ„åŠå…¶åŠ¨æ€è‡³å…³é‡è¦ï¼Œè¿™äº›æ˜¯ç¢³å‚¨é‡ã€ç”Ÿç‰©å¤šæ ·æ€§å’Œæ£®æ—å¥åº·çš„å…³é”®æŒ‡æ ‡ã€‚æ·±åº¦å­¦ä¹ åœ¨æ­¤ä»»åŠ¡ä¸­å°¤ä¸ºæœ‰æ•ˆï¼Œå› å…¶èƒ½æ•´åˆå…±åŒåæ˜ å† å±‚ç»“æ„çš„å…‰è°±ã€æ—¶é—´ä¸ç©ºé—´ä¿¡å·ã€‚ä¸ºæ»¡è¶³è¿™ä¸€éœ€æ±‚ï¼Œæˆ‘ä»¬æå‡ºTHREASURE-Netâ€”â€”ä¸€ç§ç”¨äºæ ‘é«˜å›å½’ä¸è¶…åˆ†è¾¨ç‡é‡å»ºçš„æ–°å‹ç«¯åˆ°ç«¯æ¡†æ¶ã€‚è¯¥æ¨¡å‹åŸºäºæ³•å›½å¤§éƒ½å¸‚åŒºå¤šç©ºé—´åˆ†è¾¨ç‡çš„æ¿€å…‰é›·è¾¾é«˜æ¸…æ•°æ®æå–å‚è€ƒé«˜åº¦æŒ‡æ ‡ï¼Œåˆ©ç”¨å“¨å…µäºŒå·æ—¶é—´åºåˆ—è¿›è¡Œè®­ç»ƒï¼Œä»¥ç”Ÿæˆå¹´åº¦æ ‘é«˜åˆ†å¸ƒå›¾ã€‚â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11524v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11524.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ NeuralOGCMï¼šåŸºäºå¯å­¦ä¹ ç‰©ç†çš„å¯å¾®åˆ†æµ·æ´‹å»ºæ¨¡</strong></p>
<p><em>NeuralOGCM: Differentiable Ocean Modeling with Learnable Physics</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>ICLR 2025 æˆ– NeurIPS 2025</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§èåˆå¯å¾®åˆ†ç¼–ç¨‹ä¸æ·±åº¦å­¦ä¹ çš„æµ·æ´‹å»ºæ¨¡æ¡†æ¶ï¼Œé€šè¿‡å°†å…³é”®ç‰©ç†å‚æ•°è½¬åŒ–ä¸ºå¯å­¦ä¹ å‚æ•°ï¼Œå¹¶å¼•å…¥ç¥ç»ç½‘ç»œæ ¡æ­£æ¬¡ç½‘æ ¼è¿‡ç¨‹ï¼Œå®ç°äº†ç‰©ç†æ¨¡å‹æ ¸å¿ƒçš„ç«¯åˆ°ç«¯è‡ªä¸»ä¼˜åŒ–ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ¡†æ¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªå®Œå…¨å¯å¾®åˆ†çš„åŠ¨åŠ›å­¦æ±‚è§£å™¨ï¼Œå®ƒç»“åˆäº†ç¡®å®šæ€§ç‰©ç†æ¼”åŒ–å’Œä¸€ä¸ªç”¨äºæ ¡æ­£è¯¯å·®çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œä¸¤è€…é€šè¿‡ç»Ÿä¸€çš„ODEæ±‚è§£å™¨ååŒå·¥ä½œã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: é«˜ç²¾åº¦ç§‘å­¦æ¨¡æ‹Ÿé•¿æœŸé¢ä¸´è®¡ç®—æ•ˆç‡ä¸ç‰©ç†ä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡éš¾é¢˜ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºNeuralOGCMâ€”â€”ä¸€ä¸ªèåˆå¯å¾®åˆ†ç¼–ç¨‹ä¸æ·±åº¦å­¦ä¹ çš„æµ·æ´‹å»ºæ¨¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯å…·å¤‡å®Œå…¨å¯å¾®åˆ†ç‰¹æ€§çš„åŠ¨åŠ›å­¦æ±‚è§£å™¨ï¼Œå…¶ä»¥ç‰©ç†çŸ¥è¯†ä½œä¸ºæ ¸å¿ƒå½’çº³åç½®ã€‚å¯å­¦ä¹ çš„ç‰©ç†ç§¯åˆ†æ¨¡å—æ•æ‰å¤§å°ºåº¦ç¡®å®šæ€§ç‰©ç†æ¼”åŒ–è¿‡ç¨‹ï¼Œå¹¶å°†å…³é”®ç‰©ç†å‚æ•°ï¼ˆå¦‚æ‰©æ•£ç³»æ•°ï¼‰è½¬åŒ–ä¸ºå¯å­¦ä¹ å‚æ•°ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒè‡ªä¸»ä¼˜åŒ–å…¶ç‰©ç†æ ¸å¿ƒã€‚åŒæ—¶ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œå­¦ä¹ ä¿®æ­£ç‰©ç†â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11525v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11525.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºï¼ˆå¾®åˆ†ï¼‰æœºå™¨å­¦ä¹ çš„å‚æ•°åŒ–æ•°å€¼ç§¯åˆ†</strong></p>
<p><em>Parametric Numerical Integration with (Differential) Machine Learning</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>arXiv preprint æˆ– æœºå™¨å­¦ä¹ /è®¡ç®—æ•°å­¦äº¤å‰é¢†åŸŸçš„é¡¶çº§ä¼šè®®ï¼ˆå¦‚ NeurIPS, ICMLï¼‰æˆ–æœŸåˆŠï¼ˆå¦‚ Journal of Computational Physics, SIAM Journal on Scientific Computingï¼‰ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºä¸€ç§ç»“åˆå¯¼æ•°ä¿¡æ¯çš„å¾®åˆ†æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºæ±‚è§£å‚æ•°åŒ–ç§¯åˆ†é—®é¢˜ï¼Œç›¸æ¯”ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•åœ¨ç²¾åº¦ã€å¯æ‰©å±•æ€§å’Œæ ·æœ¬æ•ˆç‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è¯¥æ–¹æ³•å°†å¾®åˆ†å­¦ä¹ æ€æƒ³èå…¥è®­ç»ƒè¿‡ç¨‹ï¼Œåˆ©ç”¨å¯¼æ•°ä¿¡æ¯å¢å¼ºæ¨¡å‹å¯¹å‚æ•°åŒ–ç§¯åˆ†é—®é¢˜çš„æ‹Ÿåˆèƒ½åŠ›ï¼Œå¹¶åœ¨ç»Ÿè®¡æ³›å‡½ã€åˆ‡æ¯”é›ªå¤«å±•å¼€å’Œå¾®åˆ†æ–¹ç¨‹ç§¯åˆ†ä¸‰ç±»ä»£è¡¨æ€§é—®é¢˜ä¸ŠéªŒè¯äº†å…¶ä¼˜è¶Šæ€§ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæœºå™¨&#x2F;æ·±åº¦å­¦ä¹ çš„æ–¹æ³•æ¥è§£å†³å‚æ•°ç§¯åˆ†é—®é¢˜ã€‚é™¤ç»å…¸æœºå™¨å­¦ä¹ æ–¹æ³•å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¾®åˆ†å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èå…¥å¯¼æ•°ä¿¡æ¯ï¼Œå¹¶é‡ç‚¹é˜è¿°äº†å…¶ä¼˜åŠ¿ç‰¹æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ¶µç›–ä¸‰ç±»å…¸å‹é—®é¢˜ï¼šç»Ÿè®¡æ³›å‡½ï¼ˆåŒ…æ‹¬çŸ©é‡ä¸ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼‰ã€åŸºäºåˆ‡æ¯”é›ªå¤«å±•å¼€å¼çš„å‡½æ•°é€¼è¿‘ï¼Œä»¥åŠå¾®åˆ†æ–¹ç¨‹ç›´æ¥å¯¼å‡ºçš„ç§¯åˆ†é—®é¢˜ã€‚è¿™äº›ç®—ä¾‹æ¶µç›–ä»å…‰æ»‘é—­å¼åŸºå‡†æµ‹è¯•åˆ°å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å€¼ç§¯åˆ†ç­‰å¤šç§æƒ…å½¢ã€‚åœ¨æ‰€æœ‰æ¡ˆä¾‹ä¸­ï¼ŒåŸºäºå¾®åˆ†æœºå™¨å­¦ä¹ çš„æ–¹æ³•å‡æŒç»­ä¼˜â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11530v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11530.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºTransformeræ¨¡å‹çš„è‡ªåŠ¨ä½œæ–‡è¯„åˆ†ä»»åŠ¡ä¸­ä¸Šä¸‹æ–‡å½±å“çš„å®è¯åˆ†æ</strong></p>
<p><em>Empirical Analysis of the Effect of Context in the Task of Automated Essay Scoring in Transformer-Based Models</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>æ ¹æ®å…¶ç ”ç©¶é¢†åŸŸï¼ˆæ•™è‚²æŠ€æœ¯ã€è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ï¼‰å’Œå®è¯åˆ†ææ€§è´¨ï¼Œè¯¥è®ºæ–‡å¯èƒ½å‘è¡¨äº**ACL**ã€**EMNLP**ã€**AAAI**æˆ–**arXiv preprint**ã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æœ¬æ–‡çš„ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºï¼Œé’ˆå¯¹å½“å‰åŸºäºTransformerçš„è‡ªåŠ¨ä½œæ–‡è¯„åˆ†æ¨¡å‹æ€§èƒ½ä¸åŠå…¶ä»–æ·±åº¦å­¦ä¹ æ¶æ„çš„ç°è±¡ï¼Œæå‡ºå¹¶ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†é€šè¿‡èå…¥å¤šç§ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å¢å¼ºæ­¤ç±»æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: è®ºæ–‡ä½¿ç”¨ASAP-AESæ•°æ®é›†ï¼Œé€šè¿‡å‘åŸºäºTransformerçš„æ¨¡å‹ï¼ˆå¦‚BERTï¼‰ä¸­æ³¨å…¥å¤šç§ç»´åº¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚æç¤ºä¿¡æ¯ã€è¯„åˆ†æ ‡å‡†ç­‰ï¼‰ï¼Œæ„å»ºäº†ä¸€ä¸ªå¢å¼ºçš„AESæ¨¡å‹ï¼Œå¹¶åˆ†æäº†ä¸åŒä¸Šä¸‹æ–‡å› ç´ çš„å½±å“ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: éšç€æ•™è‚²è‡ªåŠ¨åŒ–éœ€æ±‚çš„æ—¥ç›Šå¢é•¿ï¼Œè‡ªåŠ¨ä½œæ–‡è¯„åˆ†ç³»ç»Ÿåº”è¿è€Œç”Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡æä¾›å®¢è§‚ä¸”ç»æµé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå®ç°äº†å¯¹æ‰©å±•æ€§å›ç­”çš„æ ‡å‡†åŒ–è¯„ä¼°ã€‚å°½ç®¡è¯¥é¢†åŸŸå·²æœ‰å¤§é‡ç ”ç©¶ï¼Œä½†è¿‘æœŸè°ƒæŸ¥æ˜¾ç¤ºï¼Œæ›¿ä»£æ€§çš„æ·±åº¦å­¦ä¹ æ¶æ„åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†åŸºäºTransformerçš„æ¨¡å‹ã€‚å°½ç®¡Transformeræ¶æ„åœ¨å…¶ä»–å¤šç§ä»»åŠ¡ä¸­å·²æˆåŠŸå æ®ä¸»å¯¼åœ°ä½ï¼Œä½†è¿™ç§æ€§èƒ½å·®å¼‚ä¿ƒä½¿æˆ‘ä»¬éœ€è¦é€šè¿‡è¯­å¢ƒå¢å¼ºæ¥ä¼˜åŒ–åŸºäºTransformerçš„è‡ªåŠ¨ä½œæ–‡è¯„åˆ†æ¨¡å‹ã€‚æœ¬ç ”ç©¶åˆ©â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.16638v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.16638.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ åŸºäºæ¢…å°”é¢‘è°±å›¾çš„æ°´ä¸‹å£°å­¦ç›®æ ‡è¯†åˆ«å›¾åµŒå…¥æ–¹æ³•</strong></p>
<p><em>Graph Embedding with Mel-spectrograms for Underwater Acoustic Target Recognition</em></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code> | ğŸ“ å‡ºå¤„: <code>IEEE Transactions on Geoscience and Remote Sensing æˆ– ICASSPã€‚</code></p>
<p>ğŸ’¡ <strong>åˆ›æ–°ç‚¹</strong>: æå‡ºäº†ä¸€ç§éæ¬§å‡ é‡Œå¾—æ·±åº¦å­¦ä¹ æ¨¡å‹UATR-GTransformerï¼Œå°†Transformeræ¶æ„ä¸å›¾ç¥ç»ç½‘ç»œç»“åˆï¼Œä»¥å¤„ç†æ°´ä¸‹å£°å­¦ä¿¡å·å›ºæœ‰çš„å¤æ‚æ‹“æ‰‘å’Œéå¹³ç¨³ã€éçº¿æ€§ç‰¹æ€§ï¼Œçªç ´äº†ç°æœ‰æ–¹æ³•åŸºäºæ¬§æ°ç©ºé—´çš„å‡è®¾ã€‚</p>
<p>ğŸ”§ <strong>æ–¹æ³•æ¡†æ¶</strong>: æ¨¡å‹åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šæ¢…å°”è°±å›¾åˆ†å—æ¨¡å—å°†æ¢…å°”é¢‘è°±å›¾åˆ†å‰²ä¸ºé‡å å—ï¼›GTransformeræ¨¡å—åˆ©ç”¨Transformerç¼–ç å™¨æ•æ‰åˆ†å—é—´çš„äº’ä¿¡æ¯ï¼Œå¹¶ç»“åˆå›¾ç¥ç»ç½‘ç»œå¤„ç†éæ¬§ç»“æ„ï¼›åˆ†ç±»å¤´ç”¨äºæœ€ç»ˆç›®æ ‡è¯†åˆ«ã€‚</p>
<p>ğŸ“ <strong>æ‘˜è¦</strong>: æ°´ä¸‹å£°å­¦ç›®æ ‡è¯†åˆ«ï¼ˆUATRï¼‰å› èˆ°èˆ¹è¾å°„å™ªå£°çš„å¤æ‚æ€§å’Œæµ·æ´‹ç¯å¢ƒçš„å¤šå˜æ€§è€Œæå…·æŒ‘æˆ˜æ€§ã€‚å°½ç®¡æ·±åº¦å­¦ä¹ æ–¹æ³•å·²å–å¾—æ˜¾è‘—æˆæœï¼Œä½†ç°æœ‰æ¨¡å‹å¤§å¤šéšå«å‡è®¾æ°´ä¸‹å£°å­¦æ•°æ®å¤„äºæ¬§å‡ é‡Œå¾—ç©ºé—´ã€‚ç„¶è€Œï¼Œè¿™ç§å‡è®¾å¹¶ä¸é€‚ç”¨äºæ°´ä¸‹å£°å­¦ä¿¡å·å›ºæœ‰çš„å¤æ‚æ‹“æ‰‘ç»“æ„ï¼Œè¿™äº›ä¿¡å·è¡¨ç°å‡ºéå¹³ç¨³ã€éé«˜æ–¯å’Œéçº¿æ€§çš„ç‰¹å¾ã€‚ä¸ºçªç ´è¿™ä¸€å±€é™ï¼Œæœ¬æ–‡æå‡ºUATR-GTransformerâ€”â€”ä¸€ç§èåˆTransformeræ¶æ„ä¸å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰çš„éæ¬§å‡ é‡Œå¾—æ·±åº¦â€¦</p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11545v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11545.pdf">PDF</a></p>
</div>

<hr>
<h3 id="ğŸ“…-2025-12-11"><a href="#ğŸ“…-2025-12-11" class="headerlink" title="ğŸ“… 2025-12-11"></a>ğŸ“… 2025-12-11</h3><div class="paper-card">

<p><strong>ğŸ“„ Changes in Real Time: Online Scene Change Detection with Multi-View Fusion</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.12370v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.12370.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09335v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09335.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10369v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10369.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.07752v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.07752.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MADrive: Memory-Augmented Driving Scene Modeling</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.21520v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.21520.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Seamless Outdoor-Indoor Pedestrian Positioning System with GNSS&#x2F;UWB&#x2F;IMU Fusion: A Comparison of EKF, FGO, and PF</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10480v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10480.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ K-Track: Kalman-Enhanced Tracking for Accelerating Deep Point Trackers on Edge Devices</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10628v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10628.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Spiking Neural Network Implementation of Gaussian Belief Propagation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10638v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10638.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Latent Chain-of-Thought World Modeling for End-to-End Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10226v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10226.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GuideFlow: Constraint-Guided Flow Matching for Planning in End-to-End Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18729v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18729.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10305v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10305.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.19195v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.19195.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.03454v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.03454.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Adaptive Dual-Weighted Gravitational Point Cloud Denoising Method</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10386v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10386.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Thinking Ahead: Foresight Intelligence in MLLMs and World Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18735v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18735.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ T-SKM-Net: Trainable Neural Network Framework for Linear Constraint Satisfaction via Sampling Kaczmarz-Motzkin Method</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10461v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10461.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Orbis: Overcoming Challenges of Long-Horizon Prediction in Driving World Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.13162v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.13162.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10492v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10492.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ NaviHydra: Controllable Navigation-guided End-to-end Autonomous Driving with Hydra-distillation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10660v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10660.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Leveraging Depth and Language for Open-Vocabulary Domain-Generalized Semantic Segmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.09881v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.09881.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Panoramic Out-of-Distribution Segmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.03539v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.03539.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10719v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10719.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.06112v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.06112.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Mr. Virgil: Learning Multi-robot Visual-range Relative Localization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Graph Optimization</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10540v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10540.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Development and Testing for Perception Based Autonomous Landing of a Long-Range QuadPlane</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Visual Inertial Odometry</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09343v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09343.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Object-centric proto-symbolic behavioural reasoning from pixels</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.17438v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.17438.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Evaluating Gemini Robotics Policies in a Veo World Simulator</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10675v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10675.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Generalized Spherical Neural Operators: Greenâ€™s Function Formulation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10723v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10723.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10958v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10958.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ VDAWorld: World Modelling via VLM-Directed Abstraction and Simulation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11061v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11061.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.16203v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.16203.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10394v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10394.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Accessible Physical AI: LoRA-Based Fine-Tuning of VLA Models for Real-World Robot Control</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11921v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11921.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision and Language Navigation</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10322v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10322.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CLASH: Collaborative Large-Small Hierarchical Framework for Continuous Vision-and-Language Navigation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision and Language Navigation</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10360v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10360.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Offscript: Automated Auditing of Instruction Adherence in LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10172v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10172.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MiniF2F-Dafny: LLM-Guided Mathematical Theorem Proving via Auto-Active Verification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10187v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10187.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Emotional Support with LLM-based Empathetic Dialogue Generation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.12820v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.12820.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ It Hears, It Sees too: Multi-Modal LLM for Depression Detection By Integrating Visual Understanding into Audio Language Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.19877v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.19877.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Attention is All You Need to Defend Against Indirect Prompt Injection Attacks in LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08417v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08417.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.18428v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.18428.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.17508v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.17508.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HarnessAgent: Scaling Automatic Fuzzing Harness Construction with Tool-Augmented LLM Pipelines</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.03420v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.03420.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Simple Yet Strong Baseline for Long-Term Conversational Memory of LLM Agents</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.17208v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.17208.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ When Less Language is More: Language-Reasoning Disentanglement Makes LLMs Better Multilingual Reasoners</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.15257v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.15257.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ EchoingPixels: Cross-Modal Adaptive Token Reduction for Efficient Audio-Visual LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10324v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10324.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ JITServe: SLO-aware LLM Serving with Imprecise Request Information</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.20068v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.20068.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Aligning ASR Evaluation with Human and LLM Judgments: Intelligibility Metrics Using Phonetic, Semantic, and NLI Approaches</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.16528v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.16528.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-Empowered Representation Learning for Emerging Item Recommendation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10370v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10370.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ How to Trick Your AI TA: A Systematic Study of Academic Jailbreaking in LLM Code Evaluation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10415v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10415.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10453v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10453.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case Study with In-Context Representation Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.17552v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.17552.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Lab to Reality: A Practical Evaluation of Deep Learning Models and LLMs for Vulnerability Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10485v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10485.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-Assisted AHP for Explainable Cyber Range Evaluation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10487v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10487.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10545v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10545.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-Auction: Generative Auction towards LLM-Native Advertising</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10551v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10551.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Thinking While Driving: A Concurrent Framework for Real-Time, LLM-Based Adaptive Routing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10610v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10610.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.08139v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.08139.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ On the Dynamics of Multi-Agent LLM Communities Driven by Value Diversity</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10665v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10665.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Challenges of Evaluating LLM Safety for User Welfare</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10687v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10687.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The LLM Wears Prada: Analysing Gender Bias and Stereotypes through Online Shopping Data</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.01951v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.01951.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10780v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10780.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10793v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10793.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLMs Can Assist with Proposal Selection at Large User Facilities</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10895v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10895.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10922v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10922.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.06982v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.06982.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Asynchronous Reasoning: Training-Free Interactive Thinking LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10931v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10931.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.15447v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.15447.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Beyond Early-Token Bias: Model-Specific and Language-Specific Position Effects in Multilingual LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.16134v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.16134.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Understanding LLM Agent Behaviours via Game Theory: Strategy Recognition, Biases and Multi-Agent Dynamics</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.07462v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.07462.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Breaking the Frozen Subspace: Importance Sampling for Low-Rank Optimization in LLM Pretraining</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.05790v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.05790.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.04573v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.04573.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Automated Penetration Testing with LLM Agents and Classical Planning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11143v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11143.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Causal Judge Evaluation: Calibrated Surrogate Metrics for LLM Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11150v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11150.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Mirror Speculative Decoding: Breaking the Serial Barrier in LLM Inference</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.13161v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.13161.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CIEGAD: Cluster-Conditioned Interpolative and Extrapolative Framework for Geometry-Aware and Domain-Aligned Data Augmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10178v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10178.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ An Efficient Graph-Transformer Operator for Learning Physical Dynamics with Manifolds Embedding</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10227v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10227.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Deferred Poisoning: Making the Model More Vulnerable via Hessian Singularization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.03752v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.03752.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10271v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10271.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FLARE: A Wireless Side-Channel Fingerprinting Attack on Federated Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10296v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10296.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ High-Dimensional Data Processing: Benchmarking Machine Learning and Deep Learning Architectures in Local and Distributed Environments</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10312v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10312.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Conditional Generative Framework for Synthetic Data Augmentation in Segmenting Thin and Elongated Structures in Biological Images</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10334v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10334.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Self-Supervised Contrastive Embedding Adaptation for Endoscopic Image Matching</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10379v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10379.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ The Operator Origins of Neural Scaling Laws: A Generalized Spectral Transport Dynamics of Deep Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10427v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10427.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Representation of the structure of graphs by sequences of instructions</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10429v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10429.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Metacognitive Sensitivity for Test-Time Dynamic Model Selection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10451v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10451.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Hierarchical Deep Learning for Diatom Image Classification: A Multi-Level Taxonomic Approach</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.06613v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.06613.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Robust Shape from Focus via Multiscale Directional Dilated Laplacian and Recurrent Network</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10498v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10498.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Visual Re-Identification of Fish using Fine-Grained Classification for Electronic Monitoring in Fisheries</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08400v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08400.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Robust Assessment of Pathological Voices via Combined Low-Level Descriptors and Foundation Model Representations</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.21356v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.21356.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Uncertainty-Preserving QBNNs: Multi-Level Quantization of SVI-Based Bayesian Neural Networks for Image Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10602v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10602.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Robust Multi-Disease Retinal Classification via Xception-Based Transfer Learning and W-Net Vessel Segmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10608v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10608.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Unsupervised Learning for Industrial Defect Detection: A Case Study on Shearographic Data</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.02541v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.02541.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10671v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10671.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Optimal transport unlocks end-to-end learning for single-molecule localization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10683v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10683.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PMB-NN: Physiology-Centred Hybrid AI for Personalized Hemodynamic Monitoring from Photoplethysmography</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10745v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10745.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Stronger Normalization-Free Transformers</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10938v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10938.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MultiScript30k: Leveraging Multilingual Embeddings to Extend Cross Script Parallel Data</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11074v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11074.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HEIST: A Graph Foundation Model for Spatial Transcriptomics and Proteomics Data</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.11152v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.11152.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Fast, accurate measurement of the worker populations of honey bee colonies using deep learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11075v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11075.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Estimating Object Physical Properties from RGB-D Vision and Depth Robot Sensors Using Deep Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.05029v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.05029.pdf">PDF</a></p>
</div>

<hr>
<h3 id="ğŸ“…-2025-12-10"><a href="#ğŸ“…-2025-12-10" class="headerlink" title="ğŸ“… 2025-12-10"></a>ğŸ“… 2025-12-10</h3><div class="paper-card">

<p><strong>ğŸ“„ MoRel: Long-Range Flicker-Free 4D Motion Modeling via Anchor Relay-based Bidirectional Blending with Hierarchical Densification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09270v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09270.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D Generation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.02316v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.02316.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ YOPO-Nav: Visual Navigation using 3DGS Graphs from One-Pass Videos</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09903v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09903.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Splatent: Splatting Diffusion Latents for Novel View Synthesis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09923v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09923.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.06438v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.06438.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.05991v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.05991.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SmokeSeer: 3D Gaussian Splatting for Smoke Removal and Scene Reconstruction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>3D Gaussian Splatting</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.17329v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.17329.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Efficient Transformed Gaussian Process State-Space Models for Non-Stationary High-Dimensional Dynamical Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.18309v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.18309.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Observability Analysis and Composite Disturbance Filtering for a Bar Tethered to Dual UAVs Subject to Multi-source Disturbances</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09377v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09377.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Neural posterior inference with state-space models for calibrating ice sheet simulators</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Kalman Filter</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09561v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09561.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Understanding World or Predicting Future? A Comprehensive Survey of World Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.14499v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.14499.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HeLoFusion: An Efficient and Scalable Encoder for Modeling Heterogeneous and Multi-Scale Interactions in Trajectory Prediction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.11719v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.11719.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Traffic Scene Small Target Detection Method Based on YOLOv8n-SPTS Model for Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09296v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09296.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ COVLM-RL: Critical Object-Oriented Reasoning for Autonomous Driving Using VLM-Guided Reinforcement Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09349v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09349.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WeatherDiffusion: Controllable Weather Editing in Intrinsic Space</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.06982v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.06982.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ BridgeDrive: Diffusion Bridge Policy for Closed-Loop Trajectory Planning in Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.23589v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.23589.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Autonomous Driving</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09864v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09864.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ D$^2$GSLAM: 4D Dynamic Gaussian Splatting SLAM</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Dynamic SLAM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09411v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09411.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Sequential Testing for Descriptor-Agnostic LiDAR Loop Closure in Repetitive Environments</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Graph Optimization</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09447v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09447.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ PlayerOne: Egocentric World Simulator</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.09995v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.09995.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Matrix-game 2.0: An open-source real-time and streaming interactive world model</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.13009v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.13009.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Closing the Train-Test Gap in World Models for Gradient-Based Planning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09929v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09929.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Latent Action World Models for Control with Unlabeled Trajectories</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>World Model</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10016v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10016.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Mind to Hand: Purposeful Robotic Control via Embodied Reasoning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08580v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08580.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ GLaD: Geometric Latent Distillation for Vision-Language-Action Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09619v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09619.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09927v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09927.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09928v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09928.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Vision Language Action</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11908v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11908.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.13381v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.13381.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.00417v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.00417.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09872v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09872.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Text-Trained LLMs Can Zero-Shot Extrapolate PDE Dynamics, Revealing a Three-Stage In-Context Learning Mechanism</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.06322v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.06322.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ AI-powered Code Review with LLMs: Early Results</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.18496v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.18496.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Exploring LLMs for Scientific Information Extraction Using The SciEx Framework</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10004v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10004.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Intelligently Weighting Multiple Reference Models for Direct Preference Optimization of LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10040v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10040.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10043v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10043.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10080v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10080.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Reparameterized LLM Training via Orthogonal Equivalence Transformation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.08001v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.08001.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM-PEA: Leveraging Large Language Models Against Phishing Email Attacks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10104v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10104.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Mitigating Forgetting in LLM Fine-Tuning via Low-Perplexity Token Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.14315v7">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.14315.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Efficient Real-Time Video Motion Transfer via Generative Time Series Modeling</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.05537v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.05537.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Beyond Algorithm Evolution: An LLM-Driven Framework for the Co-Evolution of Swarm Intelligence Optimization Algorithms and Prompts</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09209v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09209.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Targeting Misalignment: A Conflict-Aware Framework for Reward-Model-based LLM Alignment</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09212v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09212.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Memory Injection Attacks on LLM Agents via Query-Only Interaction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.03704v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.03704.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LLM Meeting Decision Trees on Tabular Data</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.17918v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.17918.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Minimalist Optimizer Design for LLM Pretraining</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.16659v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.16659.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Guiding LLMs to Generate High-Fidelity and High-Quality Counterfactual Explanations for Text Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.04463v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.04463.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09369v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09369.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Forgetting-MarI: LLM Unlearning via Marginal Information Regularization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.11914v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.11914.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Black-Box Behavioral Distillation Breaks Safety Alignment in Medical LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09403v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09403.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CREME: Robustness Enhancement of Code LLMs via Layer-Aware Model Editing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.16407v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.16407.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in Multimodal LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.19366v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.19366.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ ODMA: On-Demand Memory Allocation Framework for LLM Serving on LPDDR-Class Accelerators</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09427v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09427.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WarmServe: Enabling One-for-Many GPU Prewarming for Multi-LLM Serving</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09472v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09472.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Source Coverage and Citation Bias in LLM-based vs. Traditional Search Engines</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09483v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09483.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Advancing LLM-Based Security Automation with Customized Group Relative Policy Optimization for Zero-Touch Networks</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09485v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09485.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Grammar-Based Code Representation: Is It a Worthy Pursuit for LLMs?</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.05507v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.05507.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Improving Topic Relevance Model by Mix-structured Summarization and LLM-based Data Augmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.02616v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.02616.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ LogICL: Distilling LLM Reasoning to Bridge the Semantic Gap in Cross-Domain Log Anomaly Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09627v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09627.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ An End-to-end Planning Framework with Agentic LLMs and PDDL</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09629v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09629.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Can LLMs Evaluate What They Cannot Annotate? Revisiting LLM Reliability in Hate Speech Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09662v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09662.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Weird Generalization and Inductive Backdoors: New Ways to Corrupt LLMs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09742v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09742.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Revealing economic facts: LLMs know more than they say</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.08662v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.08662.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>LLM</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09829v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09829.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Sinusoidal Initialization, Time for a New Start</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.12909v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.12909.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ HOLE: Homological Observation of Latent Embeddings for Neural Network Interpretability</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.07988v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.07988.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Who Speaks What from Afar: Eavesdropping In-Person Conversations via mmWave Sensing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09285v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09285.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MelanomaNet: Explainable Deep Learning for Skin Lesion Classification</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09289v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09289.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Hetero-SplitEE: Split Learning of Neural Networks with Early Exits for Heterogeneous IoT Devices</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09313v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09313.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Efficiency-Aware Computational Intelligence for Resource-Constrained Manufacturing Toward Edge-Ready Deployment</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09319v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09319.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DISTA-Net: Dynamic Closely-Spaced Infrared Small Target Unmixing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.19148v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.19148.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Rates and architectures for learning geometrically non-trivial operators</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09376v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09376.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Detection and Localization of Subdural Hematoma Using Deep Learning on Computed Tomography</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09393v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09393.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Resilient Transportation: A Conditional Transformer for Accident-Informed Traffic Forecasting</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09398v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09398.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Label-free Motion-Conditioned Diffusion Model for Cardiac Ultrasound Synthesis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09418v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09418.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Cytoplasmic Strings Analysis in Human Embryo Time-Lapse Videos using Deep Learning Framework</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09461v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09461.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ DeepMech: A Machine Learning Framework for Chemical Reaction Mechanism Prediction</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.15872v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.15872.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CupCleaner: A Hybrid Data Cleaning Approach for Comment Updating</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.06898v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2308.06898.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Gradient-Guided Learning Network for Infrared Small Target Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09497v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09497.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Towards Robust Infrared Small Target Detection: A Feature-Enhanced and Sensitivity-Tunable Framework</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.20090v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.20090.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.06485v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.06485.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ NeuroSketch: An Effective Framework for Neural Decoding via Systematic Architectural Optimization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09524v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09524.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Multi-Scale Direction-Aware Network for Infrared Small Target Detection</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.02037v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.02037.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ SensHRPS: Sensing Comfortable Human-Robot Proxemics and Personal Space With Eye-Tracking</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08518v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08518.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CS3D: An Efficient Facial Expression Recognition via Event Vision</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09592v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09592.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ A Network Science Approach to Granular Time Series Segmentation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.17640v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.17640.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Straggler Tolerant and Resilient DL Training on Homogeneous GPUs</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09685v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09685.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Physics-Aware Heterogeneous GNN Architecture for Real-Time BESS Optimization in Unbalanced Distribution Systems</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09780v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09780.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Predicting Polymer Solubility in Solvents Using SMILES Strings</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09784v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09784.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ CHEM: Estimating and Understanding Hallucinations in Deep Learning for Image Processing</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09806v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09806.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Semantic Data Augmentation Enhanced Invariant Risk Minimization for Medical Image Domain Generalization</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.05593v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.05593.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Symmetry in Neural Network Parameter Spaces</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.13018v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.13018.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Maple: A Multi-agent System for Portable Deep Learning across Clusters</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.08842v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.08842.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Proof of a perfect platonic representation hypothesis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.01098v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.01098.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10098v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10098.pdf">PDF</a></p>
</div>

<hr>
<div class="paper-card">

<p><strong>ğŸ“„ Sequence-to-Image Transformation for Sequence Classification Using Rips Complex Construction and Chaos Game Representation</strong></p>
<p>ğŸ·ï¸ åˆ†ç±»: <code>Deep Learning</code></p>
<p>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10141v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10141.pdf">PDF</a></p>
</div>

<hr>
</div>

<hr>
<h2 id="ğŸ“‚-è®ºæ–‡åˆ†ç±»"><a href="#ğŸ“‚-è®ºæ–‡åˆ†ç±»" class="headerlink" title="ğŸ“‚ è®ºæ–‡åˆ†ç±»"></a>ğŸ“‚ è®ºæ–‡åˆ†ç±»</h2><div class="category-nav">

<p><a href="#llm">LLM (377)</a> | <a href="#deep-learning">Deep Learning (336)</a> | <a href="#autonomous-driving">Autonomous Driving (145)</a> | <a href="#3d-gaussian-splatting">3D Gaussian Splatting (112)</a> | <a href="#world-model">World Model (110)</a> | <a href="#vision-language-action">Vision Language Action (104)</a> | <a href="#vision-and-language-navigation">Vision and Language Navigation (84)</a> | <a href="#visual-place-recognition">Visual Place Recognition (83)</a> | <a href="#visual-inertial-odometry">Visual Inertial Odometry (80)</a> | <a href="#lidar-odometry">LiDAR Odometry (77)</a> | <a href="#loop-closure-detection">Loop Closure Detection (75)</a> | <a href="#graph-optimization">Graph Optimization (68)</a> | <a href="#visual-slam">Visual SLAM (67)</a> | <a href="#semantic-slam">Semantic SLAM (66)</a> | <a href="#kalman-filter">Kalman Filter (65)</a> | <a href="#visual-inertial-slam">Visual Inertial SLAM (63)</a> | <a href="#lidar-slam">Lidar SLAM (60)</a> | <a href="#gnss">GNSS (51)</a> | <a href="#dynamic-slam">Dynamic SLAM (36)</a> | <a href="#gaussian-slam">Gaussian SLAM (20)</a></p>
</div>

<h3 id="LLM-50-ç¯‡"><a href="#LLM-50-ç¯‡" class="headerlink" title="LLM (50 ç¯‡)"></a><span id="llm">LLM</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>Towards Human-Guided, Data-Centric LLM Co-Pilots</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.10321v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.10321.pdf">PDF</a></li>
</ul>
<p><strong>A Causal Perspective on Measuring, Explaining and Mitigating Smells in LLM-Generated Code</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.15817v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.15817.pdf">PDF</a></li>
</ul>
<p><strong>LLM-based Behaviour Driven Development for Hardware Design</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17814v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17814.pdf">PDF</a></li>
</ul>
<p><strong>Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.20150v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.20150.pdf">PDF</a></li>
</ul>
<p><strong>LLM-as-a-qualitative-judge: automating error analysis in natural language generation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.09147v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.09147.pdf">PDF</a></li>
</ul>
<p><strong>Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.12817v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.12817.pdf">PDF</a></li>
</ul>
<p><strong>Designing an LLM-Based Behavioral Activation Chatbot for Young People with Depression: Insights from an Evaluation with Artificial Users and Clinical Experts</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.21540v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.21540.pdf">PDF</a></li>
</ul>
<p><strong>Linear Personality Probing and Steering in LLMs: A Big Five Study</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17639v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17639.pdf">PDF</a></li>
</ul>
<p><strong>Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17630v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17630.pdf">PDF</a></li>
</ul>
<p><strong>GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17570v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17570.pdf">PDF</a></li>
</ul>
<p><strong>SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17540v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17540.pdf">PDF</a></li>
</ul>
<p><strong>Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced Time Series Classification</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.18686v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.18686.pdf">PDF</a></li>
</ul>
<p><strong>RBCTest: Leveraging LLMs to Mine and Verify Oracles of API Response Bodies for RESTful API Testing</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.17287v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.17287.pdf">PDF</a></li>
</ul>
<p><strong>AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17375v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17375.pdf">PDF</a></li>
</ul>
<p><strong>From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.25123v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.25123.pdf">PDF</a></li>
</ul>
<p><strong>Bridging Natural Language and Formal Specificationâ€“Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17334v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17334.pdf">PDF</a></li>
</ul>
<p><strong>V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12284v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12284.pdf">PDF</a></li>
</ul>
<p><strong>Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.16882v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.16882.pdf">PDF</a></li>
</ul>
<p><strong>SportsGPT: An LLM-driven Framework for Interpretable Sports Motion Assessment and Training Guidance</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14121v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14121.pdf">PDF</a></li>
</ul>
<p><strong>Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16189v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16189.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Deep-Learning-50-ç¯‡"><a href="#Deep-Learning-50-ç¯‡" class="headerlink" title="Deep Learning (50 ç¯‡)"></a><span id="deep-learning">Deep Learning</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>å¼€æ”¾åŸºç¡€æ¨¡å‹ä¸­è§†è§‰çš„å¯¹æŠ—é²æ£’æ€§</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Adversarial Robustness of Vision in Open Foundation Models</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ arXiv preprint æˆ– CVPR&#x2F;ICLR&#x2F;NeurIPSç­‰é¡¶çº§ä¼šè®®çš„Workshopã€‚</li>
<li>ğŸ’¡ æœ¬æ–‡é¦–æ¬¡å¯¹LLaVA-1.5-13Bå’ŒMeta Llama 3.2 Vision-8B-2è¿™ä¸¤ç§å¼€æ”¾è§†è§‰åŸºç¡€æ¨¡å‹è¿›è¡Œäº†å¯¹æŠ—é²æ£’æ€§çš„å®è¯è¯„ä¼°ä¸æ¯”è¾ƒï¼Œæ­ç¤ºäº†åœ¨è§†è§‰é—®ç­”ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹åŸºçº¿å‡†ç¡®ç‡ä¸å¯¹æŠ—é²æ£’æ€§ä¹‹é—´å¯èƒ½å­˜åœ¨çš„æƒè¡¡å…³ç³»ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17902v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17902.pdf">PDF</a></li>
</ul>
<p><strong>ä½ç§©æ»¤æ³¢ä¸å¹³æ»‘åœ¨åºåˆ—æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Low-Rank Filtering and Smoothing for Sequential Deep Learning</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ ICLR 2025 æˆ– NeurIPS 2025</li>
<li>ğŸ’¡ æå‡ºä¸€ç§è´å¶æ–¯æ¡†æ¶ï¼Œå°†ç¥ç»ç½‘ç»œå‚æ•°è§†ä¸ºéçº¿æ€§é«˜æ–¯æ¨¡å‹çš„çŠ¶æ€ç©ºé—´ï¼Œå®ç°äº†å¯¹ä»»åŠ¡é—´å…³ç³»çš„å…ˆéªŒçŸ¥è¯†ç¼–ç ï¼Œå¹¶åˆ›æ–°æ€§åœ°åº”ç”¨è´å¶æ–¯å¹³æ»‘ä½¿æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨æœªæ¥ä»»åŠ¡çš„çŸ¥è¯†ï¼Œè€Œæ— éœ€è®¿é—®å…¶åŸå§‹æ•°æ®ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.06800v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.06800.pdf">PDF</a></li>
</ul>
<p><strong>è§å…‰ä¸»å¯¼æ¡ä»¶ä¸‹æ‹‰æ›¼å…‰è°±å»å™ªçš„ä»¿çœŸé©±åŠ¨æ·±åº¦å­¦ä¹ æ¡†æ¶</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Simulation-Driven Deep Learning Framework for Raman Spectral Denoising Under Fluorescence-Dominant Conditions</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ å¯èƒ½å‘è¡¨äºç”Ÿç‰©åŒ»å­¦å…‰å­¦æˆ–å…‰è°±åˆ†æé¢†åŸŸçš„é¡¶çº§æœŸåˆŠï¼Œå¦‚ <em>Analytical Chemistry</em>ã€<em>Biomedical Optics Express</em> æˆ– <em>Nature Communications</em> çš„å­åˆŠã€‚</li>
<li>ğŸ’¡ æå‡ºäº†ä¸€ç§ç»“åˆç»Ÿè®¡å™ªå£°æ¨¡å‹ä¸æ·±åº¦å­¦ä¹ çš„ä»¿çœŸé©±åŠ¨æ¡†æ¶ï¼Œç”¨äºåœ¨è§å…‰ä¸»å¯¼æ¡ä»¶ä¸‹å¯¹æ‹‰æ›¼å…‰è°±è¿›è¡Œå»å™ªï¼Œæœ‰æ•ˆè”åˆæŠ‘åˆ¶éšæœºæ¢æµ‹å™¨å™ªå£°å’Œè§å…‰åŸºçº¿å¹²æ‰°ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17852v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17852.pdf">PDF</a></li>
</ul>
<p><strong>UrbanDIFFï¼šå¯†é›†äº‘å±‚è¦†ç›–ä¸‹åŸå¸‚åœ°è¡¨æ¸©åº¦ç©ºé—´ç¼ºå¤±å¡«è¡¥çš„å»å™ªæ‰©æ•£æ¨¡å‹</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>UrbanDIFF: A Denoising Diffusion Model for Spatial Gap Filling of Urban Land Surface Temperature Under Dense Cloud Cover</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ IEEE Transactions on Geoscience and Remote Sensing (TGRS) æˆ– Remote Sensing of Environmentã€‚</li>
<li>ğŸ’¡ æå‡ºäº†ä¸€ç§åŸºäºå»å™ªæ‰©æ•£æ¨¡å‹çš„çº¯ç©ºé—´æ–¹æ³•UrbanDIFFï¼Œç”¨äºåœ¨å¯†é›†äº‘å±‚è¦†ç›–ä¸‹é‡å»ºåŸå¸‚åœ°è¡¨æ¸©åº¦ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤§é¢ç§¯è¿ç»­ç¼ºå¤±åŒºåŸŸæ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17782v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17782.pdf">PDF</a></li>
</ul>
<p><strong>UniStateDLOï¼šé¢å‘å—é™æ“ä½œçš„é®æŒ¡ç¯å¢ƒä¸‹å¯å˜å½¢çº¿æ€§ç‰©ä½“çš„ç»Ÿä¸€ç”Ÿæˆå¼çŠ¶æ€ä¼°è®¡ä¸è·Ÿè¸ª</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>UniStateDLO: Unified Generative State Estimation and Tracking of Deformable Linear Objects Under Occlusion for Constrained Manipulation</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– IROS 2025</li>
<li>ğŸ’¡ æå‡ºäº†é¦–ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„å®Œæ•´DLOæ„ŸçŸ¥æ¡†æ¶UniStateDLOï¼Œå°†å•å¸§çŠ¶æ€ä¼°è®¡ä¸è·¨å¸§çŠ¶æ€è·Ÿè¸ªç»Ÿä¸€å»ºæ¨¡ä¸ºæ¡ä»¶ç”Ÿæˆé—®é¢˜ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹åœ¨ä¸¥é‡é®æŒ¡ä¸‹å®ç°é²æ£’æ„ŸçŸ¥ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17764v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17764.pdf">PDF</a></li>
</ul>
<p><strong>åŸºäºå¯¹é½çºµå‘MRIä¸ä¸´åºŠæ•°æ®çš„ä¹³è…ºç™Œæ–°è¾…åŠ©åŒ–ç–—ç–—æ•ˆé¢„æµ‹</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Breast Cancer Neoadjuvant Chemotherapy Treatment Response Prediction Using Aligned Longitudinal MRI and Clinical Data</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ MICCAI 2025 æˆ– IEEE Transactions on Medical Imagingã€‚</li>
<li>ğŸ’¡ æå‡ºä¸€ä¸ªç»“åˆçºµå‘å¯¹é½MRIå½±åƒä¸ä¸´åºŠæ•°æ®çš„æ¡†æ¶ï¼Œç”¨äºé¢„æµ‹ä¹³è…ºç™Œæ–°è¾…åŠ©åŒ–ç–—çš„æ²»ç–—ååº”ï¼Œå¹¶åˆ›æ–°æ€§åœ°æ¯”è¾ƒäº†å¤šç§æ·±åº¦å­¦ä¹ ä¸å½±åƒç»„å­¦ç‰¹å¾æå–å™¨åœ¨çºµå‘å½±åƒåˆ†æä¸­çš„æ€§èƒ½ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17759v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17759.pdf">PDF</a></li>
</ul>
<p><strong>MambaMIL+ï¼šé¢å‘åƒå…†åƒç´ å…¨åˆ‡ç‰‡å›¾åƒçš„é•¿ç¨‹ä¸Šä¸‹æ–‡æ¨¡å¼å»ºæ¨¡</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>MambaMIL+: Modeling Long-Term Contextual Patterns for Gigapixel Whole Slide Image</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ MICCAI 2025 æˆ– Medical Image Analysis (MedIA) æœŸåˆŠã€‚</li>
<li>ğŸ’¡ æå‡ºMambaMIL+æ¡†æ¶ï¼Œé€šè¿‡é‡å æ‰«æå’Œç©ºé—´ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ‰«ææœºåˆ¶ï¼Œåœ¨ä¿æŒé•¿åºåˆ—å»ºæ¨¡æ•ˆç‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆæ•´åˆäº†WSIçš„ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯å¹¶ç¼“è§£äº†è®°å¿†è¡°å‡é—®é¢˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17726v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17726.pdf">PDF</a></li>
</ul>
<p><strong>ç©ºé—´æ„ŸçŸ¥å˜æ¢å™¨ï¼šå°†åœ°ç»Ÿè®¡åæ–¹å·®åç½®æ³¨å…¥è‡ªæ³¨æ„åŠ›æœºåˆ¶ä»¥æå‡æ—¶ç©ºé¢„æµ‹èƒ½åŠ›</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Spatially-informed transformers: Injecting geostatistical covariance biases into self-attention for spatio-temporal forecasting</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ NeurIPS 2025 æˆ– ICLR 2025ã€‚è¯¥è®ºæ–‡èšç„¦äºTransformeræ¶æ„çš„åŸºç¡€æ€§æ”¹è¿›ï¼Œå¹¶å°†å…¶åº”ç”¨äºæ—¶ç©ºé¢„æµ‹è¿™ä¸€æ ¸å¿ƒæœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œç†è®ºå’Œæ–¹æ³•åˆ›æ–°æ€§å¼ºï¼Œç¬¦åˆé¡¶çº§æœºå™¨å­¦ä¹ ä¼šè®®çš„å½•ç”¨æ ‡å‡†ã€‚</li>
<li>ğŸ’¡ æå‡ºäº†ä¸€ç§ç©ºé—´æ„ŸçŸ¥çš„Transformeræ¶æ„ï¼Œé€šè¿‡å°†å¯å­¦ä¹ çš„åœ°ç»Ÿè®¡åæ–¹å·®æ ¸ç›´æ¥æ³¨å…¥è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸ºåºåˆ—å»ºæ¨¡å¼•å…¥äº†ç©ºé—´å‡ ä½•å½’çº³åç½®ï¼Œä»è€Œå¼¥åˆäº†ç»å…¸åœ°ç»Ÿè®¡å­¦ä¸æ·±åº¦å­¦ä¹ åœ¨é«˜ç»´æ—¶ç©ºè¿‡ç¨‹å»ºæ¨¡ä¸­çš„é¸¿æ²Ÿã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17696v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17696.pdf">PDF</a></li>
</ul>
<p><strong>MolMarkï¼šé€šè¿‡å¯å­¦ä¹ åŸå­çº§æ°´å°ä¿æŠ¤åˆ†å­ç»“æ„</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>MolMark: Safeguarding Molecular Structures through Learnable Atom-Level Watermarking</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ NeurIPS 2025 æˆ– ICLR 2025</li>
<li>ğŸ’¡ æå‡ºäº†é¦–ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„åˆ†å­æ°´å°æ¡†æ¶MolMarkï¼Œèƒ½å¤Ÿåœ¨ä¿æŒåˆ†å­åŠŸèƒ½çš„å‰æä¸‹ï¼Œå°†é«˜ä¿çœŸæ•°å­—ç­¾ååµŒå…¥åˆ°åŸå­çº§åˆ«çš„åˆ†å­ç»“æ„ä¸­ï¼Œå¹¶ç¡®ä¿å…¶å‡ ä½•é²æ£’æ€§ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.17702v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.17702.pdf">PDF</a></li>
</ul>
<p><strong>MGRegBenchï¼šä¸€ç§å¸¦æœ‰è§£å‰–æ ‡å¿—çš„ä¹³è…ºXå…‰å›¾åƒé…å‡†æ–°å‹åŸºå‡†æ•°æ®é›†</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>MGRegBench: A Novel Benchmark Dataset with Anatomical Landmarks for Mammography Image Registration</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ MICCAI 2024 &#x2F; IEEE Transactions on Medical Imaging (TMI) &#x2F; Medical Image Analysis</li>
<li>ğŸ’¡ æå‡ºäº†é¦–ä¸ªå…¬å¼€çš„ä¹³è…ºXå…‰å›¾åƒé…å‡†åŸºå‡†æ•°æ®é›†MGRegBenchï¼ŒåŒ…å«è¶…è¿‡5000å¯¹å›¾åƒå’Œ100å¯¹å¸¦æœ‰äººå·¥æ ‡æ³¨è§£å‰–æ ‡å¿—ç‚¹åŠåˆ†å‰²æ©ç çš„å›¾åƒå¯¹ï¼Œæ—¨åœ¨è§£å†³è¯¥é¢†åŸŸç¼ºä¹å…¬å¼€æ•°æ®å’Œæ ‡å‡†åŒ–è¯„ä¼°çš„é—®é¢˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17605v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17605.pdf">PDF</a></li>
</ul>
<p><strong>Edge-Native Digitization of Handwritten Marksheets: A Hybrid Heuristic-Deep Learning Framework</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.16295v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.16295.pdf">PDF</a></li>
</ul>
<p><strong>MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17594v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17594.pdf">PDF</a></li>
</ul>
<p><strong>Sharing Knowledge without Sharing Data: Stitches can improve ensembles of disjointly trained models</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17592v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17592.pdf">PDF</a></li>
</ul>
<p><strong>On Using Neural Networks to Learn Safety Speed Reduction in Human-Robot Collaboration: A Comparative Analysis</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17579v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17579.pdf">PDF</a></li>
</ul>
<p><strong>Learning-Based Safety-Aware Task Scheduling for Efficient Human-Robot Collaboration</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17560v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17560.pdf">PDF</a></li>
</ul>
<p><strong>Towards Explainable Conversational AI for Early Diagnosis with Large Language Models</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17559v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17559.pdf">PDF</a></li>
</ul>
<p><strong>Deep Learning-based Robust Autonomous Navigation of Aerial Robots in Dense Forests</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17553v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17553.pdf">PDF</a></li>
</ul>
<p><strong>Towards Reproducibility in Predictive Process Mining: SPICE â€“ A Deep Learning Library</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16715v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16715.pdf">PDF</a></li>
</ul>
<p><strong>Resource-efficient medical image classification for edge devices</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17515v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17515.pdf">PDF</a></li>
</ul>
<p><strong>TwinSegNet: A Digital Twin-Enabled Federated Learning Framework for Brain Tumor Analysis</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17488v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17488.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Autonomous-Driving-50-ç¯‡"><a href="#Autonomous-Driving-50-ç¯‡" class="headerlink" title="Autonomous Driving (50 ç¯‡)"></a><span id="autonomous-driving">Autonomous Driving</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>OntoGSNï¼šåŸºäºæœ¬ä½“çš„ä¿éšœæ¡ˆä¾‹è¯­ä¹‰ç®¡ç†ä¸æ‰©å±•æ¡†æ¶</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>OntoGSN: An Ontology-Based Framework for Semantic Management and Extension of Assurance Cases</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ å¯èƒ½å‘è¡¨äºè½¯ä»¶å·¥ç¨‹æˆ–å½¢å¼åŒ–æ–¹æ³•é¢†åŸŸçš„é¡¶çº§ä¼šè®®&#x2F;æœŸåˆŠï¼Œå¦‚ICSEï¼ˆå›½é™…è½¯ä»¶å·¥ç¨‹å¤§ä¼šï¼‰ã€FSEï¼ˆè½¯ä»¶å·¥ç¨‹åŸºç¡€å¤§ä¼šï¼‰ã€IEEE Transactions on Software Engineeringæˆ–Journal of Systems and Softwareã€‚</li>
<li>ğŸ’¡ æå‡ºäº†ä¸€ç§åŸºäºæœ¬ä½“çš„æ¡†æ¶ï¼ˆOntoGSNï¼‰ï¼Œç”¨äºå¯¹é‡‡ç”¨ç›®æ ‡ç»“æ„ç¬¦å·ï¼ˆGSNï¼‰æ ‡å‡†çš„ä¿è¯æ¡ˆä¾‹è¿›è¡Œè¯­ä¹‰åŒ–ç®¡ç†å’ŒåŠ¨æ€æ‰©å±•ï¼Œæ—¨åœ¨è§£å†³ä¿è¯æ¡ˆä¾‹åœ¨å˜æ›´ç®¡ç†ä¸­çŸ¥è¯†ç»´æŠ¤å›°éš¾çš„é—®é¢˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.11023v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.11023.pdf">PDF</a></li>
</ul>
<p><strong>StereoMV2Dï¼šä¸€ç§ç”¨äºé²æ£’å¤šè§†è§’ä¸‰ç»´ç›®æ ‡æ£€æµ‹çš„ç¨€ç–æ—¶åºç«‹ä½“å¢å¼ºæ¡†æ¶</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>StereoMV2D: A Sparse Temporal Stereo-Enhanced Framework for Robust Multi-View 3D Object Detection</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– ECCV 2024ã€‚</li>
<li>ğŸ’¡ æå‡ºStereoMV2Dæ¡†æ¶ï¼Œå°†æ—¶åºç«‹ä½“å»ºæ¨¡å¼•å…¥åŸºäº2Dæ£€æµ‹å¼•å¯¼çš„å¤šè§†è§’3Dæ£€æµ‹å™¨ï¼Œé€šè¿‡åˆ©ç”¨ç›¸é‚»å¸§é—´åŒä¸€ç›®æ ‡çš„è·¨æ—¶åºè§†å·®æ¥å¢å¼ºæ·±åº¦æ„ŸçŸ¥å¹¶ä¼˜åŒ–æŸ¥è¯¢å…ˆéªŒï¼Œä»è€Œè§£å†³å•å¸§2Dæ£€æµ‹å›ºæœ‰çš„æ·±åº¦æ¨¡ç³Šé—®é¢˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17620v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17620.pdf">PDF</a></li>
</ul>
<p><strong>åˆ©ç”¨é¢„æµ‹æ€§å®‰å…¨è¡¨å¾å­¦ä¹ å®‰å…¨çš„è‡ªåŠ¨é©¾é©¶ç­–ç•¥</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Learning Safe Autonomous Driving Policies Using Predictive Safety Representations</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ ICLR 2025 æˆ– NeurIPS 2025</li>
<li>ğŸ’¡ å°†ç”¨äºå®‰å…¨å¼ºåŒ–å­¦ä¹ çš„é¢„æµ‹æ€§å®‰å…¨è¡¨ç¤ºï¼ˆSRPLï¼‰æ¡†æ¶ï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§åœ°åº”ç”¨äºçœŸå®ä¸–ç•Œè‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼ˆWaymoå’ŒNuPlanæ•°æ®é›†ï¼‰ï¼ŒéªŒè¯å…¶åœ¨æå‡æˆåŠŸç‡ä¸é™ä½å®‰å…¨æˆæœ¬æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17586v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17586.pdf">PDF</a></li>
</ul>
<p><strong>TakeADï¼šåŸºäºä¸“å®¶æ¥ç®¡æ•°æ®çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶åå¥½åä¼˜åŒ–</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CoRL 2025 æˆ– ICLR 2025</li>
<li>ğŸ’¡ æå‡ºTakeADæ¡†æ¶ï¼Œé¦–æ¬¡åˆ©ç”¨è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿè„±é’©åœºæ™¯ä¸­çš„ä¸“å®¶æ¥ç®¡æ•°æ®ï¼Œé€šè¿‡åå¥½ä¼˜åŒ–å¯¹é¢„è®­ç»ƒçš„æ¨¡ä»¿å­¦ä¹ ç­–ç•¥è¿›è¡Œåä¼˜åŒ–ï¼Œä»¥è§£å†³å¼€ç¯è®­ç»ƒä¸é—­ç¯éƒ¨ç½²çš„é”™ä½é—®é¢˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17370v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17370.pdf">PDF</a></li>
</ul>
<p><strong>DVGT: Driving Visual Geometry Transformer</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16919v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16919.pdf">PDF</a></li>
</ul>
<p><strong>Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16760v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16760.pdf">PDF</a></li>
</ul>
<p><strong>Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13107v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13107.pdf">PDF</a></li>
</ul>
<p><strong>Self-localization on a 3D map by fusing global and local features from a monocular camera</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.26170v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.26170.pdf">PDF</a></li>
</ul>
<p><strong>DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.12796v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.12796.pdf">PDF</a></li>
</ul>
<p><strong>CompEvent: Complex-valued Event-RGB Fusion for Low-light Video Enhancement and Deblurring</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14469v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.14469.pdf">PDF</a></li>
</ul>
<p><strong>LADY: Linear Attention for Autonomous Driving Efficiency without Transformers</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15038v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15038.pdf">PDF</a></li>
</ul>
<p><strong>Autoencoder-based Denoising Defense against Adversarial Attacks on Object Detection</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16123v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16123.pdf">PDF</a></li>
</ul>
<p><strong>Driving in Corner Case: A Real-World Adversarial Closed-Loop Evaluation Platform for End-to-End Autonomous Driving</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16055v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16055.pdf">PDF</a></li>
</ul>
<p><strong>From Words to Wavelengths: VLMs for Few-Shot Multispectral Object Detection</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15971v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15971.pdf">PDF</a></li>
</ul>
<p><strong>OccSTeP: Benchmarking 4D Occupancy Spatio-Temporal Persistence</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15621v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15621.pdf">PDF</a></li>
</ul>
<p><strong>Human-like Working Memory from Artificial Intrinsic Plasticity Neurons</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15829v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15829.pdf">PDF</a></li>
</ul>
<p><strong>DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.09245v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.09245.pdf">PDF</a></li>
</ul>
<p><strong>KD360-VoxelBEV: LiDAR and 360-degree Camera Cross Modality Knowledge Distillation for Birdâ€™s-Eye-View Segmentation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15311v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15311.pdf">PDF</a></li>
</ul>
<p><strong>EPSM: A Novel Metric to Evaluate the Safety of Environmental Perception in Autonomous Driving</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15195v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15195.pdf">PDF</a></li>
</ul>
<p><strong>Large Model Enabled Embodied Intelligence for 6G Integrated Perception, Communication, and Computation Network</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15109v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15109.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="3D-Gaussian-Splatting-50-ç¯‡"><a href="#3D-Gaussian-Splatting-50-ç¯‡" class="headerlink" title="3D Gaussian Splatting (50 ç¯‡)"></a><span id="3d-gaussian-splatting">3D Gaussian Splatting</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>åˆå”±å›¢ï¼šé¢å‘æ•´ä½“ä¸‰ç»´é«˜æ–¯åœºæ™¯ç¼–ç çš„å¤šæ•™å¸ˆé¢„è®­ç»ƒ</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Chorus: Multi-Teacher Pretraining for Holistic 3D Gaussian Scene Encoding</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– ICLR 2025</li>
<li>ğŸ’¡ æå‡ºäº†Chorusï¼Œé¦–ä¸ªé€šè¿‡ä»å¤šä¸ª2DåŸºç¡€æ¨¡å‹è’¸é¦äº’è¡¥ä¿¡å·æ¥é¢„è®­ç»ƒå…¨æ ˆå¼3Dé«˜æ–¯åœºæ™¯ç¼–ç å™¨çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä¸º3DGSåŸºå…ƒå­¦ä¹ ä¸°å¯Œã€é€šç”¨çš„ç‰¹å¾è¡¨ç¤ºã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17817v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17817.pdf">PDF</a></li>
</ul>
<p><strong>G3Splatï¼šå‡ ä½•ä¸€è‡´å¯æ³›åŒ–çš„é«˜æ–¯æº…å°„</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>G3Splat: Geometrically Consistent Generalizable Gaussian Splatting</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– ECCV 2024</li>
<li>ğŸ’¡ é’ˆå¯¹ä»…ä¾èµ–è§†å›¾åˆæˆæŸå¤±å¯¼è‡´å‡ ä½•ä¿¡æ¯æ¨¡ç³Šçš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºG3Splatï¼Œé€šè¿‡å¼•å…¥å‡ ä½•å…ˆéªŒçº¦æŸï¼Œå®ç°äº†å‡ ä½•ä¸€è‡´çš„å¯æ³›åŒ–3Dé«˜æ–¯æº…å°„è¡¨ç¤ºã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17547v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17547.pdf">PDF</a></li>
</ul>
<p><strong>VLA-ANï¼šé¢å‘å¤æ‚ç¯å¢ƒç©ºä¸­å¯¼èˆªçš„é«˜æ•ˆæœºè½½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨æ¡†æ¶</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– IROS 2025ï¼ˆå› å…¶èšç„¦è®¡ç®—æœºè§†è§‰ä¸æœºå™¨äººç³»ç»Ÿé›†æˆï¼Œä¸”è§£å†³äº†å®é™…éƒ¨ç½²çš„å…³é”®ç“¶é¢ˆï¼‰ã€‚</li>
<li>ğŸ’¡ æå‡ºé¦–ä¸ªé«˜æ•ˆã€å¯æœºè½½éƒ¨ç½²çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ— äººæœºå¯¼èˆªæ¡†æ¶VLA-ANï¼Œé€šè¿‡æ„å»ºåŸºäº3Dé«˜æ–¯æ³¼æº…çš„é«˜ä¿çœŸæ•°æ®é›†ã€æ¸è¿›å¼ä¸‰é˜¶æ®µè®­ç»ƒä»¥åŠç»“åˆå‡ ä½•å®‰å…¨æ ¡æ­£çš„è½»é‡åŒ–å®æ—¶åŠ¨ä½œæ¨¡å—ï¼Œç³»ç»Ÿæ€§åœ°è§£å†³äº†ç°æœ‰å¤§å‹ç©ºä¸­å¯¼èˆªæ¨¡å‹åœ¨æ•°æ®åŸŸã€æ—¶åºæ¨ç†ã€å®‰å…¨æ€§å’Œéƒ¨ç½²æ•ˆç‡æ–¹é¢çš„å››å¤§å±€é™ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15258v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15258.pdf">PDF</a></li>
</ul>
<p><strong>åŸºäºä¸‰ç»´è¾å°„åœºåŸŸé€‚åº”å­¦ä¹ çš„å•ç›®RGBæ‚ä¹±ç¯å¢ƒé£è¡Œ</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ ICRA 2025 æˆ– RSS 2025ï¼ˆæœºå™¨äººå­¦é¡¶çº§ä¼šè®®ï¼‰ï¼›æˆ–ä½œä¸ºäº¤å‰é¢†åŸŸå·¥ä½œå‘è¡¨äº CVPR 2025ã€‚</li>
<li>ğŸ’¡ æå‡ºäº†ä¸€ç§ç»“åˆ3Dé«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰é«˜ä¿çœŸä»¿çœŸä¸å¯¹æŠ—æ€§åŸŸé€‚åº”çš„æ¡†æ¶ï¼Œé¦–æ¬¡å®ç°äº†ä»…ä½¿ç”¨å•ç›®RGBå›¾åƒåœ¨æ‚ä¹±ç¯å¢ƒä¸­è¿›è¡Œé›¶æ ·æœ¬çœŸå®ä¸–ç•Œé£è¡Œçš„ç­–ç•¥å­¦ä¹ ï¼Œæœ‰æ•ˆå¼¥åˆäº†ä»¿çœŸä¸ç°å®çš„æ„ŸçŸ¥å·®è·ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17349v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17349.pdf">PDF</a></li>
</ul>
<p><strong>PhysGMï¼šç”¨äºå‰é¦ˆå¼å››ç»´åˆæˆçš„å¤§å‹ç‰©ç†é«˜æ–¯æ¨¡å‹</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>PhysGM: Large Physical Gaussian Model for Feed-Forward 4D Synthesis</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– arXiv preprint</li>
<li>ğŸ’¡ æå‡ºPhysGMï¼Œä¸€ç§å‰é¦ˆå¼æ¡†æ¶ï¼Œèƒ½å¤Ÿä»å•å¼ å›¾åƒè”åˆé¢„æµ‹3Dé«˜æ–¯è¡¨ç¤ºå’Œç‰©ç†å±æ€§ï¼Œå®ç°äº†æ— éœ€é€åœºæ™¯ä¼˜åŒ–çš„å¿«é€Ÿ4Dåˆæˆä¸æ¸²æŸ“ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.13911v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.13911.pdf">PDF</a></li>
</ul>
<p><strong>UniGaussianï¼šåŸºäºç»Ÿä¸€é«˜æ–¯è¡¨ç¤ºçš„å¤šç›¸æœºæ¨¡å‹é©¾é©¶åœºæ™¯é‡å»º</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>UniGaussian: Driving Scene Reconstruction from Multiple Camera Models via Unified Gaussian Representations</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– ECCV 2024&#x2F;2026ï¼ˆè€ƒè™‘åˆ°å…¶èšç„¦äº3Dé‡å»ºã€ç¥ç»æ¸²æŸ“ä¸è‡ªåŠ¨é©¾é©¶çš„äº¤å‰é¢†åŸŸï¼Œä¸”æ–¹æ³•å…·æœ‰æ˜¾è‘—åˆ›æ–°æ€§å’Œå®ç”¨æ€§ï¼Œé¡¶çº§è®¡ç®—æœºè§†è§‰ä¼šè®®æ˜¯å…¶ä¸»è¦ç›®æ ‡ï¼‰ã€‚</li>
<li>ğŸ’¡ æå‡ºäº†ä¸€ç§åä¸ºUniGaussiançš„æ–°æ–¹æ³•ï¼Œé¦–æ¬¡å®ç°äº†ä»å¤šç›¸æœºæ¨¡å‹ï¼ˆåŒ…æ‹¬é’ˆå­”å’Œé±¼çœ¼ç›¸æœºï¼‰å­¦ä¹ ç»Ÿä¸€çš„3Dé«˜æ–¯è¡¨ç¤ºï¼Œç”¨äºè‡ªåŠ¨é©¾é©¶åŸå¸‚åœºæ™¯é‡å»ºï¼›å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§é’ˆå¯¹é±¼çœ¼ç›¸æœºæ¨¡å‹çš„å¯å¾®æ¸²æŸ“æ–¹æ³•ï¼Œé€šè¿‡ä¸€ç³»åˆ—ä»¿å°„å˜æ¢æ¥æ‰­æ›²3Dé«˜æ–¯ï¼Œè§£å†³äº†3Dé«˜æ–¯æ³¼æº…ä¸é±¼çœ¼ç›¸æœºä¸å…¼å®¹çš„éš¾é¢˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.15355v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.15355.pdf">PDF</a></li>
</ul>
<p><strong>NeAR: Coupled Neural Asset-Renderer Stack</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18600v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18600.pdf">PDF</a></li>
</ul>
<p><strong>SDFoam: Signed-Distance Foam for explicit surface reconstruction</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16706v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16706.pdf">PDF</a></li>
</ul>
<p><strong>D-FCGS: Feedforward Compression of Dynamic Gaussian Splatting for Free-Viewpoint Videos</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.05859v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.05859.pdf">PDF</a></li>
</ul>
<p><strong>Gaussian Pixel Codec Avatars: A Hybrid Representation for Efficient Rendering</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15711v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15711.pdf">PDF</a></li>
</ul>
<p><strong>Off The Grid: Detection of Primitives for Feed-Forward 3D Gaussian Splatting</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15508v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15508.pdf">PDF</a></li>
</ul>
<p><strong>MVGSR: Multi-View Consistent 3D Gaussian Super-Resolution via Epipolar Guidance</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15048v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15048.pdf">PDF</a></li>
</ul>
<p><strong>HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14352v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14352.pdf">PDF</a></li>
</ul>
<p><strong>RTR-GS: 3D Gaussian Splatting for Inverse Rendering with Radiance Transfer and Reflection</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.07733v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.07733.pdf">PDF</a></li>
</ul>
<p><strong>Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14200v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14200.pdf">PDF</a></li>
</ul>
<p><strong>Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14180v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14180.pdf">PDF</a></li>
</ul>
<p><strong>GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14087v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14087.pdf">PDF</a></li>
</ul>
<p><strong>ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14039v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14039.pdf">PDF</a></li>
</ul>
<p><strong>Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13796v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13796.pdf">PDF</a></li>
</ul>
<p><strong>OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.09397v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.09397.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="World-Model-50-ç¯‡"><a href="#World-Model-50-ç¯‡" class="headerlink" title="World Model (50 ç¯‡)"></a><span id="world-model">World Model</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>çµå·§ä¸–ç•Œæ¨¡å‹</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Dexterous World Models</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 &#x2F; ICCV 2025 &#x2F; arXiv preprint</li>
<li>ğŸ’¡ æå‡ºDexterous World Model (DWM)ï¼Œä¸€ä¸ªåœºæ™¯-åŠ¨ä½œæ¡ä»¶åŒ–çš„è§†é¢‘æ‰©æ•£æ¡†æ¶ï¼Œç”¨äºå»ºæ¨¡çµå·§äººæ‰‹åŠ¨ä½œå¦‚ä½•é©±åŠ¨é™æ€3Dåœºæ™¯äº§ç”ŸåŠ¨æ€äº¤äº’å˜åŒ–ï¼Œä»è€Œä¸ºæ•°å­—å­ªç”Ÿç¯å¢ƒæ³¨å…¥å…·èº«äº¤äº’èƒ½åŠ›ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17907v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17907.pdf">PDF</a></li>
</ul>
<p><strong>é€šè¿‡è¾“å…¥é¢„æµ‹ä¸å¤±è¯¯ä¿®æ­£åŠ é€Ÿå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ¸¸æˆæ€§èƒ½</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ ICLR 2025 æˆ– NeurIPS 2025ï¼ˆè®ºæ–‡èšç„¦å¼ºåŒ–å­¦ä¹ ä¸æ¨¡å‹é¢„æµ‹æ§åˆ¶çš„äº¤å‰é¢†åŸŸï¼Œæ–¹æ³•å…·æœ‰ç†è®ºåˆ›æ–°å’Œå®éªŒéªŒè¯ï¼Œç¬¦åˆé¡¶çº§æœºå™¨å­¦ä¹ ä¼šè®®çš„å½•ç”¨æ ‡å‡†ï¼‰ã€‚</li>
<li>ğŸ’¡ æå‡ºä¸€ç§â€œæ¨æµ‹ä¸ä¿®æ­£â€æ¡†æ¶ï¼Œå°†æ¨æµ‹æ‰§è¡Œçš„â€œé¢„æµ‹-éªŒè¯â€æ€æƒ³åº”ç”¨äºåŸºäºæ¨¡å‹çš„å®æ—¶æ§åˆ¶ï¼Œé€šè¿‡é¢„æµ‹åŠ¨ä½œé˜Ÿåˆ—å’Œè½»é‡çº§ä¿®æ­£æ¥å‡å°‘è§„åˆ’å»¶è¿Ÿï¼Œæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨æ¸¸æˆä¸­çš„å®æ—¶æ§åˆ¶æ€§èƒ½ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17250v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17250.pdf">PDF</a></li>
</ul>
<p><strong>åŸºäºä»£è¡¨æ€§æ½œåœ¨ä¸–ç•Œæ¨¡å‹çš„é«˜æ•ˆå›¾åƒç›®æ ‡å¯¼èˆª</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Efficient Image-Goal Navigation with Representative Latent World Model</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– ICLR 2025</li>
<li>ğŸ’¡ æå‡ºäº†ä¸€ç§åœ¨é«˜çº§è¯­ä¹‰è¡¨å¾çš„éšç©ºé—´ä¸­è¿›è¡Œé¢„æµ‹å’Œè§„åˆ’çš„å¯¼èˆªä¸–ç•Œæ¨¡å‹ï¼ˆReL-NWMï¼‰ï¼Œæ‘’å¼ƒäº†ä¼ ç»Ÿæ–¹æ³•ä¸­è®¡ç®—å¯†é›†çš„åƒç´ çº§é‡å»ºï¼Œå®ç°äº†é«˜æ•ˆå¯¼èˆªã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.11011v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.11011.pdf">PDF</a></li>
</ul>
<p><strong>PhysFire-WMï¼šä¸€ç§ç”¨äºæ¨¡æ‹Ÿç«ç¾è”“å»¶åŠ¨æ€çš„ç‰©ç†ä¿¡æ¯ä¸–ç•Œæ¨¡å‹</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>PhysFire-WM: A Physics-Informed World Model for Emulating Fire Spread Dynamics</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– ICLR 2025ï¼ˆå› å…¶ç»“åˆäº†è®¡ç®—æœºè§†è§‰ã€ç‰©ç†å»ºæ¨¡ä¸ç”Ÿæˆæ¨¡å‹ï¼Œä¸”æ–¹æ³•å…·æœ‰åˆ›æ–°æ€§ï¼Œé€‚åˆé¡¶çº§AIä¼šè®®ï¼‰ã€‚</li>
<li>ğŸ’¡ æå‡ºäº†ä¸€ç§èåˆç‰©ç†å…ˆéªŒçš„ä¸–ç•Œæ¨¡å‹PhysFire-WMï¼Œé€šè¿‡å¼•å…¥ç‰©ç†æ¨¡æ‹Ÿå™¨çš„ç»“æ„åŒ–å…ˆéªŒæ¥çº æ­£ç‰©ç†ä¸ä¸€è‡´æ€§ï¼Œå¹¶è®¾è®¡äº†è·¨ä»»åŠ¡ååŒè®­ç»ƒç­–ç•¥ä»¥æ•´åˆçƒ­è¾å°„å’Œè¾¹ç•Œä¿¡æ¯ï¼Œæå‡äº†ç«ç¾è”“å»¶åŠ¨æ€æ¨¡æ‹Ÿçš„å‡†ç¡®æ€§ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17152v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17152.pdf">PDF</a></li>
</ul>
<p><strong>The World is Your Canvas: Painting Promptable Events with Reference Images, Trajectories, and Text</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16924v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16924.pdf">PDF</a></li>
</ul>
<p><strong>Animate Any Character in Any World</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17796v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17796.pdf">PDF</a></li>
</ul>
<p><strong>SNOW: Spatio-Temporal Scene Understanding with World Knowledge for Open-World Embodied Reasoning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16461v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16461.pdf">PDF</a></li>
</ul>
<p><strong>Enter the Void - Planning to Seek Entropy When Reward is Scarce</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.16787v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.16787.pdf">PDF</a></li>
</ul>
<p><strong>AIE4ML: An End-to-End Framework for Compiling Neural Networks for the Next Generation of AMD AI Engines</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15946v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15946.pdf">PDF</a></li>
</ul>
<p><strong>R4: Retrieval-Augmented Reasoning for Vision-Language Models in 4D Spatio-Temporal Space</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15940v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15940.pdf">PDF</a></li>
</ul>
<p><strong>MMGR: Multi-Modal Generative Reasoning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14691v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14691.pdf">PDF</a></li>
</ul>
<p><strong>Soft Geometric Inductive Bias for Object Centric Dynamics</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15493v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15493.pdf">PDF</a></li>
</ul>
<p><strong>SparseWorld-TC: Trajectory-Conditioned Sparse Occupancy World Model</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.22039v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.22039.pdf">PDF</a></li>
</ul>
<p><strong>WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14614v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14614.pdf">PDF</a></li>
</ul>
<p><strong>MobileWorldBench: Towards Semantic World Modeling For Mobile Agents</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14014v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14014.pdf">PDF</a></li>
</ul>
<p><strong>Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.10400v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.10400.pdf">PDF</a></li>
</ul>
<p><strong>The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13821v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13821.pdf">PDF</a></li>
</ul>
<p><strong>World Models Can Leverage Human Videos for Dexterous Manipulation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13644v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13644.pdf">PDF</a></li>
</ul>
<p><strong>LongVie 2: Multimodal Controllable Ultra-Long Video World Model</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13604v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13604.pdf">PDF</a></li>
</ul>
<p><strong>A Deep Learning Model of Mental Rotation Informed by Interactive VR Experiments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13517v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13517.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Vision-Language-Action-50-ç¯‡"><a href="#Vision-Language-Action-50-ç¯‡" class="headerlink" title="Vision Language Action (50 ç¯‡)"></a><span id="vision-language-action">Vision Language Action</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>æ¨¡ä»¿è§†é¢‘ï¼šè¶…è¶Šè§†è§‰è¯­è¨€æ¨¡å‹çš„é€šç”¨æœºå™¨äººæ§åˆ¶è§†é¢‘åŠ¨ä½œæ¨¡å‹</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– ICLR 2025ï¼ˆè‹¥æœªæ­£å¼å‘è¡¨ï¼Œå¯èƒ½å…ˆä»¥ arXiv preprint å½¢å¼å‘å¸ƒï¼‰</li>
<li>ğŸ’¡ æå‡ºä¸€ç§åä¸º mimic-video çš„æ–°å‹è§†é¢‘-åŠ¨ä½œæ¨¡å‹ï¼Œé€šè¿‡åˆ©ç”¨äº’è”ç½‘è§„æ¨¡çš„è§†é¢‘æ¨¡å‹æ¥è”åˆå­¦ä¹ è¯­ä¹‰å’Œè§†è§‰åŠ¨æ€å…ˆéªŒï¼Œä»è€Œå°†ä½çº§æ§åˆ¶ä»»åŠ¡ä¸ç‰©ç†åŠ¨æ€ç†è§£åˆ†ç¦»ï¼Œæ—¨åœ¨å‡å°‘æœºå™¨äººç­–ç•¥å­¦ä¹ å¯¹å¤§è§„æ¨¡ä¸“å®¶æ¼”ç¤ºæ•°æ®çš„ä¾èµ–ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15692v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15692.pdf">PDF</a></li>
</ul>
<p><strong>è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹å‰–æï¼šä»æ¨¡å—æ„æˆåˆ°é‡Œç¨‹ç¢‘ä¸æŒ‘æˆ˜</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>An Anatomy of Vision-Language-Action Models: From Modules to Milestones and Challenges</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ arXiv preprintã€‚è¿™æ˜¯ä¸€ç¯‡é¢†åŸŸç»¼è¿°è®ºæ–‡ï¼Œå†…å®¹å…¨é¢ä¸”ç»“æ„æ¸…æ™°ï¼Œæ—¨åœ¨æ¢³ç†çˆ†ç‚¸å¼å¢é•¿çš„VLAç ”ç©¶ç°çŠ¶ï¼Œå…¶å½¢å¼å’Œç›®æ ‡ä¸åœ¨arXivä¸Šå¿«é€Ÿå‘å¸ƒçš„ç»¼è¿°æ–‡ç« é«˜åº¦å»åˆã€‚</li>
<li>ğŸ’¡ æœ¬æ–‡çš„ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºä¸ºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹é¢†åŸŸæä¾›äº†ä¸€ä¸ªæ¸…æ™°ã€ç»“æ„åŒ–çš„ç»¼è¿°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒè´¡çŒ®æ˜¯å°†è¯¥é¢†åŸŸçš„å‘å±•è·¯å¾„ç³»ç»Ÿæ€§åœ°åˆ†è§£ä¸ºâ€œæ¨¡å—-é‡Œç¨‹ç¢‘-æŒ‘æˆ˜â€ä¸‰ä¸ªå±‚æ¬¡ï¼Œå¹¶é‡ç‚¹å‰–æäº†è¡¨å¾ã€æ‰§è¡Œã€æ³›åŒ–ã€å®‰å…¨ã€æ•°æ®é›†ä¸è¯„ä¼°è¿™äº”å¤§æ ¸å¿ƒæŒ‘æˆ˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11362v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11362.pdf">PDF</a></li>
</ul>
<p><strong>MiVLAï¼šè¿ˆå‘é€šç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼šåŸºäºäººæœºäº’æ¨¡ä»¿é¢„è®­ç»ƒ</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>MiVLA: Towards Generalizable Vision-Language-Action Model with Human-Robot Mutual Imitation Pre-training</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– ICLR 2025</li>
<li>ğŸ’¡ æå‡ºMiVLAæ¨¡å‹ï¼Œé€šè¿‡äººç±»ä¸æœºå™¨äººä¹‹é—´çš„â€œåŒå‘æ¨¡ä»¿â€é¢„è®­ç»ƒï¼Œåˆ©ç”¨äººæ‰‹ä¸æœºæ¢°è‡‚çš„è¡Œä¸ºç›¸ä¼¼æ€§æ¥æ„å»ºé€šç”¨çš„è¡Œä¸ºå…ˆéªŒï¼Œä»¥è§£å†³ç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨è§†è§’ã€å¤–è§‚å’Œå½¢æ€å·®å¼‚ä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³é—®é¢˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15411v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15411.pdf">PDF</a></li>
</ul>
<p><strong>éšå½¢å¨èƒï¼šæ¢ç´¢å¹¶å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹å¯¹æŠ—ç‰©ç†ä¼ æ„Ÿå™¨æ”»å‡»çš„é²æ£’æ€§</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Phantom Menace: Exploring and Enhancing the Robustness of VLA Models Against Physical Sensor Attacks</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ CVPR 2025 æˆ– ICLR 2025</li>
<li>ğŸ’¡ é¦–æ¬¡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†é’ˆå¯¹è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„ç‰©ç†ä¼ æ„Ÿå™¨æ”»å‡»ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªâ€œçœŸå®-æ¨¡æ‹Ÿ-çœŸå®â€æ¡†æ¶æ¥è‡ªåŠ¨ç”Ÿæˆå’ŒéªŒè¯æ”»å‡»å‘é‡ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸå®‰å…¨ç ”ç©¶çš„ç©ºç™½ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.10008v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.10008.pdf">PDF</a></li>
</ul>
<p><strong>GeoPredict: Leveraging Predictive Kinematics and 3D Gaussian Geometry for Precise VLA Manipulation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.16811v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.16811.pdf">PDF</a></li>
</ul>
<p><strong>Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08333v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08333.pdf">PDF</a></li>
</ul>
<p><strong>Large Video Planner Enables Generalizable Robot Control</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15840v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15840.pdf">PDF</a></li>
</ul>
<p><strong>EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14666v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14666.pdf">PDF</a></li>
</ul>
<p><strong>Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14031v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14031.pdf">PDF</a></li>
</ul>
<p><strong>Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13080v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13080.pdf">PDF</a></li>
</ul>
<p><strong>WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11047v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11047.pdf">PDF</a></li>
</ul>
<p><strong>End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-13</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.00139v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.00139.pdf">PDF</a></li>
</ul>
<p><strong>BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11769v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11769.pdf">PDF</a></li>
</ul>
<p><strong>Embodied Image Compression</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11612v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11612.pdf">PDF</a></li>
</ul>
<p><strong>Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11584v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11584.pdf">PDF</a></li>
</ul>
<p><strong>Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14396v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.14396.pdf">PDF</a></li>
</ul>
<p><strong>Benchmarking the Generality of Vision-Language-Action Models</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11315v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11315.pdf">PDF</a></li>
</ul>
<p><strong>Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11218v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11218.pdf">PDF</a></li>
</ul>
<p><strong>Towards Accessible Physical AI: LoRA-Based Fine-Tuning of VLA Models for Real-World Robot Control</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11921v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11921.pdf">PDF</a></li>
</ul>
<p><strong>RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10394v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10394.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Vision-and-Language-Navigation-50-ç¯‡"><a href="#Vision-and-Language-Navigation-50-ç¯‡" class="headerlink" title="Vision and Language Navigation (50 ç¯‡)"></a><span id="vision-and-language-navigation">Vision and Language Navigation</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14222v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14222.pdf">PDF</a></li>
</ul>
<p><strong>MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.03958v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.03958.pdf">PDF</a></li>
</ul>
<p><strong>D3D-VLP: Dynamic 3D Vision-Language-Planning Model for Embodied Grounding and Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-14</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12622v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12622.pdf">PDF</a></li>
</ul>
<p><strong>CLASH: Collaborative Large-Small Hierarchical Framework for Continuous Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10360v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10360.pdf">PDF</a></li>
</ul>
<p><strong>User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10322v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10322.pdf">PDF</a></li>
</ul>
<p><strong>Aerial Vision-Language Navigation with a Unified Framework for Spatial, Temporal and Embodied Reasoning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08639v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08639.pdf">PDF</a></li>
</ul>
<p><strong>Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.08186v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.08186.pdf">PDF</a></li>
</ul>
<p><strong>ST-Booster: An Iterative SpatioTemporal Perception Booster for Vision-and-Language Navigation in Continuous Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.09843v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.09843.pdf">PDF</a></li>
</ul>
<p><strong>UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-24</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18845v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18845.pdf">PDF</a></li>
</ul>
<p><strong>Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14131v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.14131.pdf">PDF</a></li>
</ul>
<p><strong>FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.13524v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.13524.pdf">PDF</a></li>
</ul>
<p><strong>Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.13132v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.13132.pdf">PDF</a></li>
</ul>
<p><strong>VISTAv2: World Imagination for Indoor Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-14</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.00041v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.00041.pdf">PDF</a></li>
</ul>
<p><strong>Agent Journey Beyond RGB: Hierarchical Semantic-Spatial Representation Enrichment for Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-13</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.06465v5">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.06465.pdf">PDF</a></li>
</ul>
<p><strong>A Survey on Improving Human Robot Collaboration through Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-06</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.00027v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.00027.pdf">PDF</a></li>
</ul>
<p><strong>Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.00933v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.00933.pdf">PDF</a></li>
</ul>
<p><strong>Continual Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-31</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.15049v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.15049.pdf">PDF</a></li>
</ul>
<p><strong>STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-27</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.00033v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.00033.pdf">PDF</a></li>
</ul>
<p><strong>LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-22</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.19655v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.19655.pdf">PDF</a></li>
</ul>
<p><strong>NavQ: Learning a Q-Model for Foresighted Vision-and-Language Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.16457v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.16457.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Visual-Place-Recognition-50-ç¯‡"><a href="#Visual-Place-Recognition-50-ç¯‡" class="headerlink" title="Visual Place Recognition (50 ç¯‡)"></a><span id="visual-place-recognition">Visual Place Recognition</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>Enhancing Geo-localization for Crowdsourced Flood Imagery via LLM-Guided Attention</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11811v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11811.pdf">PDF</a></li>
</ul>
<p><strong>Towards Test-time Efficient Visual Place Recognition via Asymmetric Query Processing</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13055v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13055.pdf">PDF</a></li>
</ul>
<p><strong>Adaptive Thresholding for Visual Place Recognition using Negative Gaussian Mixture Statistics</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09071v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09071.pdf">PDF</a></li>
</ul>
<p><strong>Spike-EVPR: Deep Spiking Residual Networks with SNN-Tailored Representations for Event-Based Visual Place Recognition</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.10476v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2402.10476.pdf">PDF</a></li>
</ul>
<p><strong>D$^{2}$-VPR: A Parameter-efficient Visual-foundation-model-based Visual Place Recognition Method via Knowledge Distillation and Deformable Aggregation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.12528v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.12528.pdf">PDF</a></li>
</ul>
<p><strong>GuideNav: User-Informed Development of a Vision-Only Robotic Navigation Assistant For Blind Travelers</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-05</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.06147v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.06147.pdf">PDF</a></li>
</ul>
<p><strong>SAGE: Spatial-visual Adaptive Graph Exploration for Visual Place Recognition</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-04</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.25723v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.25723.pdf">PDF</a></li>
</ul>
<p><strong>Image-Based Relocalization and Alignment for Long-Term Monitoring of Dynamic Underwater Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.04096v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.04096.pdf">PDF</a></li>
</ul>
<p><strong>Scene Summarization: Clustering Scene Videos into Spatially Diverse Frames</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.17940v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.17940.pdf">PDF</a></li>
</ul>
<p><strong>SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18290v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18290.pdf">PDF</a></li>
</ul>
<p><strong>$A^2$GC: $A$symmetric $A$ggregation with Geometric Constraints for Locally Aggregated Descriptors</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14109v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.14109.pdf">PDF</a></li>
</ul>
<p><strong>Towards Implicit Aggregation: Robust Image Representation for Place Recognition in the Transformer Era</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.06024v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.06024.pdf">PDF</a></li>
</ul>
<p><strong>MutualVPR: A Mutual Learning Framework for Resolving Supervision Inconsistencies via Adaptive Clustering</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.09199v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.09199.pdf">PDF</a></li>
</ul>
<p><strong>Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.05404v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.05404.pdf">PDF</a></li>
</ul>
<p><strong>SelaVPR++: Towards Seamless Adaptation of Foundation Models for Efficient Place Recognition</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.16601v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.16601.pdf">PDF</a></li>
</ul>
<p><strong>Joint Multi-Condition Representation Modelling via Matrix Factorisation for Visual Place Recognition</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-20</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.17739v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.17739.pdf">PDF</a></li>
</ul>
<p><strong>Through the Lens of Doubt: Robust and Efficient Uncertainty Estimation for Visual Place Recognition</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.13464v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.13464.pdf">PDF</a></li>
</ul>
<p><strong>Flexible and Efficient Spatio-Temporal Transformer for Sequential Visual Place Recognition</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-05</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.04282v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.04282.pdf">PDF</a></li>
</ul>
<p><strong>The Overlooked Value of Test-time Reference Sets in Visual Place Recognition</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-04</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.03751v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.03751.pdf">PDF</a></li>
</ul>
<p><strong>Hierarchical place recognition with omnidirectional images and curriculum learning-based loss functions</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.14117v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.14117.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Visual-Inertial-Odometry-50-ç¯‡"><a href="#Visual-Inertial-Odometry-50-ç¯‡" class="headerlink" title="Visual Inertial Odometry (50 ç¯‡)"></a><span id="visual-inertial-odometry">Visual Inertial Odometry</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>SUPER â€“ A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14189v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14189.pdf">PDF</a></li>
</ul>
<p><strong>Development and Testing for Perception Based Autonomous Landing of a Long-Range QuadPlane</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09343v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09343.pdf">PDF</a></li>
</ul>
<p><strong>Enabling Autonomous Navigation in a Snake Robot through Visual-Inertial Odometry and Closed-Loop Trajectory Tracking Control</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11886v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11886.pdf">PDF</a></li>
</ul>
<p><strong>Dual-Agent Reinforcement Learning for Adaptive and Cost-Aware Visual-Inertial Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-26</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.21083v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.21083.pdf">PDF</a></li>
</ul>
<p><strong>SMF-VO: Direct Ego-Motion Estimation via Sparse Motion Fields</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.09072v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.09072.pdf">PDF</a></li>
</ul>
<p><strong>Multi-cam Multi-map Visual Inertial Localization: System, Validation and Dataset</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.04287v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.04287.pdf">PDF</a></li>
</ul>
<p><strong>A Plug-and-Play Learning-based IMU Bias Factor for Robust Visual-Inertial Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.12527v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.12527.pdf">PDF</a></li>
</ul>
<p><strong>TCB-VIO: Tightly-Coupled Focal-Plane Binary-Enhanced Visual Inertial Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-04</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.03919v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.03919.pdf">PDF</a></li>
</ul>
<p><strong>Learned IMU Bias Prediction for Invariant Visual Inertial Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.06748v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.06748.pdf">PDF</a></li>
</ul>
<p><strong>Statistical Uncertainty Learning for Robust Visual-Inertial State Estimation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.01648v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.01648.pdf">PDF</a></li>
</ul>
<p><strong>Autonomous Close-Proximity Photovoltaic Panel Coating Using a Quadcopter</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-28</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.10979v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.10979.pdf">PDF</a></li>
</ul>
<p><strong>An Extended Kalman Filter for Systems with Infinite-Dimensional Measurements</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.18749v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.18749.pdf">PDF</a></li>
</ul>
<p><strong>Efficient and Accurate Downfacing Visual Inertial Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.10021v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.10021.pdf">PDF</a></li>
</ul>
<p><strong>Detection and Recovery of Adversarial Slow-Pose Drift in Offloaded Visual-Inertial Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.07130v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.07130.pdf">PDF</a></li>
</ul>
<p><strong>ESVO2: Direct Visual-Inertial Odometry with Stereo Event Cameras</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.09374v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.09374.pdf">PDF</a></li>
</ul>
<p><strong>Multi-LVI-SAM: A Robust LiDAR-Visual-Inertial Odometry for Multiple Fisheye Cameras</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-06</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.05740v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.05740.pdf">PDF</a></li>
</ul>
<p><strong>HDVIO2.0: Wind and Disturbance Estimation with Hybrid Dynamics VIO</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.00969v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.00969.pdf">PDF</a></li>
</ul>
<p><strong>Observer Design for Optical Flow-Based Visual-Inertial Odometry with Almost-Global Convergence</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-08-28</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.21163v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.21163.pdf">PDF</a></li>
</ul>
<p><strong>XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-08-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.13049v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.13049.pdf">PDF</a></li>
</ul>
<p><strong>DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-08-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.11950v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.11950.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="LiDAR-Odometry-50-ç¯‡"><a href="#LiDAR-Odometry-50-ç¯‡" class="headerlink" title="LiDAR Odometry (50 ç¯‡)"></a><span id="lidar-odometry">LiDAR Odometry</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>Conceptual Evaluation of Deep Visual Stereo Odometry for the MARWIN Radiation Monitoring Robot in Accelerator Tunnels</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-25</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.00080v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.00080.pdf">PDF</a></li>
</ul>
<p><strong>Doppler Correspondence: Non-Iterative Scan Matching With Doppler Velocity-Based Correspondence</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-24</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.11461v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.11461.pdf">PDF</a></li>
</ul>
<p><strong>A visual study of ICP variants for Lidar Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14919v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.14919.pdf">PDF</a></li>
</ul>
<p><strong>LIO-MARS: Non-uniform Continuous-time Trajectories for Real-time LiDAR-Inertial-Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.13985v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.13985.pdf">PDF</a></li>
</ul>
<p><strong>AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-30</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.26358v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.26358.pdf">PDF</a></li>
</ul>
<p><strong>DAMM-LOAM: Degeneracy Aware Multi-Metric LiDAR Odometry and Mapping</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.13287v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.13287.pdf">PDF</a></li>
</ul>
<p><strong>Inland-LOAM: Voxel-Based Structural Semantic LiDAR Odometry and Mapping for Inland Waterway Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.03672v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.03672.pdf">PDF</a></li>
</ul>
<p><strong>SVN-ICP: Uncertainty Estimation of ICP-based LiDAR Odometry using Stein Variational Newton</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.08069v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.08069.pdf">PDF</a></li>
</ul>
<p><strong>FORM: Fixed-Lag Odometry with Reparative Mapping utilizing Rotating LiDAR Sensors</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.09966v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.09966.pdf">PDF</a></li>
</ul>
<p><strong>An Adaptive ICP LiDAR Odometry Based on Reliable Initial Pose</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-26</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.22058v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.22058.pdf">PDF</a></li>
</ul>
<p><strong>Adaptive Motorized LiDAR Scanning Control for Robust Localization with OpenStreetMap</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.11742v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.11742.pdf">PDF</a></li>
</ul>
<p><strong>DVLO4D: Deep Visual-Lidar Odometry with Sparse Spatial-temporal Fusion</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.06023v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.06023.pdf">PDF</a></li>
</ul>
<p><strong>Efficient Active Training for Deep LiDAR Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.03211v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.03211.pdf">PDF</a></li>
</ul>
<p><strong>Generalizing Unsupervised Lidar Odometry Model from Normal to Snowy Weather Conditions</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.02011v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.02011.pdf">PDF</a></li>
</ul>
<p><strong>A flexible framework for accurate LiDAR odometry, map manipulation, and localization</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-08-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.20465v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.20465.pdf">PDF</a></li>
</ul>
<p><strong>A Comprehensive Evaluation of LiDAR Odometry Techniques</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-21</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.16000v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.16000.pdf">PDF</a></li>
</ul>
<p><strong>Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-21</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.15496v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.15496.pdf">PDF</a></li>
</ul>
<p><strong>CURL-SLAM: Continuous and Compact LiDAR Mapping</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-06-26</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.21077v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.21077.pdf">PDF</a></li>
</ul>
<p><strong>Multi-Sensor Fusion for Quadruped Robot State Estimation using Invariant Filtering and Smoothing</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-04-29</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.20615v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.20615.pdf">PDF</a></li>
</ul>
<p><strong>Transformation &amp; Translation Occupancy Grid Mapping: 2-Dimensional Deep Learning Refined SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-04-28</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.19654v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.19654.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Loop-Closure-Detection-50-ç¯‡"><a href="#Loop-Closure-Detection-50-ç¯‡" class="headerlink" title="Loop Closure Detection (50 ç¯‡)"></a><span id="loop-closure-detection">Loop Closure Detection</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>A Minimal Subset Approach for Informed Keyframe Sampling in Large-Scale SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-29</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.01791v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.01791.pdf">PDF</a></li>
</ul>
<p><strong>Sequential Autonomous Exploration-Based Precise Mapping for Mobile Robots through Stepwise and Consistent Motions</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.17005v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.17005.pdf">PDF</a></li>
</ul>
<p><strong>Semi-distributed Cross-modal Air-Ground Relative Localization</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.06749v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.06749.pdf">PDF</a></li>
</ul>
<p><strong>Multi-Mapcher: Loop Closure Detection-Free Heterogeneous LiDAR Multi-Session SLAM Leveraging Outlier-Robust Registration for Autonomous Vehicles</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.00635v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.00635.pdf">PDF</a></li>
</ul>
<p><strong>TWC-SLAM: Multi-Agent Cooperative SLAM with Text Semantics and WiFi Features Integration for Similar Indoor Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-26</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.22754v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.22754.pdf">PDF</a></li>
</ul>
<p><strong>Bag-of-Word-Groups (BoWG): A Robust and Efficient Loop Closure Detection Method Under Perceptual Aliasing</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-26</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.22529v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.22529.pdf">PDF</a></li>
</ul>
<p><strong>LiDAR, GNSS and IMU Sensor Alignment through Dynamic Time Warping to Construct 3D City Maps</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.08420v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.08420.pdf">PDF</a></li>
</ul>
<p><strong>TACS-Graphs: Traversability-Aware Consistent Scene Graphs for Ground Robot Localization and Mapping</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.14178v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.14178.pdf">PDF</a></li>
</ul>
<p><strong>Novel UWB Synthetic Aperture Radar Imaging for Mobile Robot Mapping</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.02874v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.02874.pdf">PDF</a></li>
</ul>
<p><strong>SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.17249v7">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.17249.pdf">PDF</a></li>
</ul>
<p><strong>EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.01183v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.01183.pdf">PDF</a></li>
</ul>
<p><strong>ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-08-19</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.13488v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.13488.pdf">PDF</a></li>
</ul>
<p><strong>A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-08-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.08917v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.08917.pdf">PDF</a></li>
</ul>
<p><strong>DRACo-SLAM2: Distributed Robust Acoustic Communication-efficient SLAM for Imaging Sonar EquippedUnderwater Robot Teams with Object Graph Matching</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-31</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.23629v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.23629.pdf">PDF</a></li>
</ul>
<p><strong>Uni-Mapper: Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-28</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.20538v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.20538.pdf">PDF</a></li>
</ul>
<p><strong>LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-20</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.15109v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.15109.pdf">PDF</a></li>
</ul>
<p><strong>BEV-LIO(LC): BEV Image Assisted LiDAR-Inertial Odometry with Loop Closure</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.19242v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.19242.pdf">PDF</a></li>
</ul>
<p><strong>CU-Multi: A Dataset for Multi-Robot Data Association</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.17576v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.17576.pdf">PDF</a></li>
</ul>
<p><strong>BEVPlace++: Fast, Robust, and Lightweight LiDAR Global Localization for Unmanned Ground Vehicles</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-06-25</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.01841v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2408.01841.pdf">PDF</a></li>
</ul>
<p><strong>Why Sample Space Matters: Keyframe Sampling Optimization for LiDAR-based Place Recognition</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-06-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.02643v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.02643.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Graph-Optimization-50-ç¯‡"><a href="#Graph-Optimization-50-ç¯‡" class="headerlink" title="Graph Optimization (50 ç¯‡)"></a><span id="graph-optimization">Graph Optimization</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>QuantGraph: A Receding-Horizon Quantum Graph Solver</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15476v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15476.pdf">PDF</a></li>
</ul>
<p><strong>Mr. Virgil: Learning Multi-robot Visual-range Relative Localization</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10540v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10540.pdf">PDF</a></li>
</ul>
<p><strong>Sequential Testing for Descriptor-Agnostic LiDAR Loop Closure in Repetitive Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09447v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09447.pdf">PDF</a></li>
</ul>
<p><strong>Have We Scene It All? Scene Graph-Aware Deep Point Cloud Compression</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-29</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.08512v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.08512.pdf">PDF</a></li>
</ul>
<p><strong>MARVO: Marine-Adaptive Radiance-aware Visual Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-28</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.22860v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.22860.pdf">PDF</a></li>
</ul>
<p><strong>Efficient Graph Optimization via Distance-Aware Graph Representation Learning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-27</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.17281v7">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.17281.pdf">PDF</a></li>
</ul>
<p><strong>MoRe: Monocular Geometry Refinement via Graph Optimization for Cross-View Consistency</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-27</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.07119v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.07119.pdf">PDF</a></li>
</ul>
<p><strong>How Animals Dance (When Youâ€™re Not Looking)</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-25</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.23738v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.23738.pdf">PDF</a></li>
</ul>
<p><strong>DOGE: Differentiable Bezier Graph Optimization for Road Network Extraction</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-25</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.19850v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.19850.pdf">PDF</a></li>
</ul>
<p><strong>Graph Neural Networks vs Convolutional Neural Networks for Graph Domination Number Prediction</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-22</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18150v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18150.pdf">PDF</a></li>
</ul>
<p><strong>CSV-Decode: Certifiable Sub-Vocabulary Decoding for Efficient Large Language Model Inference</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.21702v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.21702.pdf">PDF</a></li>
</ul>
<p><strong>3D Mapping Using a Lightweight and Low-Power Monocular Camera Embedded inside a Gripper of Limbed Climbing Robots</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.05816v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.05816.pdf">PDF</a></li>
</ul>
<p><strong>NCSAC: Effective Neural Community Search via Attribute-augmented Conductance</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-05</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.04712v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.04712.pdf">PDF</a></li>
</ul>
<p><strong>FGO MythBusters: Explaining how Kalman Filter variants achieve the same performance as FGO in navigation applications</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-31</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.00306v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.00306.pdf">PDF</a></li>
</ul>
<p><strong>UnifiedFL: A Dynamic Unified Learning Framework for Equitable Federation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-30</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.26350v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.26350.pdf">PDF</a></li>
</ul>
<p><strong>Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-29</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.00086v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.00086.pdf">PDF</a></li>
</ul>
<p><strong>Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-26</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.22740v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.22740.pdf">PDF</a></li>
</ul>
<p><strong>Underwater Visual-Inertial-Acoustic-Depth SLAM with DVL Preintegration for Degraded Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-24</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.21215v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.21215.pdf">PDF</a></li>
</ul>
<p><strong>How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Domain Knowledge Adaptation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-24</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.21148v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.21148.pdf">PDF</a></li>
</ul>
<p><strong>Exploration through Generation: Applying GFlowNets to Structured Search</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.21886v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.21886.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Visual-SLAM-50-ç¯‡"><a href="#Visual-SLAM-50-ç¯‡" class="headerlink" title="Visual SLAM (50 ç¯‡)"></a><span id="visual-slam">Visual SLAM</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>Spatia: Video Generation with Updatable Spatial Memory</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15716v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15716.pdf">PDF</a></li>
</ul>
<p><strong>Deep Learning Perspective of Scene Understanding in Autonomous Robots</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14020v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14020.pdf">PDF</a></li>
</ul>
<p><strong>Dynamic Visual SLAM using a General 3D Prior</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.06868v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.06868.pdf">PDF</a></li>
</ul>
<p><strong>DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.12653v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.12653.pdf">PDF</a></li>
</ul>
<p><strong>vS-Graphs: Tightly Coupling Visual SLAM and 3D Scene Graphs Exploiting Hierarchical Scene Understanding</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.01783v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.01783.pdf">PDF</a></li>
</ul>
<p><strong>UMIGen: A Unified Framework for Egocentric Point Cloud Generation and Cross-Embodiment Robotic Imitation Learning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.09302v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.09302.pdf">PDF</a></li>
</ul>
<p><strong>TurboMap: GPU-Accelerated Local Mapping for Visual SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.02036v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.02036.pdf">PDF</a></li>
</ul>
<p><strong>Loop Closure from Two Views: Revisiting PGO for Scalable Trajectory Estimation through Monocular Priors</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-30</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.16275v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.16275.pdf">PDF</a></li>
</ul>
<p><strong>Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.20549v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.20549.pdf">PDF</a></li>
</ul>
<p><strong>VAR-SLAM: Visual Adaptive and Robust SLAM for Dynamic Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.16205v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.16205.pdf">PDF</a></li>
</ul>
<p><strong>Accelerated Feature Detectors for Visual SLAM: A Comparative Study of FPGA vs GPU</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.13546v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.13546.pdf">PDF</a></li>
</ul>
<p><strong>SMapper: A Multi-Modal Data Acquisition Platform for SLAM Benchmarking</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.09509v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.09509.pdf">PDF</a></li>
</ul>
<p><strong>EgoExo++: Integrating On-demand Exocentric Visuals with 2.5D Ground Surface Estimation for Interactive Teleoperation of Subsea ROVs</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.00848v5">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.00848.pdf">PDF</a></li>
</ul>
<p><strong>BIM Informed Visual SLAM for Construction Monitoring</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.13972v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.13972.pdf">PDF</a></li>
</ul>
<p><strong>RSV-SLAM: Toward Real-Time Semantic Visual SLAM in Indoor Dynamic Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.02616v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.02616.pdf">PDF</a></li>
</ul>
<p><strong>Instant4D: 4D Gaussian Splatting in Minutes</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.01119v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.01119.pdf">PDF</a></li>
</ul>
<p><strong>SuperEvent: Cross-Modal Learning of Event-based Keypoint Detection for SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-29</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.00139v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.00139.pdf">PDF</a></li>
</ul>
<p><strong>GRS-SLAM3R: Real-Time Dense SLAM with Gated Recurrent State</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-28</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.23737v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.23737.pdf">PDF</a></li>
</ul>
<p><strong>Good Weights: Proactive, Adaptive Dead Reckoning Fusion for Continuous and Robust Visual SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-26</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.22910v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.22910.pdf">PDF</a></li>
</ul>
<p><strong>Optical Ocean Recipes: Creating Realistic Datasets to Facilitate Underwater Vision Research</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-24</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.20171v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.20171.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Semantic-SLAM-50-ç¯‡"><a href="#Semantic-SLAM-50-ç¯‡" class="headerlink" title="Semantic SLAM (50 ç¯‡)"></a><span id="semantic-slam">Semantic SLAM</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>GS4: Generalizable Sparse Splatting Semantic SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.06517v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.06517.pdf">PDF</a></li>
</ul>
<p><strong>KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.01889v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.01889.pdf">PDF</a></li>
</ul>
<p><strong>Taming the Light: Illumination-Invariant Semantic 3DGS-SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-28</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.22968v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.22968.pdf">PDF</a></li>
</ul>
<p><strong>Building temporally coherent 3D maps with VGGT for memory-efficient Semantic SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-27</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.16282v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.16282.pdf">PDF</a></li>
</ul>
<p><strong>Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.00783v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.00783.pdf">PDF</a></li>
</ul>
<p><strong>Human Interaction for Collaborative Semantic SLAM using Extended Reality</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.14949v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.14949.pdf">PDF</a></li>
</ul>
<p><strong>3D Active Metric-Semantic SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-21</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.06950v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2309.06950.pdf">PDF</a></li>
</ul>
<p><strong>Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.12093v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.12093.pdf">PDF</a></li>
</ul>
<p><strong>Towards Autonomous Indoor Parking: A Globally Consistent Semantic SLAM System and A Semantic Localization Subsystem</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.12169v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.12169.pdf">PDF</a></li>
</ul>
<p><strong>SemGauss-SLAM: Dense Semantic Gaussian Splatting SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-06-24</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.07494v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.07494.pdf">PDF</a></li>
</ul>
<p><strong>GeneA-SLAM2: Dynamic SLAM with AutoEncoder-Preprocessed Genetic Keypoints Resampling and Depth Variance-Guided Dynamic Region Removal</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-06-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.02736v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.02736.pdf">PDF</a></li>
</ul>
<p><strong>Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-05-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.12384v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.12384.pdf">PDF</a></li>
</ul>
<p><strong>GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-05-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.19409v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.19409.pdf">PDF</a></li>
</ul>
<p><strong>Semantic SLAM with Rolling-Shutter Cameras and Low-Precision INS in Outdoor Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-04-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.01997v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.01997.pdf">PDF</a></li>
</ul>
<p><strong>Hier-SLAM: Scaling-up Semantics in SLAM with a Hierarchically Categorical Gaussian Splatting</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-03-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.12518v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.12518.pdf">PDF</a></li>
</ul>
<p><strong>OpenGS-SLAM: Open-Set Dense Semantic SLAM with 3D Gaussian Splatting for Object-Level Scene Understanding</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-03-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.01646v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.01646.pdf">PDF</a></li>
</ul>
<p><strong>Opti-Acoustic Semantic SLAM with Unknown Objects in Underwater Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-09-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.12837v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.12837.pdf">PDF</a></li>
</ul>
<p><strong>Active Semantic Mapping and Pose Graph Spectral Analysis for Robot Exploration</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-09-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.14726v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2408.14726.pdf">PDF</a></li>
</ul>
<p><strong>NEDS-SLAM: A Neural Explicit Dense Semantic SLAM Framework using 3D Gaussian Splatting</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-09-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.11679v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.11679.pdf">PDF</a></li>
</ul>
<p><strong>MAP-ADAPT: Real-Time Quality-Adaptive Semantic 3D Maps</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-06-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.05849v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.05849.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Kalman-Filter-50-ç¯‡"><a href="#Kalman-Filter-50-ç¯‡" class="headerlink" title="Kalman Filter (50 ç¯‡)"></a><span id="kalman-filter">Kalman Filter</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>è‡ªé€‚åº”åæ–¹å·®ä¸å››å…ƒæ•°èšç„¦æ··åˆè¯¯å·®çŠ¶æ€EKF&#x2F;UKFçš„è§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Adaptive Covariance and Quaternion-Focused Hybrid Error-State EKF&#x2F;UKF for Visual-Inertial Odometry</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ IEEE Robotics and Automation Letters (RA-L) æˆ– IROS (IEEE&#x2F;RSJ International Conference on Intelligent Robots and Systems)ã€‚</li>
<li>ğŸ’¡ æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆè¯¯å·®çŠ¶æ€EKF&#x2F;UKFæ¶æ„ï¼Œä¸“æ³¨äºå››å…ƒæ•°ä¼˜åŒ–ï¼Œå¹¶å¼•å…¥åŠ¨æ€ä¼ æ„Ÿå™¨ç½®ä¿¡åº¦è¯„åˆ†æœºåˆ¶ï¼Œä»¥æå‡æ— äººæœºè§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17505v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17505.pdf">PDF</a></li>
</ul>
<p><strong>ä¸‰ç»´å¤æ‚ç®¡é“ä¸­è‡ªæ¨è¿›å¼ç®¡é“æœºå™¨äººèˆªä½æ¨ç®—ç®—æ³•ç ”ç©¶</strong></p>
<ul>
<li>åŸæ ‡é¢˜: <em>Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines</em></li>
<li>ğŸ“… æ—¥æœŸ: 2025-12-19 | ğŸ“ IEEE&#x2F;ASME Transactions on Mechatronics æˆ– IEEE International Conference on Robotics and Automation (ICRA)</li>
<li>ğŸ’¡ æå‡ºä¸€ç§åŸºäºæƒ¯æ€§å¯¼èˆªä¸è½®å¼é‡Œç¨‹è®¡èåˆçš„è‡ªé©±åŠ¨ç®¡é“æœºå™¨äººå®šä½æ–¹æ³•ï¼Œä»¥è§£å†³å¤æ‚ä¸‰ç»´ç®¡é“ç¯å¢ƒä¸­ä¼ ç»Ÿå®šä½æ–¹æ³•ï¼ˆå¦‚è§†è§‰&#x2F;æ¿€å…‰ï¼‰å› å…‰ç…§ä¸è¶³ã€ç‰¹å¾ç¼ºå¤±å¯¼è‡´çš„å®šä½æ¼‚ç§»é—®é¢˜ã€‚</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.17215v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.17215.pdf">PDF</a></li>
</ul>
<p><strong>Gated KalmaNet: A Fading Memory Layer Through Test-Time Ridge Regression</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.21016v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.21016.pdf">PDF</a></li>
</ul>
<p><strong>Iterative Joint Detection of Kalman Filter and Channel Decoder for Sensor-to-Controller Link in Wireless Networked Control Systems</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.18022v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.18022.pdf">PDF</a></li>
</ul>
<p><strong>Variational Robust Kalman Filters: A Unified Framework</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.15419v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.15419.pdf">PDF</a></li>
</ul>
<p><strong>Supervisory Measurement-Guided Noise Covariance Estimation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.24508v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.24508.pdf">PDF</a></li>
</ul>
<p><strong>Nowcasting using regression on signatures</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.10256v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.10256.pdf">PDF</a></li>
</ul>
<p><strong>TransientTrack: Advanced Multi-Object Tracking and Classification of Cancer Cells with Transient Fluorescent Signals</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.01885v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.01885.pdf">PDF</a></li>
</ul>
<p><strong>Chirp Delay-Doppler Domain Modulation Based Joint Communication and Radar for Autonomous Vehicles</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14432v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14432.pdf">PDF</a></li>
</ul>
<p><strong>Quadratic Kalman Filter for Elliptical Extended Object Tracking based on Decoupling State Components</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14426v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14426.pdf">PDF</a></li>
</ul>
<p><strong>Safe Online Control-Informed Learning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13868v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13868.pdf">PDF</a></li>
</ul>
<p><strong>CT-UIO: Continuous-Time UWB-Inertial-Odometer Localization Using Non-Uniform B-spline with Fewer Anchors</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.06287v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.06287.pdf">PDF</a></li>
</ul>
<p><strong>K-VARK: Kernelized Variance-Aware Residual Kalman Filter for Sensorless Force Estimation in Collaborative Robots</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13009v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.13009.pdf">PDF</a></li>
</ul>
<p><strong>Balancing Accuracy and Speed: A Multi-Fidelity Ensemble Kalman Filter with a Machine Learning Surrogate Model</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-13</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.12276v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.12276.pdf">PDF</a></li>
</ul>
<p><strong>iPINNER: An Iterative Physics-Informed Neural Network with Ensemble Kalman Filter</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.00731v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.00731.pdf">PDF</a></li>
</ul>
<p><strong>A Multi-Mode Structured Light 3D Imaging System with Multi-Source Information Fusion for Underwater Pipeline Detection</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.11354v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.11354.pdf">PDF</a></li>
</ul>
<p><strong>A Spiking Neural Network Implementation of Gaussian Belief Propagation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10638v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10638.pdf">PDF</a></li>
</ul>
<p><strong>K-Track: Kalman-Enhanced Tracking for Accelerating Deep Point Trackers on Edge Devices</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10628v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10628.pdf">PDF</a></li>
</ul>
<p><strong>Seamless Outdoor-Indoor Pedestrian Positioning System with GNSS&#x2F;UWB&#x2F;IMU Fusion: A Comparison of EKF, FGO, and PF</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-11</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10480v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.10480.pdf">PDF</a></li>
</ul>
<p><strong>Neural posterior inference with state-space models for calibrating ice sheet simulators</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09561v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09561.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Visual-Inertial-SLAM-50-ç¯‡"><a href="#Visual-Inertial-SLAM-50-ç¯‡" class="headerlink" title="Visual Inertial SLAM (50 ç¯‡)"></a><span id="visual-inertial-slam">Visual Inertial SLAM</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>ICD-Net: Inertial Covariance Displacement Network for Drone Visual-Inertial SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-13</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.00037v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.00037.pdf">PDF</a></li>
</ul>
<p><strong>Integration of Visual SLAM into Consumer-Grade Automotive Localization</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.06919v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.06919.pdf">PDF</a></li>
</ul>
<p><strong>Benchmarking Egocentric Visual-Inertial SLAM at City Scale</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-30</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.26639v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.26639.pdf">PDF</a></li>
</ul>
<p><strong>FastTrack: GPU-Accelerated Tracking for Visual SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-13</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.10757v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.10757.pdf">PDF</a></li>
</ul>
<p><strong>Scalable Outdoors Autonomous Drone Flight with Visual-Inertial SLAM and Dense Submaps Built without LiDAR</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-08-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.09596v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.09596.pdf">PDF</a></li>
</ul>
<p><strong>AQUA-SLAM: Tightly-Coupled Underwater Acoustic-Visual-Inertial SLAM with Sensor Calibration</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-03-14</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.11420v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.11420.pdf">PDF</a></li>
</ul>
<p><strong>Visual-Inertial SLAM for Unstructured Outdoor Environments: Benchmarking the Benefits and Computational Costs of Loop Closing</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-03-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.01716v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2408.01716.pdf">PDF</a></li>
</ul>
<p><strong>Uncertainty-Aware Visual-Inertial SLAM with Volumetric Occupancy Mapping</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-03-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.12051v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.12051.pdf">PDF</a></li>
</ul>
<p><strong>Efficient Submap-based Autonomous MAV Exploration using Visual-Inertial SLAM Configurable for LiDARs or Depth Cameras</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-03-05</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.16972v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.16972.pdf">PDF</a></li>
</ul>
<p><strong>RUSSO: Robust Underwater SLAM with Sonar Optimization against Visual Degradation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-03-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.01434v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.01434.pdf">PDF</a></li>
</ul>
<p><strong>LVI-GS: Tightly-coupled LiDAR-Visual-Inertial SLAM using 3D Gaussian Splatting</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-11-05</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.02703v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.02703.pdf">PDF</a></li>
</ul>
<p><strong>Visual-Inertial SLAM as Simple as A, B, VINS</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-09-22</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.05969v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.05969.pdf">PDF</a></li>
</ul>
<p><strong>Advancements in Translation Accuracy for Stereo Visual-Inertial Initialization</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-08-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.15082v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.15082.pdf">PDF</a></li>
</ul>
<p><strong>MAVIS: Multi-Camera Augmented Visual-Inertial SLAM using SE2(3) Based Exact IMU Pre-integration</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-07-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.08142v5">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2309.08142.pdf">PDF</a></li>
</ul>
<p><strong>IDLS: Inverse Depth Line based Visual-Inertial SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-06-30</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.11748v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2304.11748.pdf">PDF</a></li>
</ul>
<p><strong>$D^2$SLAM: Decentralized and Distributed Collaborative Visual-inertial SLAM System for Aerial Swarm</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-06-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2211.01538v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2211.01538.pdf">PDF</a></li>
</ul>
<p><strong>DVI-SLAM: A Dual Visual Inertial SLAM Network</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-05-26</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.13814v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2309.13814.pdf">PDF</a></li>
</ul>
<p><strong>A Probabilistic-based Drift Correction Module for Visual Inertial SLAMs</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-04-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.10140v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.10140.pdf">PDF</a></li>
</ul>
<p><strong>Stereo-NEC: Enhancing Stereo Visual-Inertial SLAM Initialization with Normal Epipolar Constraints</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-03-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.07225v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.07225.pdf">PDF</a></li>
</ul>
<p><strong>Control-Barrier-Aided Teleoperation with Visual-Inertial SLAM for Safe MAV Navigation in Complex Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-03-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.04331v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.04331.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Lidar-SLAM-50-ç¯‡"><a href="#Lidar-SLAM-50-ç¯‡" class="headerlink" title="Lidar SLAM (50 ç¯‡)"></a><span id="lidar-slam">Lidar SLAM</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>OptMap: Geometric Map Distillation via Submodular Maximization</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.07775v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.07775.pdf">PDF</a></li>
</ul>
<p><strong>ADA-DPM: A Neural Descriptors-based Adaptive Noise Filtering Strategy for SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-20</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.18016v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.18016.pdf">PDF</a></li>
</ul>
<p><strong>Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.15803v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.15803.pdf">PDF</a></li>
</ul>
<p><strong>SiLVR: Scalable Lidar-Visual Radiance Field Reconstruction with Uncertainty Quantification</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.02657v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.02657.pdf">PDF</a></li>
</ul>
<p><strong>Task-driven SLAM Benchmarking For Robot Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-08-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.16573v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.16573.pdf">PDF</a></li>
</ul>
<p><strong>Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-08-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.21553v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.21553.pdf">PDF</a></li>
</ul>
<p><strong>SKiD-SLAM: Robust, Lightweight, and Distributed Multi-Robot LiDAR SLAM in Resource-Constrained Field Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-30</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.08230v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.08230.pdf">PDF</a></li>
</ul>
<p><strong>Anti-Degeneracy Scheme for Lidar SLAM based on Particle Filter in Geometry Feature-Less Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-25</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.11486v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.11486.pdf">PDF</a></li>
</ul>
<p><strong>Informed, Constrained, Aligned: A Field Analysis on Degeneracy-aware Point Cloud Registration in the Wild</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-14</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.11809v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2408.11809.pdf">PDF</a></li>
</ul>
<p><strong>MDF: Multi-Modal Data Fusion with CNN-Based Object Detection for Enhanced Indoor Localization Using LiDAR-SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-05-13</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.08388v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.08388.pdf">PDF</a></li>
</ul>
<p><strong>Online Tree Reconstruction and Forest Inventory on a Mobile Robotic System</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-03-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.17622v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.17622.pdf">PDF</a></li>
</ul>
<p><strong>Lifelong 3D Mapping Framework for Hand-held &amp; Robot-mounted LiDAR Mapping Systems</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-01-30</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.18110v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.18110.pdf">PDF</a></li>
</ul>
<p><strong>Unified Few-shot Crack Segmentation and its Precise 3D Automatic Measurement in Concrete Structures</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-01-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.09203v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.09203.pdf">PDF</a></li>
</ul>
<p><strong>ROLO-SLAM: Rotation-Optimized LiDAR-Only SLAM in Uneven Terrain with Ground Vehicle</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-01-04</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.02166v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.02166.pdf">PDF</a></li>
</ul>
<p><strong>Selective Kalman Filter: When and How to Fuse Multi-Sensor Information to Overcome Degeneracy in SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-12-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.17235v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.17235.pdf">PDF</a></li>
</ul>
<p><strong>LiDAR SLAMMOT based on Confidence-guided Data Association</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-12-02</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.01041v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.01041.pdf">PDF</a></li>
</ul>
<p><strong>LiDAR Inertial Odometry And Mapping Using Learned Registration-Relevant Features</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-10-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.02961v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.02961.pdf">PDF</a></li>
</ul>
<p><strong>Heterogeneous LiDAR Dataset for Benchmarking Robust Localization in Diverse Degenerate Scenarios</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-09-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.04961v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.04961.pdf">PDF</a></li>
</ul>
<p><strong>Automated Lane Change Behavior Prediction and Environmental Perception Based on SLAM Technology</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-04-06</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.04492v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.04492.pdf">PDF</a></li>
</ul>
<p><strong>LONER: LiDAR Only Neural Representations for Real-Time SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-03-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.04937v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2309.04937.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="GNSS-50-ç¯‡"><a href="#GNSS-50-ç¯‡" class="headerlink" title="GNSS (50 ç¯‡)"></a><span id="gnss">GNSS</span> (50 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.14428v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.14428.pdf">PDF</a></li>
</ul>
<p><strong>JaGuard: Jamming Correction of GNSS Deviation with Deep Temporal Graphs</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-08</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.14000v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.14000.pdf">PDF</a></li>
</ul>
<p><strong>Wasserstein distance based semi-supervised manifold learning and application to GNSS multi-path detection</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-05</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.05567v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.05567.pdf">PDF</a></li>
</ul>
<p><strong>GNSS-Inertial State Initialization Using Inter-Epoch Baseline Residuals</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.11534v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.11534.pdf">PDF</a></li>
</ul>
<p><strong>A Robust 5G Terrestrial Positioning System with Sensor Fusion in GNSS-denied Scenarios</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-25</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.16600v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.16600.pdf">PDF</a></li>
</ul>
<p><strong>Stable Multi-Drone GNSS Tracking System for Marine Robots</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-24</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.18694v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18694.pdf">PDF</a></li>
</ul>
<p><strong>GNSS Jammer Direction Finding in Dynamic Scenarios Using an Inertial-based Multi-Antenna System</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.05128v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.05128.pdf">PDF</a></li>
</ul>
<p><strong>Ionospheric and Plasmaspheric Delay Characterization for Lunar Terrestrial GNSS Receivers with Global Core Plasma Model</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-21</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.10059v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.10059.pdf">PDF</a></li>
</ul>
<p><strong>V2VLoc: Robust GNSS-Free Collaborative Perception via LiDAR Localization</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14247v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.14247.pdf">PDF</a></li>
</ul>
<p><strong>Long Duration Inspection of GNSS-Denied Environments with a Tethered UAV-UGV Marsupial System</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-17</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.23457v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.23457.pdf">PDF</a></li>
</ul>
<p><strong>MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.20757v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.20757.pdf">PDF</a></li>
</ul>
<p><strong>Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-12</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.05999v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.05999.pdf">PDF</a></li>
</ul>
<p><strong>TRICK: Time and Range Integrity ChecK using Low Earth Orbiting Satellite for Securing GNSS</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.05100v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.05100.pdf">PDF</a></li>
</ul>
<p><strong>Optimizing Earth-Moon Transfer and Cislunar Navigation: Integrating Low-Energy Trajectories, AI Techniques and GNSS-R Technologies</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-05</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.03173v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.03173.pdf">PDF</a></li>
</ul>
<p><strong>How Effective Are Time-Series Models for Precipitation Nowcasting? A Comprehensive Benchmark for GNSS-based Precipitation Nowcasting</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-04</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.25263v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.25263.pdf">PDF</a></li>
</ul>
<p><strong>Genetic Optimization of a Software-Defined GNSS Receiver</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-25</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.22417v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.22417.pdf">PDF</a></li>
</ul>
<p><strong>Remote Autonomy for Multiple Small Lowcost UAVs in GNSS-denied Search and Rescue Operations</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-24</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.21357v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.21357.pdf">PDF</a></li>
</ul>
<p><strong>Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.20480v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.20480.pdf">PDF</a></li>
</ul>
<p><strong>Communications to Circulations: Real-Time 3D Wind Field Prediction Using 5G GNSS Signals and Deep Learning</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-20</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.16068v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.16068.pdf">PDF</a></li>
</ul>
<p><strong>Robust Statistics vs. Machine Learning vs. Bayesian Inference: Insights into Handling Faulty GNSS Measurements in Field Robotics</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.06015v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.06015.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 30 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Dynamic-SLAM-36-ç¯‡"><a href="#Dynamic-SLAM-36-ç¯‡" class="headerlink" title="Dynamic SLAM (36 ç¯‡)"></a><span id="dynamic-slam">Dynamic SLAM</span> (36 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>3D Scene Prompting for Scene-Consistent Camera-Controllable Video Generation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-15</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.14945v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2510.14945.pdf">PDF</a></li>
</ul>
<p><strong>D$^2$GSLAM: 4D Dynamic Gaussian Splatting SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-12-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09411v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2512.09411.pdf">PDF</a></li>
</ul>
<p><strong>DynoSAM: Open-Source Smoothing and Mapping Framework for Dynamic SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-20</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.11893v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.11893.pdf">PDF</a></li>
</ul>
<p><strong>MLP-SLAM: Multilayer Perceptron-Based Simultaneous Localization and Mapping</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-06</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.10669v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.10669.pdf">PDF</a></li>
</ul>
<p><strong>ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-22</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.17864v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.17864.pdf">PDF</a></li>
</ul>
<p><strong>Online Dynamic SLAM with Incremental Smoothing and Mapping</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.08197v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.08197.pdf">PDF</a></li>
</ul>
<p><strong>IL-SLAM: Intelligent Line-assisted SLAM Based on Feature Awareness for Dynamic Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.02972v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.02972.pdf">PDF</a></li>
</ul>
<p><strong>SR-SLAM: Scene-reliability Based RGB-D SLAM in Diverse Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.01111v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.01111.pdf">PDF</a></li>
</ul>
<p><strong>NGD-SLAM: Towards Real-Time Dynamic SLAM without GPU</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-06-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.07392v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.07392.pdf">PDF</a></li>
</ul>
<p><strong>GARAD-SLAM: 3D GAussian splatting for Real-time Anti Dynamic SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-02-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.03228v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.03228.pdf">PDF</a></li>
</ul>
<p><strong>TivNe-SLAM: Dynamic Mapping and Tracking via Time-Varying Neural Radiance Fields</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-02-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.18917v7">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.18917.pdf">PDF</a></li>
</ul>
<p><strong>DGS-SLAM: Gaussian Splatting SLAM in Dynamic Environment</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-11-16</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.10722v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.10722.pdf">PDF</a></li>
</ul>
<p><strong>The Importance of Coordinate Frames in Dynamic SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-09-30</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.04031v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.04031.pdf">PDF</a></li>
</ul>
<p><strong>DynORecon: Dynamic Object Reconstruction for Navigation</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-09-30</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.19928v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.19928.pdf">PDF</a></li>
</ul>
<p><strong>D$^3$FlowSLAM: Self-Supervised Dynamic SLAM with Flow Motion Decomposition and DINO Guidance</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-08-21</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2207.08794v4">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2207.08794.pdf">PDF</a></li>
</ul>
<p><strong>Learn to Memorize and to Forget: A Continual Learning Perspective of Dynamic SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-07-18</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.13338v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.13338.pdf">PDF</a></li>
</ul>
<p><strong>RoDyn-SLAM: Robust Dynamic Dense RGB-D SLAM with Neural Radiance Fields</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-07-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.01303v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.01303.pdf">PDF</a></li>
</ul>
<p><strong>Multi-object Detection, Tracking and Prediction in Rugged Dynamic Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2023-08-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.11870v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2308.11870.pdf">PDF</a></li>
</ul>
<p><strong>Simulation of Dynamic Environments for SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2023-05-26</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.04286v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.04286.pdf">PDF</a></li>
</ul>
<p><strong>RGB-D-Inertial SLAM in Indoor Dynamic Environments with Long-term Large Occlusion</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2023-03-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.13316v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.13316.pdf">PDF</a></li>
</ul>
<blockquote>
<p>ğŸ“ è¿˜æœ‰ 16 ç¯‡è®ºæ–‡æœªæ˜¾ç¤º</p>
</blockquote>
</details>

<h3 id="Gaussian-SLAM-20-ç¯‡"><a href="#Gaussian-SLAM-20-ç¯‡" class="headerlink" title="Gaussian SLAM (20 ç¯‡)"></a><span id="gaussian-slam">Gaussian SLAM</span> (20 ç¯‡)</h3><details>
<summary>ç‚¹å‡»å±•å¼€è®ºæ–‡åˆ—è¡¨</summary>

<p><strong>DiskChunGS: Large-Scale 3D Gaussian SLAM Through Chunk-Based Memory Management</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-28</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.23030v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.23030.pdf">PDF</a></li>
</ul>
<p><strong>SING3R-SLAM: Submap-based Indoor Monocular Gaussian SLAM with 3D Reconstruction Priors</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-11-21</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.17207v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.17207.pdf">PDF</a></li>
</ul>
<p><strong>Gaussian Scenes: Pose-Free Sparse-View Scene Reconstruction using Depth-Enhanced Diffusion Priors</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-10-10</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.15966v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.15966.pdf">PDF</a></li>
</ul>
<p><strong>Open-Vocabulary Online Semantic Mapping for SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-29</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.15043v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.15043.pdf">PDF</a></li>
</ul>
<p><strong>FGO-SLAM: Enhancing Gaussian SLAM with Globally Consistent Opacity Radiance Field</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-09-01</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.01547v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.01547.pdf">PDF</a></li>
</ul>
<p><strong>Hier-SLAM++: Neuro-Symbolic Semantic SLAM with a Hierarchically Categorical Gaussian Splatting</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-07-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.14931v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.14931.pdf">PDF</a></li>
</ul>
<p><strong>GRAND-SLAM: Local Optimization for Globally Consistent Large-Scale Multi-Agent Gaussian SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-06-23</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.18885v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.18885.pdf">PDF</a></li>
</ul>
<p><strong>UP-SLAM: Adaptively Structured Gaussian SLAM with Uncertainty Prediction in Dynamic Environments</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-05-28</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.22335v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.22335.pdf">PDF</a></li>
</ul>
<p><strong>VPGS-SLAM: Voxel-based Progressive 3D Gaussian SLAM in Large-Scale Scenes</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-05-25</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.18992v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.18992.pdf">PDF</a></li>
</ul>
<p><strong>HI-SLAM2: Geometry-Aware Gaussian SLAM for Fast Monocular Scene Reconstruction</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-04-29</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.17982v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2411.17982.pdf">PDF</a></li>
</ul>
<p><strong>MonoGS++: Fast and Accurate Monocular RGB Gaussian SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-04-03</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.02437v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2504.02437.pdf">PDF</a></li>
</ul>
<p><strong>MG-SLAM: Structure Gaussian Splatting SLAM with Manhattan World Hypothesis</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-03-20</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.20031v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.20031.pdf">PDF</a></li>
</ul>
<p><strong>DenseSplat: Densifying Gaussian Splatting SLAM with Neural Radiance Prior</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2025-02-13</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2502.09111v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.09111.pdf">PDF</a></li>
</ul>
<p><strong>PanoSLAM: Panoptic 3D Scene Reconstruction via Gaussian SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-12-31</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.00352v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.00352.pdf">PDF</a></li>
</ul>
<p><strong>IG-SLAM: Instant Gaussian SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-08-07</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.01126v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2408.01126.pdf">PDF</a></li>
</ul>
<p><strong>Monocular Gaussian SLAM with Language Extended Loop Closure</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-05-22</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.13748v1">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.13748.pdf">PDF</a></li>
</ul>
<p><strong>RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-05-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.19706v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.19706.pdf">PDF</a></li>
</ul>
<p><strong>Gaussian-SLAM: Photo-realistic Dense SLAM with Gaussian Splatting</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2024-03-22</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.10070v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.10070.pdf">PDF</a></li>
</ul>
<p><strong>GAPSLAM: Blending Gaussian Approximation and Particle Filters for Real-Time Non-Gaussian SLAM</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2023-08-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.14283v2">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.14283.pdf">PDF</a></li>
</ul>
<p><strong>Nested Sampling for Non-Gaussian Inference in SLAM Factor Graphs</strong></p>
<ul>
<li>ğŸ“… æ—¥æœŸ: 2022-08-09</li>
<li>ğŸ”— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2109.10871v3">arXiv</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2109.10871.pdf">PDF</a></li>
</ul>
</details>

<hr>
<h2 id="ğŸ“–-å…³äºæœ¬é¡µé¢"><a href="#ğŸ“–-å…³äºæœ¬é¡µé¢" class="headerlink" title="ğŸ“– å…³äºæœ¬é¡µé¢"></a>ğŸ“– å…³äºæœ¬é¡µé¢</h2><p>æœ¬é¡µé¢è‡ªåŠ¨è¿½è¸ª <a target="_blank" rel="noopener" href="https://github.com/luohongk/Embodied-AI-Daily">luohongk&#x2F;Embodied-AI-Daily</a> ä»“åº“ä¸­çš„æœ€æ–°è®ºæ–‡ã€‚</p>
<p><strong>ä¸»è¦ç ”ç©¶æ–¹å‘åŒ…æ‹¬:</strong></p>
<ul>
<li>ğŸš Vision and Language Navigation (VLN)</li>
<li>ğŸ¤– Vision-Language-Action (VLA)</li>
<li>ğŸ—ºï¸ SLAM &#x2F; Visual SLAM</li>
<li>ğŸŒ 3D Gaussian Splatting</li>
<li>ğŸ§  World Model</li>
<li>ğŸ”§ éçº¿æ€§ä¼˜åŒ–</li>
</ul>
<p><strong>åŠŸèƒ½ç‰¹ç‚¹:</strong></p>
<ul>
<li>ğŸ“… æ¯æ—¥è‡ªåŠ¨æ›´æ–°</li>
<li>ğŸŒ ä¸­è‹±æ–‡åŒè¯­æ˜¾ç¤º</li>
<li>ğŸ’¡ è‡ªåŠ¨æå–åˆ›æ–°ç‚¹å’Œæ–¹æ³•æ¡†æ¶</li>
<li>ğŸ“„ ç›´é“¾arXivå’ŒPDF</li>
</ul>
<hr>
<p><em>ğŸ¤– Powered by DeepSeek AI | ğŸ“¡ Auto-generated</em></p>
<p><em>æœ€åæ›´æ–°: 2025-12-24 00:08:14</em></p>
</div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/touxiang.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">mrguo</div><div class="author-info-description">è¿™æ˜¯æˆ‘çš„ä¸ªäººåšå®¢ï¼Œè®°å½•å­¦ä¹ å’Œç”Ÿæ´»</div><div class="site-data"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">81</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">29</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ztguoresearch"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/ztguoresearch" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:ztguoresearch@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://blog.csdn.net/weixin_60594413?spm=1000.2115.3001.5343" target="_blank" title="CSDN"><i class="fas fa-copyright" style="color: #fc5531;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>æœ€æ–°æ–‡ç« </span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/12/23/AI%E6%96%B0%E9%97%BB-2025-12-22/" title="2025-12-22 AIæ–°é—»æ—¥æŠ¥"><img src="/img/ai-news-cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2025-12-22 AIæ–°é—»æ—¥æŠ¥"/></a><div class="content"><a class="title" href="/2025/12/23/AI%E6%96%B0%E9%97%BB-2025-12-22/" title="2025-12-22 AIæ–°é—»æ—¥æŠ¥">2025-12-22 AIæ–°é—»æ—¥æŠ¥</a><time datetime="2025-12-23T04:01:51.000Z" title="å‘è¡¨äº 2025-12-23 12:01:51">2025-12-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/22/AI%E6%96%B0%E9%97%BB-2025-12-21/" title="2025-12-21 AIæ–°é—»æ—¥æŠ¥"><img src="/img/ai-news-cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2025-12-21 AIæ–°é—»æ—¥æŠ¥"/></a><div class="content"><a class="title" href="/2025/12/22/AI%E6%96%B0%E9%97%BB-2025-12-21/" title="2025-12-21 AIæ–°é—»æ—¥æŠ¥">2025-12-21 AIæ–°é—»æ—¥æŠ¥</a><time datetime="2025-12-22T04:01:09.000Z" title="å‘è¡¨äº 2025-12-22 12:01:09">2025-12-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/21/AI%E6%96%B0%E9%97%BB-2025-12-20/" title="2025-12-20 AIæ–°é—»æ—¥æŠ¥"><img src="/img/ai-news-cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2025-12-20 AIæ–°é—»æ—¥æŠ¥"/></a><div class="content"><a class="title" href="/2025/12/21/AI%E6%96%B0%E9%97%BB-2025-12-20/" title="2025-12-20 AIæ–°é—»æ—¥æŠ¥">2025-12-20 AIæ–°é—»æ—¥æŠ¥</a><time datetime="2025-12-21T04:01:05.000Z" title="å‘è¡¨äº 2025-12-21 12:01:05">2025-12-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/20/AI%E6%96%B0%E9%97%BB-2025-12-19/" title="2025-12-19 AIæ–°é—»æ—¥æŠ¥"><img src="/img/ai-news-cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2025-12-19 AIæ–°é—»æ—¥æŠ¥"/></a><div class="content"><a class="title" href="/2025/12/20/AI%E6%96%B0%E9%97%BB-2025-12-19/" title="2025-12-19 AIæ–°é—»æ—¥æŠ¥">2025-12-19 AIæ–°é—»æ—¥æŠ¥</a><time datetime="2025-12-20T04:02:33.000Z" title="å‘è¡¨äº 2025-12-20 12:02:33">2025-12-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/19/AI%E6%96%B0%E9%97%BB-2025-12-18/" title="2025-12-18 AIæ–°é—»æ—¥æŠ¥"><img src="/img/ai-news-cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2025-12-18 AIæ–°é—»æ—¥æŠ¥"/></a><div class="content"><a class="title" href="/2025/12/19/AI%E6%96%B0%E9%97%BB-2025-12-18/" title="2025-12-18 AIæ–°é—»æ—¥æŠ¥">2025-12-18 AIæ–°é—»æ—¥æŠ¥</a><time datetime="2025-12-19T04:02:46.000Z" title="å‘è¡¨äº 2025-12-19 12:02:46">2025-12-19</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>åˆ†ç±»</span>
            
          </div>
          <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI%E6%96%B0%E9%97%BB/"><span class="card-category-list-name">AIæ–°é—»</span><span class="card-category-list-count">74</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Web%E5%BC%80%E5%8F%91/"><span class="card-category-list-name">Webå¼€å‘</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%BB%8F%E9%AA%8C/"><span class="card-category-list-name">å­¦ä¹ ç»éªŒ</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">æŠ€æœ¯ç¬”è®°</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%97%A5%E5%B8%B8/"><span class="card-category-list-name">æ—¥å¸¸</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"><span class="card-category-list-name">ç¼–ç¨‹è¯­è¨€</span><span class="card-category-list-count">1</span></a></li>
          </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>æ ‡ç­¾</span></div><div class="card-tag-cloud"><a href="/tags/AI/" style="font-size: 1.45em; color: rgb(126, 50, 168);">AI</a><a href="/tags/%E6%96%B0%E9%97%BB/" style="font-size: 1.35em; color: rgb(171, 154, 174);">æ–°é—»</a><a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 1.35em; color: rgb(78, 138, 182);">äººå·¥æ™ºèƒ½</a><a href="/tags/TechCrunch/" style="font-size: 1.35em; color: rgb(55, 187, 130);">TechCrunch</a><a href="/tags/TheVerge/" style="font-size: 1.35em; color: rgb(50, 50, 93);">TheVerge</a><a href="/tags/Python/" style="font-size: 1.25em; color: rgb(150, 147, 182);">Python</a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 1.15em; color: rgb(127, 124, 185);">æ•°æ®åˆ†æ</a><a href="/tags/Pandas/" style="font-size: 1.15em; color: rgb(108, 60, 61);">Pandas</a><a href="/tags/NumPy/" style="font-size: 1.15em; color: rgb(129, 61, 93);">NumPy</a><a href="/tags/Matplotlib/" style="font-size: 1.15em; color: rgb(153, 78, 178);">Matplotlib</a><a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 1.15em; color: rgb(156, 184, 138);">å‰ç«¯</a><a href="/tags/JavaScript/" style="font-size: 1.15em; color: rgb(123, 125, 117);">JavaScript</a><a href="/tags/HTML/" style="font-size: 1.15em; color: rgb(99, 187, 50);">HTML</a><a href="/tags/CSS/" style="font-size: 1.15em; color: rgb(50, 117, 76);">CSS</a><a href="/tags/React/" style="font-size: 1.15em; color: rgb(50, 107, 154);">React</a><a href="/tags/Vue/" style="font-size: 1.15em; color: rgb(178, 200, 162);">Vue</a><a href="/tags/%E4%BF%9D%E7%A0%94/" style="font-size: 1.15em; color: rgb(146, 81, 152);">ä¿ç ”</a><a href="/tags/%E5%9B%BD%E9%98%B2%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6/" style="font-size: 1.15em; color: rgb(50, 86, 175);">å›½é˜²ç§‘æŠ€å¤§å­¦</a><a href="/tags/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/" style="font-size: 1.15em; color: rgb(50, 150, 135);">ç»éªŒåˆ†äº«</a><a href="/tags/%E6%8E%A8%E5%85%8D/" style="font-size: 1.15em; color: rgb(105, 92, 182);">æ¨å…</a><a href="/tags/LLM/" style="font-size: 1.15em; color: rgb(50, 175, 74);">LLM</a><a href="/tags/ChatGPT/" style="font-size: 1.15em; color: rgb(139, 50, 50);">ChatGPT</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.15em; color: rgb(125, 81, 99);">æ·±åº¦å­¦ä¹ </a><a href="/tags/NLP/" style="font-size: 1.15em; color: rgb(118, 111, 135);">NLP</a><a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size: 1.15em; color: rgb(70, 161, 155);">å¼ºåŒ–å­¦ä¹ </a><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 1.15em; color: rgb(195, 148, 86);">æœºå™¨å­¦ä¹ </a><a href="/tags/%E5%8D%9A%E5%AE%A2/" style="font-size: 1.15em; color: rgb(50, 50, 50);">åšå®¢</a><a href="/tags/Hexo/" style="font-size: 1.15em; color: rgb(50, 143, 74);">Hexo</a><a href="/tags/%E5%BC%80%E5%A7%8B/" style="font-size: 1.15em; color: rgb(166, 125, 190);">å¼€å§‹</a></div></div><div class="card-widget card-archives">
    <div class="item-headline">
      <i class="fas fa-archive"></i>
      <span>å½’æ¡£</span>
      
    </div>
  
    <ul class="card-archive-list">
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/12/">
            <span class="card-archive-list-date">
              åäºŒæœˆ 2025
            </span>
            <span class="card-archive-list-count">20</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/11/">
            <span class="card-archive-list-date">
              åä¸€æœˆ 2025
            </span>
            <span class="card-archive-list-count">29</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/10/">
            <span class="card-archive-list-date">
              åæœˆ 2025
            </span>
            <span class="card-archive-list-count">32</span>
          </a>
        </li>
      
    </ul>
  </div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>ç½‘ç«™ä¿¡æ¯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">æ–‡ç« æ•°ç›® :</div><div class="item-count">81</div></div><div class="webinfo-item"><div class="item-name">è¿è¡Œæ—¶é—´ :</div><div class="item-count" id="runtimeshow" data-publishDate="2025-10-04T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™è®¿å®¢æ•° :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™æ€»æµè§ˆé‡ :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">æœ€åæ›´æ–°æ—¶é—´ :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-12-23T16:08:22.924Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By mrguo</span><span class="framework-info"><span>æ¡†æ¶ </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.0.0</a><span class="footer-separator">|</span><span>ä¸»é¢˜ </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.1</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="æ—¥é—´å’Œå¤œé—´æ¨¡å¼åˆ‡æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.1"></script><script src="/js/main.js?v=5.5.1"></script><div class="js-pjax"></div><div id="aplayer"></div><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="/js/music-player.js"></script><script src="/js/custom-init.js"></script><script src="/js/tagcloud3d.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  æ•°æ®åŠ è½½ä¸­</span></div><div class="local-search-input"><input placeholder="æœç´¢æ–‡ç« ..." type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.1"></script></div></div></body></html>